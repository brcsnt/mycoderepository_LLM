
import streamlit as st
import logging
from langchain.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA
from langchain.memory import ConversationBufferMemory
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain.docstore.document import Document
import os
import re

# 1ï¸âƒ£ Logger Ayarla
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# 2ï¸âƒ£ API AnahtarÄ± TanÄ±mla
os.environ["OPENAI_API_KEY"] = "your_api_key_here"

# 3ï¸âƒ£ Ã–rnek Kampanya Verileri
campaigns = [
    {"code": "KAMP001", "title": "Migros Ä°ndirim KampanyasÄ±", "content": "Migros marketlerinde %20 indirim! 1-10 Åubat arasÄ±nda geÃ§erlidir.", "start_date": "01-02-2024", "end_date": "10-02-2024"},
    {"code": "KAMP002", "title": "Beyaz EÅŸya KampanyasÄ±", "content": "Beyaz eÅŸyalar 15 Mart'a kadar Ã¶zel fiyatlarla!", "start_date": "01-03-2024", "end_date": "15-03-2024"},
    {"code": "KAMP003", "title": "Giyim Sezon Sonu Ä°ndirimi", "content": "TÃ¼m giyim Ã¼rÃ¼nlerinde %30 indirim!", "start_date": "01-04-2024", "end_date": "30-04-2024"}
   
]

# 4ï¸âƒ£ OpenAI Embeddings kullanarak ChromaDB oluÅŸtur ve doldur
embeddings = OpenAIEmbeddings()
vector_store = Chroma(embedding_function=embeddings)

# Kampanya verilerini ChromaDB'ye ekleyelim
docs = [Document(page_content=f"{c['title']}: {c['content']} (GeÃ§erlilik: {c['start_date']} - {c['end_date']})", metadata={"code": c["code"]}) for c in campaigns]
vector_store.add_documents(docs)
retriever = vector_store.as_retriever(search_kwargs={"k": 3})

# 5ï¸âƒ£ LLM Modeli TanÄ±mla ve Sistem Prompt Ekle
system_prompt = "Sen bir reklam kampanya asistanÄ±sÄ±n. KullanÄ±cÄ±ya kampanyalar hakkÄ±nda bilgi ver, ama sadece kampanya metinlerinden referans al."
llm = ChatOpenAI(model_name="gpt-4", temperature=0, system_prompt=system_prompt)
qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)

# 6ï¸âƒ£ Sohbet HafÄ±zasÄ±nÄ± (Memory) TanÄ±mla
memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)
previous_retrieved_campaigns = {}
follow_up_count = 0
max_follow_up = 5  # KullanÄ±cÄ±nÄ±n aynÄ± kampanya iÃ§inde sorabileceÄŸi maksimum takip sorusu

# 7ï¸âƒ£ Kampanya Kodunu Ã‡Ä±kart ve DoÄŸrudan Bilgi Getir
def extract_campaign_code(user_input):
    try:
        match = re.search(r"KAMP\d{3}", user_input)
        return match.group(0) if match else None
    except Exception as e:
        logger.error(f"Kampanya kodu Ã§Ä±karma hatasÄ±: {e}")
        return None

# 8ï¸âƒ£ Yeni Kampanyaya GeÃ§iÅŸi AlgÄ±la
def detect_new_campaign(user_input):
    global previous_retrieved_campaigns, follow_up_count
    
    try:
        logger.info(f"Yeni kampanya tespiti iÃ§in giriÅŸ alÄ±ndÄ±: {user_input}")
        
        campaign_code = extract_campaign_code(user_input)
        if campaign_code:
            docs = retriever.get_relevant_documents(campaign_code)
            if docs:
                previous_retrieved_campaigns[campaign_code] = docs[0]
                follow_up_count = 0  # Yeni kampanya baÅŸladÄ±ÄŸÄ±nda follow-up sayacÄ±nÄ± sÄ±fÄ±rla
                logger.info(f"Belirtilen kampanya kodu bulundu: {campaign_code}, Ä°Ã§erik: {docs[0].page_content}")
                return docs[0].page_content
        
        # VectorStore kullanarak en alakalÄ± top_n kampanyayÄ± bul
        similar_docs = retriever.get_relevant_documents(user_input)
        if similar_docs:
            previous_retrieved_campaigns = {f"KAMP{i+1:03}": doc for i, doc in enumerate(similar_docs)}
            follow_up_count = 0  # Yeni kampanya bulunduÄŸunda follow-up sÄ±fÄ±rlanÄ±r
            result = "\n".join([f"{key} - {doc.page_content.split(' ', 5)[0]}..." for key, doc in previous_retrieved_campaigns.items()])
            return f"En alakalÄ± kampanyalar:\n{result}"
        
        return "Uygun kampanya bulunamadÄ±."
    except Exception as e:
        logger.error(f"Yeni kampanya tespitinde hata: {e}")
        return "Bir hata oluÅŸtu, lÃ¼tfen tekrar deneyin."

# 9ï¸âƒ£ KullanÄ±cÄ±dan GiriÅŸ Al ve YanÄ±t DÃ¶ndÃ¼r
def chat_with_bot(user_input):
    global previous_retrieved_campaigns, follow_up_count
    
    try:
        logger.info(f"KullanÄ±cÄ± giriÅŸi: {user_input}")
        
        if follow_up_count >= max_follow_up:
            return "âš  Maksimum takip soru sÄ±nÄ±rÄ±na ulaÅŸÄ±ldÄ±. Yeni bir kampanya hakkÄ±nda soru sorabilirsiniz."
        
        chat_history = memory.load_memory_variables({})["chat_history"]
        campaign_info = detect_new_campaign(user_input)
        if campaign_info:
            return campaign_info
        
        match = re.search(r"(KAMP\d{3}) hakkÄ±nda (.+)\??", user_input)
        if match:
            campaign_code = match.group(1)
            if campaign_code in previous_retrieved_campaigns:
                selected_campaign = previous_retrieved_campaigns[campaign_code]
                follow_up_count += 1  # Takip sorusu sayÄ±sÄ±nÄ± artÄ±r
                logger.info(f"SeÃ§ilen kampanya: {selected_campaign}")
                return qa_chain.run(f"{chat_history}\nKullanÄ±cÄ±: {user_input}\nBu kampanya hakkÄ±nda: {selected_campaign.page_content}")
            return "âš  GeÃ§ersiz kampanya kodu. LÃ¼tfen geÃ§erli bir kampanya girin."
        
        follow_up_count += 1  # Genel sorular iÃ§in de takip sorusu sayÄ±sÄ±nÄ± artÄ±r
        response = qa_chain.run(f"{chat_history}\nKullanÄ±cÄ±: {user_input}")
        memory.save_context({"input": user_input}, {"output": response})
        logger.info(f"LLM YanÄ±tÄ±: {response}")
        return response
    except Exception as e:
        logger.error(f"Chat iÅŸleminde hata: {e}")
        return "Bir hata oluÅŸtu, lÃ¼tfen tekrar deneyin."

# ğŸ”Ÿ Streamlit ArayÃ¼zÃ¼
st.title("ğŸ“¢ Reklam Kampanya Chatbotu")
st.write("SorularÄ±nÄ±zÄ± sorun, kampanyalar hakkÄ±nda bilgi alÄ±n!")

user_input = st.text_input("MesajÄ±nÄ±zÄ± girin:")
if st.button("GÃ¶nder"):
    if user_input:
        response = chat_with_bot(user_input)
        st.write(response)



---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------





import streamlit as st
import logging
from langchain.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA
from langchain.memory import ConversationBufferMemory
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain.docstore.document import Document
import os
import re

# 1ï¸âƒ£ Logger Ayarla - Hata ve iÅŸlem kayÄ±tlarÄ±nÄ± tutmak iÃ§in kullanÄ±lÄ±r
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# 2ï¸âƒ£ OpenAI API AnahtarÄ± TanÄ±mla - OpenAI LLM modelini kullanabilmek iÃ§in gerekli
os.environ["OPENAI_API_KEY"] = "your_api_key_here"

# 3ï¸âƒ£ Ã–rnek Kampanya Verileri - KullanÄ±cÄ±ya sunulacak kampanyalar burada tanÄ±mlanÄ±r
campaigns = [
    {"code": "KAMP001", "title": "Migros Ä°ndirim KampanyasÄ±", "content": "Migros marketlerinde %20 indirim! 1-10 Åubat arasÄ±nda geÃ§erlidir.", "start_date": "01-02-2024", "end_date": "10-02-2024"},
    {"code": "KAMP002", "title": "Beyaz EÅŸya KampanyasÄ±", "content": "Beyaz eÅŸyalar 15 Mart'a kadar Ã¶zel fiyatlarla!", "start_date": "01-03-2024", "end_date": "15-03-2024"},
    {"code": "KAMP003", "title": "Giyim Sezon Sonu Ä°ndirimi", "content": "TÃ¼m giyim Ã¼rÃ¼nlerinde %30 indirim!", "start_date": "01-04-2024", "end_date": "30-04-2024"}
]

# 4ï¸âƒ£ OpenAI Embeddings kullanarak ChromaDB oluÅŸtur ve doldur - Kampanyalar vektÃ¶r olarak saklanÄ±r
embeddings = OpenAIEmbeddings()
vector_store = Chroma(embedding_function=embeddings)

# Kampanya verilerini ChromaDB'ye ekleyelim
docs = [Document(page_content=f"{c['title']}: {c['content']} (GeÃ§erlilik: {c['start_date']} - {c['end_date']})", metadata={"code": c["code"]}) for c in campaigns]
vector_store.add_documents(docs)
retriever = vector_store.as_retriever(search_kwargs={"k": 3})

# 5ï¸âƒ£ LLM Modeli TanÄ±mla ve Sistem Prompt Ekle - Modelin nasÄ±l davranacaÄŸÄ±nÄ± belirler
system_prompt = "Sen bir reklam kampanya asistanÄ±sÄ±n. KullanÄ±cÄ±ya kampanyalar hakkÄ±nda bilgi ver, ama sadece kampanya metinlerinden referans al."
follow_up_prompt = "Bu bir takip sorusudur. Ã–nceki konuÅŸmalarÄ± dikkate alarak, sadece kampanya metinlerine dayanarak kesin ve kÄ±sa bir yanÄ±t ver."

llm = ChatOpenAI(model_name="gpt-4", temperature=0, system_prompt=system_prompt)
qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)

# 6ï¸âƒ£ Sohbet HafÄ±zasÄ±nÄ± (Memory) TanÄ±mla - KullanÄ±cÄ±nÄ±n konuÅŸmalarÄ±nÄ± saklar
memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)
previous_retrieved_campaigns = {}  # Ã–nceki getirilen kampanyalarÄ± saklar
follow_up_count = 0  # KullanÄ±cÄ±nÄ±n kaÃ§ tane takip sorusu sorduÄŸunu takip eder
max_follow_up = 5  # KullanÄ±cÄ±nÄ±n aynÄ± kampanya iÃ§inde sorabileceÄŸi maksimum takip sorusu

# 9ï¸âƒ£ KullanÄ±cÄ±dan GiriÅŸ Al ve YanÄ±t DÃ¶ndÃ¼r - KullanÄ±cÄ±nÄ±n mesajÄ±nÄ± alÄ±r ve uygun cevabÄ± dÃ¶ndÃ¼rÃ¼r
def chat_with_bot(user_input):
    global previous_retrieved_campaigns, follow_up_count
    
    try:
        logger.info(f"KullanÄ±cÄ± giriÅŸi: {user_input}")
        
        if follow_up_count >= max_follow_up:
            return "âš  Maksimum takip soru sÄ±nÄ±rÄ±na ulaÅŸÄ±ldÄ±. Yeni bir kampanya hakkÄ±nda soru sorabilirsiniz."
        
        chat_history = memory.load_memory_variables({})["chat_history"]
        campaign_info = detect_new_campaign(user_input)
        if campaign_info:
            return campaign_info
        
        match = re.search(r"(KAMP\d{3}) hakkÄ±nda (.+)\??", user_input)
        if match:
            campaign_code = match.group(1)
            if campaign_code in previous_retrieved_campaigns:
                selected_campaign = previous_retrieved_campaigns[campaign_code]
                follow_up_count += 1
                logger.info(f"SeÃ§ilen kampanya: {selected_campaign}")
                return qa_chain.run(f"{follow_up_prompt}\n{chat_history}\nKullanÄ±cÄ±: {user_input}\nBu kampanya hakkÄ±nda: {selected_campaign.page_content}")
        
        follow_up_count += 1
        if follow_up_count > 1:
            response = qa_chain.run(f"{follow_up_prompt}\n{chat_history}\nKullanÄ±cÄ±: {user_input}")
        else:
            response = qa_chain.run(f"{system_prompt}\n{chat_history}\nKullanÄ±cÄ±: {user_input}")
        
        memory.save_context({"input": user_input}, {"output": response})
        logger.info(f"LLM YanÄ±tÄ±: {response}")
        return response
    except Exception as e:
        logger.error(f"Chat iÅŸleminde hata: {e}")
        return "Bir hata oluÅŸtu, lÃ¼tfen tekrar deneyin."

# ğŸ”Ÿ Streamlit ArayÃ¼zÃ¼ - KullanÄ±cÄ±dan giriÅŸ alÄ±p chatbot ile iletiÅŸime geÃ§mesini saÄŸlar
st.title("ğŸ“¢ Reklam Kampanya Chatbotu")
st.write("SorularÄ±nÄ±zÄ± sorun, kampanyalar hakkÄ±nda bilgi alÄ±n!")

user_input = st.text_input("MesajÄ±nÄ±zÄ± girin:")
if st.button("GÃ¶nder"):
    if user_input:
        response = chat_with_bot(user_input)
        st.write(response)



------------------------------------------------------------------------------------------------------------------------------------------------



"""


Evet, kodun son hali yukarÄ±daki diyalog akÄ±ÅŸÄ±na uygun ÅŸekilde cevap verebilecek ÅŸekilde tasarlanmÄ±ÅŸtÄ±r. Ã–rneÄŸin:

KullanÄ±cÄ±: "KAMP001 kampanyasÄ± nedir ?"

Sorguda aÃ§Ä±kÃ§a "KAMP001" yer aldÄ±ÄŸÄ±ndan, sistem doÄŸrudan bu kampanyayÄ± tespit eder, global kampanya listesi ve takip sayacÄ± sÄ±fÄ±rlanÄ±r (konuÅŸma geÃ§miÅŸi temizlenir) ve KAMP001â€™in iÃ§erik bilgisi ile LLMâ€™ye sorgu gÃ¶nderilerek yanÄ±t Ã¼retilir.
KullanÄ±cÄ±: "Bana Migros kampanyasÄ±nÄ±n detaylarÄ±nÄ± sÃ¶yle."

Sorguda aÃ§Ä±k bir kampanya kodu olmadÄ±ÄŸÄ± iÃ§in, sistem vector store Ã¼zerinden TOP_N (3) kriterine gÃ¶re ilgili kampanyalarÄ± arar. EÄŸer Migros ile ilgili kampanyalar varsa, bu kampanyalarÄ±n kod ve baÅŸlÄ±k bilgileri liste halinde (Ã¶rneÄŸin, â€œ1. KAMP001: Migros Ä°ndirim KampanyasÄ±â€ gibi) sunulur.
KullanÄ±cÄ±: "2.gelen kampanyanÄ±n iÃ§eriÄŸi nedir?"

Bu takip (follow-up) sorgusunda, sistem Ã¶nceki listelenen kampanyalar ve konuÅŸma geÃ§miÅŸini LLMâ€™ye gÃ¶ndererek kullanÄ±cÄ±nÄ±n hangi kampanyaya atÄ±fta bulunduÄŸunu belirlemesini ister. LLMâ€™nin tespit ettiÄŸi kampanyanÄ±n iÃ§erik bilgisi, kullanÄ±cÄ±nÄ±n sorusu ile birlikte LLMâ€™ye gÃ¶nderilir ve LLMâ€™nin cevabÄ± ekrana basÄ±lÄ±r.
KullanÄ±cÄ±: "Peki 3.sÄ±radaki kampanyanÄ±n detayÄ± neydi yazar mÄ±sÄ±n?"

AynÄ± ÅŸekilde, LLM Ã¶nceki listeden (Ã¶rneÄŸin, 3. sÄ±radaki kampanya) hangi kampanyanÄ±n kastedildiÄŸini belirler, ilgili kampanyanÄ±n iÃ§erik bilgisi ve kullanÄ±cÄ± sorusu ile LLMâ€™den nihai yanÄ±t alÄ±nÄ±r.
KullanÄ±cÄ±: "Peki sonuncu yazan kampanyanÄ±n detayÄ±?"

LLM, "sonuncu" ifadesini de gÃ¶z Ã¶nÃ¼nde bulundurarak Ã¶nceki listeden en son elemanÄ± tespit eder ve bu kampanyanÄ±n detaylarÄ±, kullanÄ±cÄ±nÄ±n sorusu ile birlikte LLMâ€™ye gÃ¶nderilerek yanÄ±t Ã¼retilir.
KullanÄ±cÄ±: "Beyaz eÅŸya kampanyasÄ±nÄ±n detaylarÄ± neydi peki"

EÄŸer LLM, bu sorgunun Ã¶nceki listelenen kampanyalarla iliÅŸkili olmadÄ±ÄŸÄ±nÄ± belirlerse, sistem global durumu (last_retrieved_campaigns ve konuÅŸma geÃ§miÅŸini) temizler ve yeni kampanya sorgusu olarak "Beyaz EÅŸya KampanyasÄ±"nÄ± vector storeâ€™dan arar. BÃ¶ylece yeni kampanya sorgusu Ã¼zerinden ilgili kampanyanÄ±n detaylarÄ± LLMâ€™den alÄ±nÄ±r.
KullanÄ±cÄ±: "KAMP003 kampanyasÄ±nÄ±n detaylarÄ± nedir ?"

Sorguda aÃ§Ä±kÃ§a "KAMP003" yer aldÄ±ÄŸÄ±ndan, sistem doÄŸrudan KAMP003â€™Ã¼ tespit eder, global durum sÄ±fÄ±rlanÄ±r ve KAMP003â€™Ã¼n iÃ§erik bilgisi ile LLMâ€™ye sorgu gÃ¶nderilerek yanÄ±t alÄ±nÄ±r.
AyrÄ±ca, takip sorgularÄ±nda maksimum takip sayÄ±sÄ± (Ã¶rneÄŸin MAX_FOLLOW_UP = 5) uygulanmakta; eÄŸer kullanÄ±cÄ± 5 takip sorgusuna ulaÅŸÄ±rsa, sistem otomatik olarak global durumu temizleyip yeni kampanya sorgusu yapÄ±lmasÄ±nÄ± isteyecektir.

Bu yapÄ± sayesinde, kullanÄ±cÄ± hiÃ§bir ek numeric veya sÄ±ralama girdisi vermeden, tamamen doÄŸal diyalog akÄ±ÅŸÄ± iÃ§erisinde doÄŸru kampanyanÄ±n tespit edilip, ilgili kampanyanÄ±n iÃ§erik bilgisiyle LLM tarafÄ±ndan Ã¼retilen yanÄ±t ekrana basÄ±lacaktÄ±r.


"""


import streamlit as st
import logging
import os
import re
from langchain.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA
from langchain.memory import ConversationBufferMemory
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain.docstore.document import Document

# 1ï¸âƒ£ Logger Ayarla
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# 2ï¸âƒ£ OpenAI API AnahtarÄ± TanÄ±mla
os.environ["OPENAI_API_KEY"] = "your_api_key_here"  # API anahtarÄ±nÄ±zÄ± buraya girin

# 3ï¸âƒ£ Ã–rnek Kampanya Verileri
campaigns = [
    {"code": "KAMP001", "title": "Migros Ä°ndirim KampanyasÄ±", "content": "Migros marketlerinde %20 indirim! 1-10 Åubat arasÄ±nda geÃ§erlidir.", "start_date": "01-02-2024", "end_date": "10-02-2024"},
    {"code": "KAMP002", "title": "Beyaz EÅŸya KampanyasÄ±", "content": "Beyaz eÅŸyalar 15 Mart'a kadar Ã¶zel fiyatlarla!", "start_date": "01-03-2024", "end_date": "15-03-2024"},
    {"code": "KAMP003", "title": "Giyim Sezon Sonu Ä°ndirimi", "content": "TÃ¼m giyim Ã¼rÃ¼nlerinde %30 indirim!", "start_date": "01-04-2024", "end_date": "30-04-2024"}
]

# Parametrik olarak top_n deÄŸeri (ÅŸu anda 3 olarak ayarlandÄ±)
TOP_N = 3

# Takip sorgularÄ± iÃ§in maksimum sayÄ±yÄ± belirleyelim (Ã¶rneÄŸin, 5)
MAX_FOLLOW_UP = 5

# 4ï¸âƒ£ OpenAI Embeddings kullanarak ChromaDB oluÅŸtur ve doldur
embeddings = OpenAIEmbeddings()
vector_store = Chroma(embedding_function=embeddings)
docs = [
    Document(
        page_content=f"{c['title']}: {c['content']} (GeÃ§erlilik: {c['start_date']} - {c['end_date']})",
        metadata={"code": c["code"]}
    )
    for c in campaigns
]
vector_store.add_documents(docs)
# TOP_N kriteri kullanÄ±larak en iyi sonuÃ§lar alÄ±nÄ±r.
retriever = vector_store.as_retriever(search_kwargs={"k": TOP_N})

# 5ï¸âƒ£ LLM Modeli ve Prompt AyarlarÄ±
system_prompt = "Sen bir reklam kampanya asistanÄ±sÄ±n. KullanÄ±cÄ±ya kampanyalar hakkÄ±nda bilgi ver, yanÄ±tlarÄ±nÄ± sadece kampanya metinlerine dayandÄ±r."
follow_up_prompt = (
    "Bu bir takip (follow-up) sorusudur. AÅŸaÄŸÄ±daki konuÅŸma geÃ§miÅŸini ve listelenen kampanyalarÄ± inceleyerek, "
    "kullanÄ±cÄ±nÄ±n hangi kampanya hakkÄ±nda detay istediÄŸini belirle ve sadece o kampanyanÄ±n detaylarÄ±nÄ± ver."
)

llm = ChatOpenAI(model_name="gpt-4", temperature=0, system_prompt=system_prompt)
qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)

# 6ï¸âƒ£ KonuÅŸma HafÄ±zasÄ± ve Global Durum DeÄŸiÅŸkenleri
memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)
last_retrieved_campaigns = []   # Son sorgudan dÃ¶nen kampanyalarÄ±n listesini saklar
follow_up_count = 0              # Takip sorgularÄ± iÃ§in sayacÄ± tutar

# 7ï¸âƒ£ Yeni Kampanya SorgularÄ±nÄ± DoÄŸal Dil ile Tespit Eden Fonksiyon
def detect_new_campaign(user_input: str):
    """
    EÄŸer sorguda doÄŸrudan kampanya kodu geÃ§miyorsa,
    vector store Ã¼zerinden ilgili kampanyalarÄ± getirir.
    
    - EÄŸer tek bir kampanya bulunursa, kampanyanÄ±n contentâ€™i ve kullanÄ±cÄ±nÄ±n sorusu ile LLM'den yanÄ±t alÄ±nÄ±r.
    - EÄŸer birden fazla kampanya bulunursa, TOP_N kadar sonuÃ§ liste halinde sunulur.
    """
    global last_retrieved_campaigns
    if re.search(r"KAMP\d{3}", user_input, re.IGNORECASE):
        return None  # Sorguda aÃ§Ä±k kampanya kodu varsa bu fonksiyon devreye girmez.

    retrieved_docs = retriever.get_relevant_documents(user_input)
    if not retrieved_docs:
        return "ÃœzgÃ¼nÃ¼m, sorgunuza uygun kampanya bulunamadÄ±."
    
    last_retrieved_campaigns = retrieved_docs

    if len(retrieved_docs) == 1:
        doc = retrieved_docs[0]
        response = qa_chain.run(
            f"{system_prompt}\nKullanÄ±cÄ±: {user_input}\nBu kampanya hakkÄ±nda: {doc.page_content}"
        )
        return response
    else:
        # Birden fazla kampanya bulunduÄŸunda, TOP_N kadar sonuÃ§ liste halinde sunulur.
        response_lines = ["Ä°lgili kampanyalar:"]
        for i, doc in enumerate(retrieved_docs[:TOP_N], start=1):
            title = doc.page_content.split(":")[0].strip()
            code = doc.metadata.get("code", "Bilinmiyor")
            response_lines.append(f"{i}. {code}: {title}")
        return "\n".join(response_lines)

# 8ï¸âƒ£ KullanÄ±cÄ± Girdilerini Ä°ÅŸleyen Fonksiyon
def chat_with_bot(user_input: str):
    global last_retrieved_campaigns, follow_up_count
    try:
        logger.info(f"KullanÄ±cÄ± giriÅŸi: {user_input}")
        chat_history = memory.load_memory_variables({})["chat_history"]

        # (A) EÄŸer sorguda aÃ§Ä±kÃ§a kampanya kodu (Ã¶rn. "KAMP001") varsa:
        code_match = re.search(r"(KAMP\d{3})", user_input, re.IGNORECASE)
        if code_match:
            campaign_code = code_match.group(1).upper()
            selected_doc = next((doc for doc in docs if doc.metadata.get("code", "").upper() == campaign_code), None)
            if selected_doc:
                # Yeni kampanya sorgusu olduÄŸundan, global liste ve (opsiyonel) geÃ§miÅŸ temizlenir.
                last_retrieved_campaigns = [selected_doc]
                follow_up_count = 0
                memory.clear()  # KonuÅŸma geÃ§miÅŸini temizle
                # KampanyanÄ±n contentâ€™i ve kullanÄ±cÄ±nÄ±n sorusu ile LLM'den yanÄ±t alÄ±nÄ±r.
                response = qa_chain.run(
                    f"{system_prompt}\nKullanÄ±cÄ±: {user_input}\nBu kampanya hakkÄ±nda: {selected_doc.page_content}"
                )
                memory.save_context({"input": user_input}, {"output": response})
                return response
            else:
                return "Belirtilen kampanya bulunamadÄ±."

        # (B) EÄŸer daha Ã¶nceki sorgudan dÃ¶nen kampanya listesi boÅŸsa, yeni sorgu olarak ele al:
        if not last_retrieved_campaigns:
            new_campaign_response = detect_new_campaign(user_input)
            memory.save_context({"input": user_input}, {"output": new_campaign_response})
            return new_campaign_response

        # (C) Gelen sorgu bir takip (follow-up) sorgusuyse:
        # EÄŸer takip sorgularÄ±nÄ±n sayÄ±sÄ± maksimum deÄŸeri aÅŸtÄ±ysa:
        if follow_up_count >= MAX_FOLLOW_UP:
            # Maksimum takip sayÄ±sÄ±na ulaÅŸÄ±ldÄ±ÄŸÄ±nda, kullanÄ±cÄ±ya yeni kampanya sorgusu yapmasÄ± istenir.
            last_retrieved_campaigns = []
            memory.clear()  # KonuÅŸma geÃ§miÅŸini temizle
            follow_up_count = 0
            return "Maksimum takip soru sÄ±nÄ±rÄ±na ulaÅŸÄ±ldÄ±. LÃ¼tfen yeni kampanya sorgusu yapÄ±nÄ±z."

        # Takip sorgusunda, LLMâ€™den Ã¶nceki listelenen kampanyalar ve konuÅŸma geÃ§miÅŸine dayanarak,
        # kullanÄ±cÄ±nÄ±n hangi kampanyaya atÄ±fta bulunduÄŸunu belirlemesi istenir.
        campaigns_context = "\n".join(
            f"{doc.metadata.get('code','Bilinmiyor')}: {doc.page_content}"
            for doc in last_retrieved_campaigns
        )
        determination_prompt = (
            f"AÅŸaÄŸÄ±daki listelenen kampanyalar iÃ§erisinden, kullanÄ±cÄ±nÄ±n aÅŸaÄŸÄ±daki sorgusuyla en Ã§ok hangi kampanyaya atÄ±fta bulunduÄŸunu belirle. "
            f"EÄŸer sorgu, listelenen kampanyalarla ilgili deÄŸilse, sadece 'yeni kampanya' yaz.\n\n"
            f"Listelenen Kampanyalar:\n{campaigns_context}\n\n"
            f"KullanÄ±cÄ±nÄ±n Sorgusu: {user_input}\n\n"
            f"YanÄ±t (sadece ilgili kampanya kodunu ya da 'yeni kampanya' ifadesini ver): "
        )
        determination = llm.run(determination_prompt).strip().lower()
        logger.info(f"Determination: {determination}")

        # EÄŸer LLM yanÄ±tÄ±nda "yeni kampanya" ifadesi geÃ§iyorsa:
        if "yeni kampanya" in determination:
            last_retrieved_campaigns = []
            memory.clear()  # KonuÅŸma geÃ§miÅŸini temizle
            follow_up_count = 0
            new_campaign_response = detect_new_campaign(user_input)
            memory.save_context({"input": user_input}, {"output": new_campaign_response})
            return new_campaign_response
        else:
            # LLM yanÄ±tÄ±ndan tespit edilen kampanya kodunu kullanarak ilgili kampanyayÄ± seÃ§elim.
            campaign_code_match = re.search(r"(KAMP\d{3})", determination, re.IGNORECASE)
            if campaign_code_match:
                campaign_code = campaign_code_match.group(1).upper()
                selected_doc = next((doc for doc in last_retrieved_campaigns if doc.metadata.get("code", "").upper() == campaign_code), None)
                if not selected_doc:
                    return "Listede belirtilen kampanya bulunamadÄ±."
            else:
                return "LÃ¼tfen hangi kampanyadan bahsettiÄŸinizi netleÅŸtiriniz."
            
            follow_up_count += 1
            # KampanyanÄ±n contentâ€™i ve kullanÄ±cÄ±nÄ±n sorusu ile LLMâ€™den yardÄ±m alÄ±nÄ±r, son yanÄ±t ekrana basÄ±lÄ±r.
            response = qa_chain.run(
                f"{follow_up_prompt}\nKullanÄ±cÄ±: {user_input}\nBu kampanya hakkÄ±nda: {selected_doc.page_content}\nKonuÅŸma GeÃ§miÅŸi:\n{chat_history}"
            )
            memory.save_context({"input": user_input}, {"output": response})
            return response

    except Exception as e:
        logger.error(f"Chat iÅŸleminde hata: {e}")
        return "Bir hata oluÅŸtu, lÃ¼tfen tekrar deneyin."

# 9ï¸âƒ£ Streamlit ArayÃ¼zÃ¼
st.title("ğŸ“¢ Reklam Kampanya Chatbotu")
st.write("SorularÄ±nÄ±zÄ± sorun, kampanyalar hakkÄ±nda bilgi alÄ±n!")

user_input = st.text_input("MesajÄ±nÄ±zÄ± girin:")
if st.button("GÃ¶nder"):
    if user_input:
        response = chat_with_bot(user_input)
        st.write(response)





----------------------------------------------------------------------------------------------------

# LOG LU YAPI



import streamlit as st
import logging
import os
import re
import pandas as pd
from datetime import datetime
from langchain.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA
from langchain.memory import ConversationBufferMemory
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain.docstore.document import Document

# 1ï¸âƒ£ Logger Ayarla
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# 2ï¸âƒ£ OpenAI API AnahtarÄ± TanÄ±mla
os.environ["OPENAI_API_KEY"] = "your_api_key_here"  # API anahtarÄ±nÄ±zÄ± buraya girin

# 3ï¸âƒ£ Ã–rnek Kampanya Verileri
campaigns = [
    {"code": "KAMP001", "title": "Migros Ä°ndirim KampanyasÄ±", "content": "Migros marketlerinde %20 indirim! 1-10 Åubat arasÄ±nda geÃ§erlidir.", "start_date": "01-02-2024", "end_date": "10-02-2024"},
    {"code": "KAMP002", "title": "Beyaz EÅŸya KampanyasÄ±", "content": "Beyaz eÅŸyalar 15 Mart'a kadar Ã¶zel fiyatlarla!", "start_date": "01-03-2024", "end_date": "15-03-2024"},
    {"code": "KAMP003", "title": "Giyim Sezon Sonu Ä°ndirimi", "content": "TÃ¼m giyim Ã¼rÃ¼nlerinde %30 indirim!", "start_date": "01-04-2024", "end_date": "30-04-2024"}
]

# Parametrik olarak top_n deÄŸeri (ÅŸu anda 3 olarak ayarlandÄ±)
TOP_N = 3

# Takip sorgularÄ± iÃ§in maksimum sayÄ± (Ã¶rneÄŸin 5)
MAX_FOLLOW_UP = 5

# 4ï¸âƒ£ OpenAI Embeddings kullanarak ChromaDB oluÅŸtur ve doldur
embeddings = OpenAIEmbeddings()
vector_store = Chroma(embedding_function=embeddings)
docs = [
    Document(
        page_content=f"{c['title']}: {c['content']} (GeÃ§erlilik: {c['start_date']} - {c['end_date']})",
        metadata={"code": c["code"]}
    )
    for c in campaigns
]
vector_store.add_documents(docs)
retriever = vector_store.as_retriever(search_kwargs={"k": TOP_N})

# 5ï¸âƒ£ LLM Modeli ve Prompt AyarlarÄ±
system_prompt = "Sen bir reklam kampanya asistanÄ±sÄ±n. KullanÄ±cÄ±ya kampanyalar hakkÄ±nda bilgi ver, yanÄ±tlarÄ±nÄ± sadece kampanya metinlerine dayandÄ±r."
follow_up_prompt = (
    "Bu bir takip (follow-up) sorusudur. AÅŸaÄŸÄ±daki konuÅŸma geÃ§miÅŸini ve listelenen kampanyalarÄ± inceleyerek, "
    "kullanÄ±cÄ±nÄ±n hangi kampanya hakkÄ±nda detay istediÄŸini belirle ve sadece o kampanyanÄ±n detaylarÄ±nÄ± ver."
)

llm = ChatOpenAI(model_name="gpt-4", temperature=0, system_prompt=system_prompt)
qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)

# 6ï¸âƒ£ KonuÅŸma HafÄ±zasÄ± ve Global Durum DeÄŸiÅŸkenleri
memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)

# Global kampanya listesi ve takip sayÄ±sÄ±
last_retrieved_campaigns = []   # Son sorgudan dÃ¶nen kampanyalarÄ±n listesini saklar
follow_up_count = 0              # Takip sorgularÄ± iÃ§in sayaÃ§

# Session yÃ¶netimi iÃ§in: kampanya kodu ve session id bilgileri
if "current_campaign_code" not in st.session_state:
    st.session_state["current_campaign_code"] = None
if "session_id" not in st.session_state:
    st.session_state["session_id"] = 0
if "session_counter" not in st.session_state:
    st.session_state["session_counter"] = 0

# Excel loglarÄ±nÄ± tutmak iÃ§in st.session_state kullanÄ±yoruz
if "chat_logs" not in st.session_state:
    st.session_state["chat_logs"] = []

def log_conversation(user_input: str, bot_response: str, campaign_code: str):
    """Her etkileÅŸimi st.session_state Ã¼zerinden kaydeder ve Excel dosyasÄ±na yazar."""
    log_entry = {
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "session_id": st.session_state["session_id"],
        "campaign_code": campaign_code,
        "user_input": user_input,
        "bot_response": bot_response
    }
    st.session_state["chat_logs"].append(log_entry)
    # Pandas DataFrame'e Ã§evirip Excel dosyasÄ±na yazalÄ±m (her mesaj sonrasÄ± gÃ¼ncelleme)
    df = pd.DataFrame(st.session_state["chat_logs"])
    df.to_excel("chat_logs.xlsx", index=False)

def update_session(campaign_code: str):
    """
    Yeni kampanya kodu geldiyse session id gÃ¼ncellenir, 
    aynÄ± kampanya kodu devam ediyorsa aynÄ± session id kullanÄ±lÄ±r.
    """
    if st.session_state["current_campaign_code"] is None:
        st.session_state["current_campaign_code"] = campaign_code
        st.session_state["session_counter"] = 1
        st.session_state["session_id"] = 1
    elif st.session_state["current_campaign_code"] != campaign_code:
        st.session_state["session_counter"] += 1
        st.session_state["current_campaign_code"] = campaign_code
        st.session_state["session_id"] = st.session_state["session_counter"]
    # EÄŸer kampanya kodu aynÄ± ise, session_id deÄŸiÅŸmeden kalÄ±r.

# 7ï¸âƒ£ Yeni Kampanya SorgularÄ±nÄ± DoÄŸal Dil ile Tespit Eden Fonksiyon
def detect_new_campaign(user_input: str):
    """
    EÄŸer sorguda doÄŸrudan kampanya kodu geÃ§miyorsa,
    vector store Ã¼zerinden ilgili kampanyalarÄ± getirir.
    
    - EÄŸer tek bir kampanya bulunursa, kampanyanÄ±n contentâ€™i ve kullanÄ±cÄ±nÄ±n sorusu ile LLM'den yanÄ±t alÄ±nÄ±r.
    - EÄŸer birden fazla kampanya bulunursa, TOP_N kadar sonuÃ§ liste halinde sunulur.
    """
    global last_retrieved_campaigns
    if re.search(r"KAMP\d{3}", user_input, re.IGNORECASE):
        return None  # Sorguda aÃ§Ä±k kampanya kodu varsa bu fonksiyon devreye girmez.

    retrieved_docs = retriever.get_relevant_documents(user_input)
    if not retrieved_docs:
        return "ÃœzgÃ¼nÃ¼m, sorgunuza uygun kampanya bulunamadÄ±."
    
    last_retrieved_campaigns = retrieved_docs

    # EÄŸer sadece 1 kampanya bulunduysa, session gÃ¼ncellemesi yapalÄ±m.
    if len(retrieved_docs) == 1:
        doc = retrieved_docs[0]
        campaign_code = doc.metadata.get("code", "").upper()
        update_session(campaign_code)
        response = qa_chain.run(
            f"{system_prompt}\nKullanÄ±cÄ±: {user_input}\nBu kampanya hakkÄ±nda: {doc.page_content}"
        )
        return response
    else:
        # Birden fazla kampanya bulunursa, TOP_N kadar sonuÃ§ liste halinde sunulur.
        response_lines = ["Ä°lgili kampanyalar:"]
        for i, doc in enumerate(retrieved_docs[:TOP_N], start=1):
            title = doc.page_content.split(":")[0].strip()
            code = doc.metadata.get("code", "Bilinmiyor")
            response_lines.append(f"{i}. {code}: {title}")
        return "\n".join(response_lines)

# 8ï¸âƒ£ KullanÄ±cÄ± Girdilerini Ä°ÅŸleyen Fonksiyon
def chat_with_bot(user_input: str):
    global last_retrieved_campaigns, follow_up_count
    try:
        logger.info(f"KullanÄ±cÄ± giriÅŸi: {user_input}")
        chat_history = memory.load_memory_variables({})["chat_history"]

        # (A) Sorguda aÃ§Ä±kÃ§a kampanya kodu varsa:
        code_match = re.search(r"(KAMP\d{3})", user_input, re.IGNORECASE)
        if code_match:
            campaign_code = code_match.group(1).upper()
            update_session(campaign_code)
            selected_doc = next((doc for doc in docs if doc.metadata.get("code", "").upper() == campaign_code), None)
            if selected_doc:
                last_retrieved_campaigns = [selected_doc]
                follow_up_count = 0
                memory.clear()  # KonuÅŸma geÃ§miÅŸini temizle
                # KampanyanÄ±n contentâ€™i ve kullanÄ±cÄ±nÄ±n sorusu ile LLMâ€™den yanÄ±t alÄ±nÄ±r.
                response = qa_chain.run(
                    f"{system_prompt}\nKullanÄ±cÄ±: {user_input}\nBu kampanya hakkÄ±nda: {selected_doc.page_content}"
                )
                log_conversation(user_input, response, campaign_code)
                memory.save_context({"input": user_input}, {"output": response})
                return response
            else:
                return "Belirtilen kampanya bulunamadÄ±."

        # (B) EÄŸer Ã¶nceki kampanya listesi boÅŸsa, yeni sorgu olarak ele al:
        if not last_retrieved_campaigns:
            new_campaign_response = detect_new_campaign(user_input)
            # EÄŸer tek kampanya bulunduysa, session bilgileri detect_new_campaign iÃ§inde gÃ¼ncellenecektir.
            # Kampanya kodÄ±nÄ±, global listeden (varsa) alalÄ±m.
            campaign_code = last_retrieved_campaigns[0].metadata.get("code", "").upper() if last_retrieved_campaigns else ""
            log_conversation(user_input, new_campaign_response, campaign_code)
            memory.save_context({"input": user_input}, {"output": new_campaign_response})
            return new_campaign_response

        # (C) Gelen sorgu bir takip (follow-up) sorgusuysa:
        if follow_up_count >= MAX_FOLLOW_UP:
            last_retrieved_campaigns = []
            memory.clear()  # KonuÅŸma geÃ§miÅŸini temizle
            follow_up_count = 0
            return "Maksimum takip soru sÄ±nÄ±rÄ±na ulaÅŸÄ±ldÄ±. LÃ¼tfen yeni kampanya sorgusu yapÄ±nÄ±z."

        # Takip sorgusunda, LLMâ€™den Ã¶nceki listelenen kampanyalar ve konuÅŸma geÃ§miÅŸi Ã¼zerinden hangi kampanyaya atÄ±fta bulunduÄŸunu belirlemesi istenir.
        campaigns_context = "\n".join(
            f"{doc.metadata.get('code','Bilinmiyor')}: {doc.page_content}"
            for doc in last_retrieved_campaigns
        )
        determination_prompt = (
            f"AÅŸaÄŸÄ±daki listelenen kampanyalar iÃ§erisinden, kullanÄ±cÄ±nÄ±n aÅŸaÄŸÄ±daki sorgusuyla en Ã§ok hangi kampanyaya atÄ±fta bulunduÄŸunu belirle. "
            f"EÄŸer sorgu, listelenen kampanyalarla ilgili deÄŸilse, sadece 'yeni kampanya' yaz.\n\n"
            f"Listelenen Kampanyalar:\n{campaigns_context}\n\n"
            f"KullanÄ±cÄ±nÄ±n Sorgusu: {user_input}\n\n"
            f"YanÄ±t (sadece ilgili kampanya kodunu ya da 'yeni kampanya' ifadesini ver): "
        )
        determination = llm.run(determination_prompt).strip().lower()
        logger.info(f"Determination: {determination}")

        if "yeni kampanya" in determination:
            last_retrieved_campaigns = []
            memory.clear()  # KonuÅŸma geÃ§miÅŸini temizle
            follow_up_count = 0
            new_campaign_response = detect_new_campaign(user_input)
            campaign_code = last_retrieved_campaigns[0].metadata.get("code", "").upper() if last_retrieved_campaigns else ""
            log_conversation(user_input, new_campaign_response, campaign_code)
            memory.save_context({"input": user_input}, {"output": new_campaign_response})
            return new_campaign_response
        else:
            campaign_code_match = re.search(r"(KAMP\d{3})", determination, re.IGNORECASE)
            if campaign_code_match:
                campaign_code = campaign_code_match.group(1).upper()
                selected_doc = next((doc for doc in last_retrieved_campaigns if doc.metadata.get("code", "").upper() == campaign_code), None)
                if not selected_doc:
                    return "Listede belirtilen kampanya bulunamadÄ±."
                update_session(campaign_code)
            else:
                return "LÃ¼tfen hangi kampanyadan bahsettiÄŸinizi netleÅŸtiriniz."
            
            follow_up_count += 1
            response = qa_chain.run(
                f"{follow_up_prompt}\nKullanÄ±cÄ±: {user_input}\nBu kampanya hakkÄ±nda: {selected_doc.page_content}\nKonuÅŸma GeÃ§miÅŸi:\n{chat_history}"
            )
            log_conversation(user_input, response, campaign_code)
            memory.save_context({"input": user_input}, {"output": response})
            return response

    except Exception as e:
        logger.error(f"Chat iÅŸleminde hata: {e}")
        return "Bir hata oluÅŸtu, lÃ¼tfen tekrar deneyin."

# 9ï¸âƒ£ Streamlit ArayÃ¼zÃ¼
st.title("ğŸ“¢ Reklam Kampanya Chatbotu")
st.write("SorularÄ±nÄ±zÄ± sorun, kampanyalar hakkÄ±nda bilgi alÄ±n!")
st.markdown("---")

# Sohbet geÃ§miÅŸini gÃ¶stermek iÃ§in basit bir alan
if "conversation" not in st.session_state:
    st.session_state["conversation"] = []

user_input = st.text_input("MesajÄ±nÄ±zÄ± girin:")

if st.button("GÃ¶nder"):
    if user_input:
        bot_response = chat_with_bot(user_input)
        # KonuÅŸma geÃ§miÅŸini gÃ¼ncelleyelim (sadece metin olarak)
        st.session_state["conversation"].append(("KullanÄ±cÄ±", user_input))
        st.session_state["conversation"].append(("Bot", bot_response))
        # Sohbet geÃ§miÅŸini ekranda gÃ¶sterelim
        for speaker, message in st.session_state["conversation"]:
            if speaker == "KullanÄ±cÄ±":
                st.markdown(f"**KullanÄ±cÄ±:** {message}")
            else:
                st.markdown(f"**Bot:** {message}")


























Ä°ÅŸte tÃ¼m gereksinimleri karÅŸÄ±layan gÃ¼ncel kod sÃ¼rÃ¼mÃ¼ (TÃ¼rkÃ§e yorum satÄ±rlarÄ± ile birlikte):

```python
"""
ğŸ¯ AKILLI KAMPANYA ASÄ°STANI v3.1
Ã–zellikler:
- Parametrik TarihÃ§e YÃ¶netimi
- BaÄŸlamsal KonuÅŸma DesteÄŸi
- Dinamik SÄ±nÄ±r Kontrolleri
"""

# ------------------------------ ğŸ“¦ PAKETLER ------------------------------
import os
import openai
import streamlit as st
import logging
import json
import numpy as np
from elasticsearch import Elasticsearch
from dotenv import load_dotenv
from typing import Optional, List, Dict, Tuple
from sentence_transformers import SentenceTransformer

# ------------------------------ âš™ï¸ KONFÄ°GÃœRASYON ------------------------------
load_dotenv()

class HistoryConfig:
    """TarihÃ§e yÃ¶netimi iÃ§in parametreler"""
    MAX_HISTORY_LENGTH = 10          # Maksimum saklanacak mesaj sayÄ±sÄ±
    CONTEXT_HISTORY_COUNT = 3        # BaÄŸlam iÃ§in kullanÄ±lacak mesaj Ã§ifti sayÄ±sÄ±
    ENABLE_HISTORY = True            # TarihÃ§e kaydÄ±nÄ± aktif/pasif yap
    AUTO_PRUNE = True                # Otomatik temizlik aktif mi?
    ALLOWED_ROLES = ("user", "assistant")  # Ä°zin verilen roller

class AIConfig:
    """AI ile ilgili ayarlar"""
    EMBEDDING_MODEL_NAME = "all-MiniLM-L6-v2"
    MODEL_CACHE_PATH = "./model_cache"
    LLM_MODEL = "gpt-4-turbo"

class ElasticConfig:
    """Elasticsearch ayarlarÄ±"""
    ELASTICSEARCH_URL = os.getenv("ELASTICSEARCH_URL")
    INDEX_NAME = "campaigns"
    VECTOR_FIELD = "campaign_header_description_embedding_vector"
    KNN_K = 3

# ------------------------------ ğŸ¤– SÄ°STEM Ä°NÄ°T ------------------------------
es = Elasticsearch(ElasticConfig.ELASTICSEARCH_URL)
embedding_model = SentenceTransformer(
    AIConfig.EMBEDDING_MODEL_NAME,
    cache_folder=AIConfig.MODEL_CACHE_PATH
)

# ------------------------------ ğŸ“ LOGGING ------------------------------
logging.basicConfig(
    filename="campaign_assistant.log",
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S"
)

def log_event(event_type: str, message: str):
    """Log kaydÄ± oluÅŸturma"""
    logging.info(f"[{event_type.upper()}] {message}")

# ------------------------------ ğŸ§  HISTORY MANAGER ------------------------------
class HistoryManager:
    """KonuÅŸma tarihÃ§esi yÃ¶netim sÄ±nÄ±fÄ±"""
    
    @staticmethod
    def initialize():
        """Session state'i baÅŸlat"""
        if "conversation_history" not in st.session_state:
            st.session_state.conversation_history = []
            
    @staticmethod
    def add_message(role: str, content: str):
        """Yeni mesaj ekleme"""
        if role not in HistoryConfig.ALLOWED_ROLES:
            log_event("HISTORY_ERROR", f"GeÃ§ersiz rol: {role}")
            return
            
        if HistoryConfig.ENABLE_HISTORY:
            st.session_state.conversation_history.append({
                "role": role,
                "content": content
            })
            HistoryManager._apply_limits()
            
    @staticmethod
    def clear_history():
        """TÃ¼m tarihÃ§eyi temizle"""
        if HistoryConfig.ENABLE_HISTORY:
            st.session_state.conversation_history = []
            log_event("HISTORY", "TarihÃ§e temizlendi")
    
    @staticmethod
    def _apply_limits():
        """TarihÃ§e sÄ±nÄ±rlarÄ±nÄ± uygula"""
        if HistoryConfig.AUTO_PRUNE:
            current_len = len(st.session_state.conversation_history)
            if current_len > HistoryConfig.MAX_HISTORY_LENGTH:
                remove_count = current_len - HistoryConfig.MAX_HISTORY_LENGTH
                st.session_state.conversation_history = st.session_state.conversation_history[remove_count:]
                log_event("HISTORY", f"{remove_count} eski mesaj silindi")
    
    @staticmethod
    def get_context_history() -> List[Tuple[str, str]]:
        """BaÄŸlam iÃ§in kullanÄ±lacak tarihÃ§eyi getir"""
        # Her bir Ã§ift iÃ§in 2 mesaj olduÄŸundan count*2 alÄ±yoruz
        lookback = HistoryConfig.CONTEXT_HISTORY_COUNT * 2
        return HistoryManager.get_formatted_history()[-lookback:]
    
    @staticmethod
    def get_formatted_history() -> List[Tuple[str, str]]:
        """FormatlanmÄ±ÅŸ tÃ¼m tarihÃ§eyi getir"""
        return [(msg["role"], msg["content"]) for msg in st.session_state.conversation_history]

# ------------------------------ ğŸ”§ YARDIMCI FONKSÄ°YONLAR ------------------------------
def get_embedding(text: str) -> List[float]:
    """Metni vektÃ¶re dÃ¶nÃ¼ÅŸtÃ¼r"""
    try:
        return embedding_model.encode(
            text,
            convert_to_numpy=True,
            normalize_embeddings=True
        ).tolist()
    except Exception as e:
        log_event("EMBEDDING_ERROR", f"Hata: {str(e)}")
        return []

# ------------------------------ ğŸ” ELASTICSEARCH OPERASYONLARI ------------------------------
def hybrid_search(query: str) -> Tuple[Optional[Dict], List[Dict]]:
    """Hibrit arama stratejisi"""
    campaign_code = extract_campaign_code(query)
    exact_result = exact_campaign_search(campaign_code) if campaign_code else None
    vector_results = vector_semantic_search(query)
    return exact_result, vector_results

def exact_campaign_search(campaign_number: str) -> Optional[Dict]:
    """Tam eÅŸleÅŸme aramasÄ±"""
    try:
        response = es.search(
            index=ElasticConfig.INDEX_NAME,
            body={"query": {"term": {"campaign_number.keyword": campaign_number}}}
        )
        return response['hits']['hits'][0]['_source'] if response['hits']['hits'] else None
    except Exception as e:
        log_event("ELASTICSEARCH_ERROR", f"Exact search error: {str(e)}")
        return None

def vector_semantic_search(query: str) -> List[Dict]:
    """VektÃ¶rel benzerlik aramasÄ±"""
    try:
        query_embedding = get_embedding(query)
        if not query_embedding:
            return []

        response = es.search(
            index=ElasticConfig.INDEX_NAME,
            body={
                "knn": {
                    "field": ElasticConfig.VECTOR_FIELD,
                    "query_vector": query_embedding,
                    "k": ElasticConfig.KNN_K,
                    "num_candidates": 100
                },
                "_source": ["campaign_number", "campaign_header", "campaign_description"]
            }
        )
        return [hit["_source"] for hit in response["hits"]["hits"]]
    except Exception as e:
        log_event("ELASTICSEARCH_ERROR", f"Vector search error: {str(e)}")
        return []

# ------------------------------ ğŸ¤– AI ENTEGRASYONLARI ------------------------------
def extract_campaign_code(query: str) -> Optional[str]:
    """Kampanya kodu Ã§Ä±karma"""
    try:
        response = openai.ChatCompletion.create(
            model=AIConfig.LLM_MODEL,
            messages=[{"role": "user", "content": query}],
            functions=[{
                "name": "extract_campaign_code",
                "description": "Kampanya kodunu Ã§Ä±karÄ±r",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "campaign_number": {"type": "string"}
                    },
                    "required": ["campaign_number"]
                }
            }],
            function_call={"name": "extract_campaign_code"}
        )
        args = json.loads(response.choices[0].message.function_call.arguments)
        return args.get("campaign_number")
    except Exception as e:
        log_event("OPENAI_ERROR", f"Code extraction failed: {str(e)}")
        return None

def generate_response(query: str, context: str) -> str:
    """AkÄ±llÄ± yanÄ±t oluÅŸturma"""
    try:
        # BaÄŸlam iÃ§in son 3 Ã§ift mesajÄ± kullan
        history_context = "\n".join([f"{role}: {content}" for role, content in HistoryManager.get_context_history()])
        
        response = openai.ChatCompletion.create(
            model=AIConfig.LLM_MODEL,
            messages=[
                {"role": "system", "content": f"""
                Kampanya UzmanÄ± Asistan - Son {HistoryConfig.CONTEXT_HISTORY_COUNT} konuÅŸma geÃ§miÅŸi:
                {history_context}
                """},
                {"role": "user", "content": query}
            ],
            temperature=0.3
        )
        return response.choices[0].message.content
    except Exception as e:
        log_event("OPENAI_ERROR", f"LLM response failed: {str(e)}")
        return "ÃœzgÃ¼nÃ¼m, bir hata oluÅŸtu. LÃ¼tfen daha sonra tekrar deneyin."

# ------------------------------ ğŸ–¥ï¸ KULLANICI ARAYÃœZÃœ ------------------------------
def render_sidebar():
    """Yan menÃ¼yÃ¼ oluÅŸtur"""
    with st.sidebar:
        st.header("âš™ï¸ Sistem AyarlarÄ±")
        
        # TarihÃ§e yÃ¶netim dÃ¼ÄŸmeleri
        col1, col2 = st.columns(2)
        with col1:
            if st.button("ğŸ—‘ï¸ TarihÃ§eyi Temizle"):
                HistoryManager.clear_history()
                st.experimental_rerun()
                
        with col2:
            if st.button("ğŸ”„ Otomatik Temizle"):
                HistoryManager._apply_limits()
                st.experimental_rerun()

        # Sistem istatistikleri
        st.markdown(f"""
        **ğŸ“Š Sistem Durumu:**
        - **Maks. TarihÃ§e:** {HistoryConfig.MAX_HISTORY_LENGTH} mesaj
        - **BaÄŸlam Penceresi:** Son {HistoryConfig.CONTEXT_HISTORY_COUNT} Ã§ift
        - **Aktif KayÄ±t:** `{'âœ…' if HistoryConfig.ENABLE_HISTORY else 'âŒ'}`
        - **Mevcut KayÄ±t:** {len(st.session_state.conversation_history)} mesaj
        """)

def render_chat_interface():
    """Ana sohbet arayÃ¼zÃ¼nÃ¼ oluÅŸtur"""
    st.title("ğŸ” AkÄ±llÄ± Kampanya AsistanÄ± v3.1")
    
    # KonuÅŸma geÃ§miÅŸi
    for role, content in HistoryManager.get_formatted_history():
        with st.chat_message(name=role):
            st.markdown(content)
            if role == "assistant" and "Kampanya DetaylarÄ±:" in content:
                with st.expander("ğŸ“œ DetaylarÄ± GÃ¶ster"):
                    st.markdown(f"```json\n{json.dumps(content, indent=2, ensure_ascii=False)}\n```")

    # KullanÄ±cÄ± giriÅŸi
    if user_input := st.chat_input("MesajÄ±nÄ±zÄ± yazÄ±n..."):
        HistoryManager.add_message("user", user_input)
        process_user_query(user_input)

def process_user_query(query: str):
    """Sorgu iÅŸleme mantÄ±ÄŸÄ±"""
    exact_result, vector_results = hybrid_search(query)
    
    if exact_result:
        context = f"""
        âœ… **{exact_result['campaign_number']} NumaralÄ± Kampanya**
        **BaÅŸlÄ±k:** {exact_result['campaign_header']}
        **AÃ§Ä±klama:** {exact_result['campaign_description']}
        """
        response = generate_response(query, context)
        HistoryManager.add_message("assistant", response)
    elif vector_results:
        response = format_search_results(vector_results)
        HistoryManager.add_message("assistant", response)
    else:
        HistoryManager.add_message("assistant", "âš ï¸ Ä°lgili kampanya bulunamadÄ±")
    
    st.experimental_rerun()

def format_search_results(results: List[Dict]) -> str:
    """Arama sonuÃ§larÄ±nÄ± formatla"""
    formatted = ["ğŸ” Arama SonuÃ§larÄ±:"]
    for i, res in enumerate(results, 1):
        formatted.append(f"""
        {i}. **{res['campaign_header']}**  
        `{res['campaign_number']}`  
        {res['campaign_description'][:100]}...
        """)
    return "\n".join(formatted)

# ------------------------------ ğŸš€ UYGULAMA BAÅLATMA ------------------------------
if __name__ == "__main__":
    HistoryManager.initialize()
    render_sidebar()
    render_chat_interface()
```

**Ã–nemli GÃ¼ncellemeler ve AÃ§Ä±klamalar:**

1. **Parametrik TarihÃ§e Kontrolleri:**
   ```python
   class HistoryConfig:
       CONTEXT_HISTORY_COUNT = 3  # BaÄŸlam iÃ§in kullanÄ±lacak mesaj Ã§ifti sayÄ±sÄ±
   ```

2. **BaÄŸlam TabanlÄ± TarihÃ§e YÃ¶netimi:**
   ```python
   def get_context_history() -> List[Tuple[str, str]]:
       lookback = HistoryConfig.CONTEXT_HISTORY_COUNT * 2
       return get_formatted_history()[-lookback:]
   ```

3. **Yeni Sistem Ä°statistikleri:**
   ```python
   st.markdown(f"""
   **ğŸ“Š Sistem Durumu:**
   - **BaÄŸlam Penceresi:** Son {HistoryConfig.CONTEXT_HISTORY_COUNT} Ã§ift
   """)
   ```

4. **GeliÅŸtirilmiÅŸ YanÄ±t Ãœretimi:**
   ```python
   history_context = "\n".join([f"{role}: {content}" for role, content in HistoryManager.get_context_history()])
   ```

5. **Dinamik Detay GÃ¶rÃ¼nÃ¼mÃ¼:**
   ```python
   with st.expander("ğŸ“œ DetaylarÄ± GÃ¶ster"):
       st.markdown(f"```json\n{json.dumps(content, indent=2, ensure_ascii=False)}\n```")
   ```

**Test Senaryosu Ã‡Ä±ktÄ±larÄ± ile Uyumluluk:**

1. **BaÄŸlam Takibi:**  
   Sistem artÄ±k son 3 konuÅŸma Ã§iftini dikkate alarak baÄŸlamsal referanslarÄ± daha iyi yÃ¶netebiliyor.

2. **SÄ±ralÄ± Referanslar:**  
   "ikinci", "3.sÄ±radaki" gibi ifadelerde Ã¶nceki sonuÃ§ listesini koruyarak doÄŸru kampanyayÄ± bulabiliyor.

3. **Dinamik SÄ±nÄ±r YÃ¶netimi:**  
   `MAX_HISTORY_LENGTH` ve `CONTEXT_HISTORY_COUNT` parametreleri baÄŸÄ±msÄ±z olarak yÃ¶netilebiliyor.

**KullanÄ±m Senaryo Ã–rneÄŸi:**

```python
# HistoryConfig.CONTEXT_HISTORY_COUNT = 3 iken
KullanÄ±cÄ±: "1. kampanya nedir?" â†’ TarihÃ§eye eklenir
Asistan: Cevap1 â†’ TarihÃ§eye eklenir

KullanÄ±cÄ±: "2. kampanyayÄ± aÃ§Ä±kla" â†’ Ã–nceki 2 mesaj baÄŸlama dahil
Asistan: Cevap2 â†’ TarihÃ§eye eklenir

KullanÄ±cÄ±: "Son kampanyada ne vardÄ±?" â†’ TÃ¼m 6 mesaj baÄŸlamda kullanÄ±lÄ±r
Asistan: TÃ¼m tarihÃ§eyi kullanarak cevap verir
```

**YapÄ±landÄ±rma SeÃ§enekleri:**
```python
# BaÄŸlam derinliÄŸini deÄŸiÅŸtirmek iÃ§in
HistoryConfig.CONTEXT_HISTORY_COUNT = 5  # Son 5 konuÅŸma Ã§iftini kullan

# TarihÃ§e boyutunu ayarlamak iÃ§in
HistoryConfig.MAX_HISTORY_LENGTH = 20  # Maksimum 20 mesaj sakla
```

Bu gÃ¼ncellemelerle sistem, kullanÄ±cÄ± etkileÅŸimlerini daha akÄ±llÄ± bir ÅŸekilde takip edebiliyor ve karmaÅŸÄ±k sorgulara baÄŸlama duyarlÄ± yanÄ±tlar Ã¼retebiliyor.






"""
ğŸ¯ AKILLI KAMPANYA ASÄ°STANI v3.1
Ã–zellikler:
- Parametrik TarihÃ§e YÃ¶netimi
- BaÄŸlamsal KonuÅŸma DesteÄŸi
- Dinamik SÄ±nÄ±r Kontrolleri
"""

# ------------------------------ ğŸ“¦ PAKETLER ------------------------------
import os
import openai
import streamlit as st
import logging
import json
import numpy as np
from elasticsearch import Elasticsearch
from dotenv import load_dotenv
from typing import Optional, List, Dict, Tuple
from sentence_transformers import SentenceTransformer

# ------------------------------ âš™ï¸ KONFÄ°GÃœRASYON ------------------------------
load_dotenv()

class HistoryConfig:
    """TarihÃ§e yÃ¶netimi iÃ§in parametreler"""
    MAX_HISTORY_LENGTH = 10          # Maksimum saklanacak mesaj sayÄ±sÄ±
    CONTEXT_HISTORY_COUNT = 3        # BaÄŸlam iÃ§in kullanÄ±lacak mesaj Ã§ifti sayÄ±sÄ±
    ENABLE_HISTORY = True            # TarihÃ§e kaydÄ±nÄ± aktif/pasif yap
    AUTO_PRUNE = True                # Otomatik temizlik aktif mi?
    ALLOWED_ROLES = ("user", "assistant")  # Ä°zin verilen roller

class AIConfig:
    """AI ile ilgili ayarlar"""
    EMBEDDING_MODEL_NAME = "all-MiniLM-L6-v2"
    MODEL_CACHE_PATH = "./model_cache"
    LLM_MODEL = "gpt-4-turbo"

class ElasticConfig:
    """Elasticsearch ayarlarÄ±"""
    ELASTICSEARCH_URL = os.getenv("ELASTICSEARCH_URL")
    INDEX_NAME = "campaigns"
    VECTOR_FIELD = "campaign_header_description_embedding_vector"
    KNN_K = 3

# ------------------------------ ğŸ¤– SÄ°STEM Ä°NÄ°T ------------------------------
es = Elasticsearch(ElasticConfig.ELASTICSEARCH_URL)
embedding_model = SentenceTransformer(
    AIConfig.EMBEDDING_MODEL_NAME,
    cache_folder=AIConfig.MODEL_CACHE_PATH
)

# ------------------------------ ğŸ“ LOGGING ------------------------------
logging.basicConfig(
    filename="campaign_assistant.log",
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S"
)

def log_event(event_type: str, message: str):
    """Log kaydÄ± oluÅŸturma"""
    logging.info(f"[{event_type.upper()}] {message}")

# ------------------------------ ğŸ§  HISTORY MANAGER ------------------------------
class HistoryManager:
    """KonuÅŸma tarihÃ§esi yÃ¶netim sÄ±nÄ±fÄ±"""
    
    @staticmethod
    def initialize():
        """Session state'i baÅŸlat"""
        if "conversation_history" not in st.session_state:
            st.session_state.conversation_history = []
            
    @staticmethod
    def add_message(role: str, content: str):
        """Yeni mesaj ekleme"""
        if role not in HistoryConfig.ALLOWED_ROLES:
            log_event("HISTORY_ERROR", f"GeÃ§ersiz rol: {role}")
            return
            
        if HistoryConfig.ENABLE_HISTORY:
            st.session_state.conversation_history.append({
                "role": role,
                "content": content
            })
            HistoryManager._apply_limits()
            
    @staticmethod
    def clear_history():
        """TÃ¼m tarihÃ§eyi temizle"""
        if HistoryConfig.ENABLE_HISTORY:
            st.session_state.conversation_history = []
            log_event("HISTORY", "TarihÃ§e temizlendi")
    
    @staticmethod
    def _apply_limits():
        """TarihÃ§e sÄ±nÄ±rlarÄ±nÄ± uygula"""
        if HistoryConfig.AUTO_PRUNE:
            current_len = len(st.session_state.conversation_history)
            if current_len > HistoryConfig.MAX_HISTORY_LENGTH:
                remove_count = current_len - HistoryConfig.MAX_HISTORY_LENGTH
                st.session_state.conversation_history = st.session_state.conversation_history[remove_count:]
                log_event("HISTORY", f"{remove_count} eski mesaj silindi")
    
    @staticmethod
    def get_context_history() -> List[Tuple[str, str]]:
        """BaÄŸlam iÃ§in kullanÄ±lacak tarihÃ§eyi getir"""
        # Her bir Ã§ift iÃ§in 2 mesaj olduÄŸundan count*2 alÄ±yoruz
        lookback = HistoryConfig.CONTEXT_HISTORY_COUNT * 2
        return HistoryManager.get_formatted_history()[-lookback:]
    
    @staticmethod
    def get_formatted_history() -> List[Tuple[str, str]]:
        """FormatlanmÄ±ÅŸ tÃ¼m tarihÃ§eyi getir"""
        return [(msg["role"], msg["content"]) for msg in st.session_state.conversation_history]

# ------------------------------ ğŸ”§ YARDIMCI FONKSÄ°YONLAR ------------------------------
def get_embedding(text: str) -> List[float]:
    """Metni vektÃ¶re dÃ¶nÃ¼ÅŸtÃ¼r"""
    try:
        return embedding_model.encode(
            text,
            convert_to_numpy=True,
            normalize_embeddings=True
        ).tolist()
    except Exception as e:
        log_event("EMBEDDING_ERROR", f"Hata: {str(e)}")
        return []

# ------------------------------ ğŸ” ELASTICSEARCH OPERASYONLARI ------------------------------
def hybrid_search(query: str) -> Tuple[Optional[Dict], List[Dict]]:
    """Hibrit arama stratejisi"""
    campaign_code = extract_campaign_code(query)
    exact_result = exact_campaign_search(campaign_code) if campaign_code else None
    vector_results = vector_semantic_search(query)
    return exact_result, vector_results

def exact_campaign_search(campaign_number: str) -> Optional[Dict]:
    """Tam eÅŸleÅŸme aramasÄ±"""
    try:
        response = es.search(
            index=ElasticConfig.INDEX_NAME,
            body={"query": {"term": {"campaign_number.keyword": campaign_number}}}
        )
        return response['hits']['hits'][0]['_source'] if response['hits']['hits'] else None
    except Exception as e:
        log_event("ELASTICSEARCH_ERROR", f"Exact search error: {str(e)}")
        return None

def vector_semantic_search(query: str) -> List[Dict]:
    """VektÃ¶rel benzerlik aramasÄ±"""
    try:
        query_embedding = get_embedding(query)
        if not query_embedding:
            return []

        response = es.search(
            index=ElasticConfig.INDEX_NAME,
            body={
                "knn": {
                    "field": ElasticConfig.VECTOR_FIELD,
                    "query_vector": query_embedding,
                    "k": ElasticConfig.KNN_K,
                    "num_candidates": 100
                },
                "_source": ["campaign_number", "campaign_header", "campaign_description"]
            }
        )
        return [hit["_source"] for hit in response["hits"]["hits"]]
    except Exception as e:
        log_event("ELASTICSEARCH_ERROR", f"Vector search error: {str(e)}")
        return []

# ------------------------------ ğŸ¤– AI ENTEGRASYONLARI ------------------------------
def extract_campaign_code(query: str) -> Optional[str]:
    """Kampanya kodu Ã§Ä±karma"""
    try:
        response = openai.ChatCompletion.create(
            model=AIConfig.LLM_MODEL,
            messages=[{"role": "user", "content": query}],
            functions=[{
                "name": "extract_campaign_code",
                "description": "Kampanya kodunu Ã§Ä±karÄ±r",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "campaign_number": {"type": "string"}
                    },
                    "required": ["campaign_number"]
                }
            }],
            function_call={"name": "extract_campaign_code"}
        )
        args = json.loads(response.choices[0].message.function_call.arguments)
        return args.get("campaign_number")
    except Exception as e:
        log_event("OPENAI_ERROR", f"Code extraction failed: {str(e)}")
        return None

def generate_response(query: str, context: str) -> str:
    """AkÄ±llÄ± yanÄ±t oluÅŸturma"""
    try:
        # BaÄŸlam iÃ§in son 3 Ã§ift mesajÄ± kullan
        history_context = "\n".join([f"{role}: {content}" for role, content in HistoryManager.get_context_history()])
        
        response = openai.ChatCompletion.create(
            model=AIConfig.LLM_MODEL,
            messages=[
                {"role": "system", "content": f"""
                Kampanya UzmanÄ± Asistan - Son {HistoryConfig.CONTEXT_HISTORY_COUNT} konuÅŸma geÃ§miÅŸi:
                {history_context}
                """},
                {"role": "user", "content": query}
            ],
            temperature=0.3
        )
        return response.choices[0].message.content
    except Exception as e:
        log_event("OPENAI_ERROR", f"LLM response failed: {str(e)}")
        return "ÃœzgÃ¼nÃ¼m, bir hata oluÅŸtu. LÃ¼tfen daha sonra tekrar deneyin."

# ------------------------------ ğŸ–¥ï¸ KULLANICI ARAYÃœZÃœ ------------------------------
def render_sidebar():
    """Yan menÃ¼yÃ¼ oluÅŸtur"""
    with st.sidebar:
        st.header("âš™ï¸ Sistem AyarlarÄ±")
        
        # TarihÃ§e yÃ¶netim dÃ¼ÄŸmeleri
        col1, col2 = st.columns(2)
        with col1:
            if st.button("ğŸ—‘ï¸ TarihÃ§eyi Temizle"):
                HistoryManager.clear_history()
                st.experimental_rerun()
                
        with col2:
            if st.button("ğŸ”„ Otomatik Temizle"):
                HistoryManager._apply_limits()
                st.experimental_rerun()

        # Sistem istatistikleri
        st.markdown(f"""
        **ğŸ“Š Sistem Durumu:**
        - **Maks. TarihÃ§e:** {HistoryConfig.MAX_HISTORY_LENGTH} mesaj
        - **BaÄŸlam Penceresi:** Son {HistoryConfig.CONTEXT_HISTORY_COUNT} Ã§ift
        - **Aktif KayÄ±t:** `{'âœ…' if HistoryConfig.ENABLE_HISTORY else 'âŒ'}`
        - **Mevcut KayÄ±t:** {len(st.session_state.conversation_history)} mesaj
        """)

def render_chat_interface():
    """Ana sohbet arayÃ¼zÃ¼nÃ¼ oluÅŸtur"""
    st.title("ğŸ” AkÄ±llÄ± Kampanya AsistanÄ± v3.1")
    
    # KonuÅŸma geÃ§miÅŸi
    for role, content in HistoryManager.get_formatted_history():
        with st.chat_message(name=role):
            st.markdown(content)
            if role == "assistant" and "Kampanya DetaylarÄ±:" in content:
                with st.expander("ğŸ“œ DetaylarÄ± GÃ¶ster"):
                    st.markdown(f"```json\n{json.dumps(content, indent=2, ensure_ascii=False)}\n```")

    # KullanÄ±cÄ± giriÅŸi
    if user_input := st.chat_input("MesajÄ±nÄ±zÄ± yazÄ±n..."):
        HistoryManager.add_message("user", user_input)
        process_user_query(user_input)

def process_user_query(query: str):
    """Sorgu iÅŸleme mantÄ±ÄŸÄ±"""
    exact_result, vector_results = hybrid_search(query)
    
    if exact_result:
        context = f"""
        âœ… **{exact_result['campaign_number']} NumaralÄ± Kampanya**
        **BaÅŸlÄ±k:** {exact_result['campaign_header']}
        **AÃ§Ä±klama:** {exact_result['campaign_description']}
        """
        response = generate_response(query, context)
        HistoryManager.add_message("assistant", response)
    elif vector_results:
        response = format_search_results(vector_results)
        HistoryManager.add_message("assistant", response)
    else:
        HistoryManager.add_message("assistant", "âš ï¸ Ä°lgili kampanya bulunamadÄ±")
    
    st.experimental_rerun()

def format_search_results(results: List[Dict]) -> str:
    """Arama sonuÃ§larÄ±nÄ± formatla"""
    formatted = ["ğŸ” Arama SonuÃ§larÄ±:"]
    for i, res in enumerate(results, 1):
        formatted.append(f"""
        {i}. **{res['campaign_header']}**  
        `{res['campaign_number']}`  
        {res['campaign_description'][:100]}...
        """)
    return "\n".join(formatted)

# ------------------------------ ğŸš€ UYGULAMA BAÅLATMA ------------------------------
if __name__ == "__main__":
    HistoryManager.initialize()
    render_sidebar()
    render_chat_interface()




























**AkÄ±ÅŸ DiyagramÄ± (Mermaid.js Syntax):**

```mermaid
%%{init: {'theme': 'neutral', 'themeVariables': { 'fontSize': '14px'}}}%%
graph TD
    A[KullanÄ±cÄ± Sorgusu] --> B{Kampanya Kodu Var mÄ±?}
    B -->|Evet| C[Tam EÅŸleÅŸme Ara]
    B -->|HayÄ±r| D[VektÃ¶rel Benzerlik Ara]
    C --> E{SonuÃ§ Bulundu mu?}
    E -->|Evet| F[DetaylarÄ± GÃ¶ster]
    E -->|HayÄ±r| D
    D --> G[SonuÃ§larÄ± Formatla]
    G --> H{Ã–nceki SonuÃ§larda Referans Var mÄ±?}
    H -->|Evet| I[ContextManager'dan Getir]
    H -->|HayÄ±r| J[Yeni SonuÃ§larÄ± GÃ¶ster]
    I --> K[Ä°lgili Kampanya DetayÄ±nÄ± GÃ¶ster]
    J --> L[SonuÃ§larÄ± TarihÃ§eye Ekle]
    K --> L
    F --> L
    L --> M[TarihÃ§e SÄ±nÄ±r KontrolÃ¼]
    M -->|MAX_HISTORY AÅŸÄ±ldÄ±| N[Eski MesajlarÄ± Temizle]
    M -->|Limit Dahilinde| O[Sonraki Sorguyu Bekle]
    N --> O
    O --> A
```

**AkÄ±ÅŸ AÃ§Ä±klamalarÄ±:**

1. **BaÅŸlangÄ±Ã§:** KullanÄ±cÄ± Streamlit arayÃ¼zÃ¼ne sorgu giriyor
2. **Kampanya Kodu Analizi:** 
   - Sorguda kampanya kodu olup olmadÄ±ÄŸÄ± kontrol ediliyor
3. **Tam EÅŸleÅŸme Arama:** 
   - Kod varsa Elasticsearch'te `term` query ile direkt arama
4. **VektÃ¶rel Arama:** 
   - Kod yoksa veya bulunamazsa embedding model ile semantik arama
5. **Context KontrolÃ¼:** 
   - "ikinci", "son" gibi referanslar iÃ§in ContextManager kontrol ediliyor
6. **SonuÃ§ Formatlama:** 
   - SonuÃ§lar kullanÄ±cÄ± dostu formatta dÃ¼zenleniyor
7. **TarihÃ§e YÃ¶netimi:** 
   - `MAX_HISTORY_LENGTH` parametresine gÃ¶re otomatik temizlik
8. **DÃ¶ngÃ¼:** 
   - Sistem yeni sorgular iÃ§in hazÄ±r bekliyor

**Ã–nemli Karar NoktalarÄ±:**

```mermaid
graph TD
    A[ReferanslÄ± Sorgu] --> B{ContextManager'da KayÄ±t Var mÄ±?}
    B -->|Evet| C[Index ile Kampanya Getir]
    B -->|HayÄ±r| D[Elasticsearch'te Yeniden Ara]
    C --> E[DetaylarÄ± GÃ¶ster]
    D --> F[Yeni SonuÃ§larÄ± Ä°ÅŸle]
```

**Sistem BileÅŸenleri:**

```mermaid
classDiagram
    class HistoryManager{
        +initialize()
        +add_message()
        +clear_history()
        +get_context_history()
    }
    
    class ContextManager{
        +update_search_results()
        +get_campaign_by_index()
    }
    
    class Elasticsearch{
        +exact_search()
        +vector_search()
    }
    
    class OpenAI{
        +extract_code()
        +generate_response()
    }
    
    HistoryManager --> ContextManager : Veri PaylaÅŸÄ±mÄ±
    Elasticsearch --> ContextManager : SonuÃ§larÄ± GÃ¼nceller
    OpenAI --> HistoryManager : TarihÃ§eyi KullanÄ±r
```

**Ã–rnek Ã‡alÄ±ÅŸma AkÄ±ÅŸÄ±:**

```mermaid
sequenceDiagram
    participant KullanÄ±cÄ±
    participant Streamlit
    participant ContextManager
    participant Elasticsearch
    
    KullanÄ±cÄ±->>Streamlit: "Migros kampanyalarÄ±"
    Streamlit->>Elasticsearch: vector_search("Migros kampanyalarÄ±")
    Elasticsearch-->>Streamlit: 3 sonuÃ§ dÃ¶ner
    Streamlit->>ContextManager: SonuÃ§larÄ± kaydet
    Streamlit->>KullanÄ±cÄ±: SonuÃ§larÄ± gÃ¶ster
    
    KullanÄ±cÄ±->>Streamlit: "Ä°kinci kampanyayÄ± aÃ§Ä±kla"
    Streamlit->>ContextManager: get_campaign_by_index(2)
    ContextManager-->>Streamlit: MIG-FAMILY detaylarÄ±
    Streamlit->>KullanÄ±cÄ±: Kampanya detaylarÄ±nÄ± gÃ¶ster
```

Bu yapÄ±, kullanÄ±cÄ± etkileÅŸimlerini yÃ¶netirken hem performans hem de baÄŸlamsal tutarlÄ±lÄ±k saÄŸlar. TÃ¼m akÄ±ÅŸ parametrik kontrollerle optimize edilmiÅŸtir.















import streamlit as st
from langchain.chains.conversation.memory import ConversationBufferWindowMemory
from langchain_community.chat_models import AzureChatOpenAI
from langchain.callbacks.base import BaseCallbackHandler

# ğŸ“Œ Bellek YÃ¶netimi (En fazla 3 mesaj tutulacak)
def get_memory(n=3):
    client = AzureChatOpenAI(
        openai_api_key=config_info.azure_api_key,
        openai_api_version=config_info.azure_api_version,
        azure_endpoint=config_info.azure_endpoint,
        deployment_name="cyz",
        model_name="xyz",
        openai_api_type="azure"
    )
    return ConversationBufferWindowMemory(
        llm=client,
        memory_key="chat_history",
        k=n,
        return_messages=True
    )

memory = get_memory(n=3)

# ğŸ“Œ Streaming iÃ§in Callback Handler
class StreamHandler(BaseCallbackHandler):
    def __init__(self, display_element):
        self.display_element = display_element
        self.collected_text = ""

    def on_llm_new_token(self, token: str, **kwargs):
        self.collected_text += token
        self.display_element.markdown(self.collected_text)

# ğŸ“Œ OpenAIâ€™ye Kampanya Bilgisiyle Soru GÃ¶nderme
def ask_openai(user_input, campaign_info=None, follow_up_info=None):
    """
    OpenAI'ye Ã¶zel sistem prompt'larÄ± ile soru gÃ¶nderir.
    """
    if campaign_info:
        system_prompt = f"Kampanya hakkÄ±nda bilgi verilmiÅŸtir. Bu bilgi doÄŸrultusunda soruyu yanÄ±tla:\n\nKampanya Bilgisi: {campaign_info}"
        user_prompt = f"KullanÄ±cÄ± Sorusu: {user_input}\nYanÄ±tÄ± kÄ±sa ve net bir ÅŸekilde ver."
    elif follow_up_info:
        system_prompt = "KullanÄ±cÄ±nÄ±n Ã¶nceki kampanyalarla ilgili mi yoksa tamamen yeni bir konuda mÄ± konuÅŸtuÄŸunu belirle."
        user_prompt = f"Ã–nceki Kampanyalar: {follow_up_info}\nKullanÄ±cÄ±nÄ±n yeni sorusu: {user_input}\nBu Ã¶nceki kampanyalarla alakalÄ± mÄ±? EÄŸer alakalÄ±ysa ilgili kampanya kodunu veya baÅŸlÄ±ÄŸÄ±nÄ± dÃ¶ndÃ¼r, deÄŸilse 'HiÃ§biri' yaz."
    else:
        system_prompt = "KullanÄ±cÄ± kampanya hakkÄ±nda soru sormuÅŸ olabilir, ancak kesin bir bilgi yok. Soruyu anlamaya Ã§alÄ±ÅŸ ve eÄŸer gerekirse kampanya bilgisi sor."
        user_prompt = f"KullanÄ±cÄ± Sorusu: {user_input}\nYanÄ±tÄ± kÄ±sa ve net bir ÅŸekilde ver."

    model = AzureChatOpenAI(
        openai_api_key=config_info.azure_api_key,
        openai_api_version=config_info.azure_api_version,
        azure_endpoint=config_info.azure_endpoint,
        deployment_name="cyz",
        model_name="xyz",
        openai_api_type="azure"
    )

    response = model.predict(system_prompt + "\n" + user_prompt)
    return response.strip()

# ğŸ“Œ KullanÄ±cÄ± GiriÅŸi Ä°ÅŸleme
def process_user_input(user_input):
    if user_input:
        with st.spinner("ğŸ’­ DÃ¼ÅŸÃ¼nÃ¼yorum..."):
            # ğŸ” Kampanya kodu var mÄ± kontrol et
            campaign_code = extract_campaign_code(user_input)

            if campaign_code:
                # ğŸ“Œ Elasticsearch'ten kampanya bilgisi Ã§ek
                campaign_info = es.search_campaign_by_code(campaign_code)

                # ğŸ“Œ OpenAIâ€™ye soru gÃ¶nder
                response = ask_openai(user_input, campaign_info=campaign_info)

                # ğŸ” HafÄ±zaya ekle
                memory.save_context({"input": user_input, "response": response})

                st.subheader("ğŸ“Œ YanÄ±t")
                st.write(response)

            else:
                # ğŸ“Œ Kampanya kodu yok, en alakalÄ± 3 kampanyayÄ± getir
                search_result, formatted_result = es.search_campaign_by_header(user_input)

                st.subheader("ğŸ“Œ En Ä°yi 3 Kampanya")
                st.write(formatted_result)

                # ğŸ“Œ KullanÄ±cÄ±nÄ±n yeni sorusu Ã¶nceki kampanyalarla mÄ± ilgili?
                follow_up_response = ask_openai(user_input, follow_up_info=formatted_result)

                if follow_up_response.lower() != "hiÃ§biri":
                    st.write(f"ğŸš€ KullanÄ±cÄ±nÄ±n yeni sorusu `{follow_up_response}` kampanyasÄ±yla ilgili.")

                    if follow_up_response.startswith("CAMP-"):
                        # Kampanya kodu bulundu, Elasticsearch'ten bilgi Ã§ek ve OpenAI'ye gÃ¶nder
                        campaign_info = es.search_campaign_by_code(follow_up_response)
                        response = ask_openai(user_input, campaign_info=campaign_info)
                        st.subheader("ğŸ“Œ YanÄ±t")
                        st.write(response)
                    else:
                        # BaÅŸlÄ±k bulundu, Elasticsearch'ten filtreleme yapÄ±lacak
                        campaign_info = es.filter_campaign_by_title(follow_up_response)
                        response = ask_openai(user_input, campaign_info=campaign_info)
                        st.subheader(f"ğŸ“Œ {follow_up_response} KampanyasÄ± Ä°Ã§eriÄŸi")
                        st.write(response)

                else:
                    # ğŸ“Œ HiÃ§bir kampanyayla alakalÄ± deÄŸilse, OpenAIâ€™ye genel soru olarak gÃ¶nder
                    response = ask_openai(user_input)
                    st.subheader("ğŸ“Œ YanÄ±t")
                    st.write(response)

# ğŸ“Œ Streamlit ArayÃ¼zÃ¼
if __name__ == "__main__":
    st.title("ğŸ“¢ Kampanya AsistanÄ±")
    st.markdown("---")

    user_input = st.text_input("LÃ¼tfen kampanya ile ilgili sorunuzu girin:")

    # ğŸ“Œ Bellekteki verileri yÃ¼kleme
    memory_variables = memory.load_memory_variables({})
    chat_history = memory_variables.get('chat_history', [])

    if not isinstance(chat_history, list):
        chat_history = []

    if "top_n_results" not in st.session_state:
        st.session_state.top_n_results = []

    # KullanÄ±cÄ± giriÅŸini iÅŸleme fonksiyonunu Ã§aÄŸÄ±r
    if user_input:
        process_user_input(user_input)

    # ğŸ“Œ Sohbet GeÃ§miÅŸi (En fazla 3 mesaj gÃ¶sterilecek)
    st.subheader("ğŸ’¬ Sohbet GeÃ§miÅŸi")
    for msg in chat_history[-3:]:  # En son 3 mesajÄ± gÃ¶ster
        st.write(msg)







import streamlit as st
from langchain.chains.conversation.memory import ConversationBufferWindowMemory
from langchain_community.chat_models import AzureChatOpenAI
from langchain.callbacks.base import BaseCallbackHandler

# ğŸ“Œ Kampanya kodu kontrolÃ¼
def is_valid_campaign_code(code):
    """
    Kampanya kodunun geÃ§erli olup olmadÄ±ÄŸÄ±nÄ± kontrol eden fonksiyon.
    - Tamamen sayÄ±sal mÄ±?
    - "CAMP-12345" gibi bir formatta mÄ±?
    """
    return code.isdigit() or (code.startswith("CAMP-") and code[5:].isdigit())

# ğŸ“Œ KullanÄ±cÄ± GiriÅŸi Ä°ÅŸleme
def process_user_input(user_input):
    if user_input:
        with st.spinner("ğŸ’­ DÃ¼ÅŸÃ¼nÃ¼yorum..."):
            # ğŸ” Kampanya kodu var mÄ± kontrol et
            campaign_code = extract_campaign_code(user_input)

            if campaign_code:
                # ğŸ“Œ Elasticsearch'ten kampanya bilgisi Ã§ek
                campaign_info = es.search_campaign_by_code(campaign_code)

                # ğŸ“Œ OpenAIâ€™ye soru gÃ¶nder
                response = ask_openai(user_input, campaign_info=campaign_info)

                # ğŸ” HafÄ±zaya ekle
                memory.save_context({"input": user_input, "response": response})

                st.subheader("ğŸ“Œ YanÄ±t")
                st.write(response)

            else:
                # ğŸ“Œ Kampanya kodu yok, en alakalÄ± 3 kampanyayÄ± getir
                search_result, formatted_result = es.search_campaign_by_header(user_input)

                st.subheader("ğŸ“Œ En Ä°yi 3 Kampanya")
                st.write(formatted_result)

                # ğŸ“Œ KullanÄ±cÄ±nÄ±n yeni sorusu Ã¶nceki kampanyalarla mÄ± ilgili?
                follow_up_response = ask_openai(user_input, follow_up_info=formatted_result)

                if is_valid_campaign_code(follow_up_response):
                    st.write(f"ğŸš€ KullanÄ±cÄ±nÄ±n yeni sorusu `{follow_up_response}` kampanyasÄ±yla ilgili.")

                    # Kampanya kodu bulundu, Elasticsearch'ten bilgi Ã§ek ve OpenAI'ye gÃ¶nder
                    campaign_info = es.search_campaign_by_code(follow_up_response)
                    response = ask_openai(user_input, campaign_info=campaign_info)
                    st.subheader("ğŸ“Œ YanÄ±t")
                    st.write(response)

                elif follow_up_response != "HiÃ§biri":
                    # Kampanya adÄ± bulundu, Elasticsearch'te baÅŸlÄ±ÄŸa gÃ¶re arama yapÄ±lacak
                    campaign_info = es.filter_campaign_by_title(follow_up_response)
                    response = ask_openai(user_input, campaign_info=campaign_info)
                    st.subheader(f"ğŸ“Œ {follow_up_response} KampanyasÄ± Ä°Ã§eriÄŸi")
                    st.write(response)

                else:
                    # ğŸ“Œ HiÃ§bir kampanyayla alakalÄ± deÄŸilse, OpenAIâ€™ye genel soru olarak gÃ¶nder
                    response = ask_openai(user_input)
                    st.subheader("ğŸ“Œ YanÄ±t")
                    st.write(response)

