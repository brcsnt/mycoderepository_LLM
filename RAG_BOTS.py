
import streamlit as st
from langchain_community.chat_models import AzureChatOpenAI
from collections import deque

# ğŸ“Œ Streamlit session state ile chat memory saklama
if "chat_memory" not in st.session_state:
    st.session_state.chat_memory = deque(maxlen=3)  # En fazla 3 mesaj saklanÄ±r

# ğŸ“Œ OpenAI istemcisini baÅŸlatma
def initialize_openai_client():
    return AzureChatOpenAI(
        openai_api_key=config_info.azure_api_key,
        openai_api_version=config_info.azure_api_version,
        azure_endpoint=config_info.azure_endpoint,
        deployment_name="xyz",
        model_name="xyz",
        openai_api_type="azure"
    )

# ğŸ“Œ KullanÄ±cÄ±nÄ±n genel mi yoksa spesifik bir kampanya hakkÄ±nda mÄ± konuÅŸtuÄŸunu belirleme
def detect_query_type(user_input):
    """OpenAI kullanarak kullanÄ±cÄ±nÄ±n genel bir arama mÄ± yoksa spesifik bir kampanya sorgusu mu yaptÄ±ÄŸÄ±nÄ± belirler."""
    
    system_prompt = """KullanÄ±cÄ±nÄ±n mesajÄ±nÄ± analiz et:
    - EÄŸer genel bir kampanya arÄ±yorsa 'GENEL ARAMA' dÃ¶ndÃ¼r. (Ã–rneÄŸin: "Boyner kampanyalarÄ±", "Ä°ndirimli kampanyalar")
    - EÄŸer belirli bir kampanya hakkÄ±nda doÄŸrudan bir soru soruyorsa, kampanya baÅŸlÄ±ÄŸÄ±nÄ± dÃ¶ndÃ¼r. (Ã–rneÄŸin: "YÄ±lbaÅŸÄ± restoran kampanyasÄ±nÄ±n bitiÅŸ tarihi nedir" â†’ "YÄ±lbaÅŸÄ± Restoran KampanyasÄ±")"""

    client = initialize_openai_client()
    response = client.predict(f"{system_prompt}\n\nKullanÄ±cÄ± MesajÄ±: {user_input}")
    
    return response.strip()

# ğŸ“Œ Mesaj Ekleme Fonksiyonu
def add_message(user_input, response):
    """Sohbet geÃ§miÅŸine yeni mesaj ekler."""
    st.session_state.chat_memory.appendleft({"user": user_input, "bot": response})

# ğŸ“Œ History'yi Ekrana FormatlÄ± YazdÄ±rma
def get_formatted_history():
    """Sohbet geÃ§miÅŸini zaman sÄ±rasÄ±na gÃ¶re formatlÄ± dÃ¶ndÃ¼rÃ¼r."""
    if not st.session_state.chat_memory:
        return "Sohbet geÃ§miÅŸi henÃ¼z boÅŸ."
    return "\n\n".join([f"ğŸ—£ KullanÄ±cÄ±: {msg['user']}\nğŸ¤– Bot: {msg['bot']}" for msg in st.session_state.chat_memory])

# ğŸ“Œ OpenAI'ye Kampanya Bilgisiyle Soru GÃ¶nderme
def ask_openai(user_input, campaign_info=None):
    """OpenAI'ye Ã¶zel sistem prompt'larÄ± ile soru gÃ¶nderir."""
    if campaign_info:
        system_prompt = f"Kampanya bilgisi verilmiÅŸtir. Bu bilgiye gÃ¶re soruyu yanÄ±tla:\n\nKampanya AÃ§Ä±klamasÄ±: {campaign_info}"
        user_prompt = f"KullanÄ±cÄ± Sorusu: {user_input}\nYanÄ±tÄ± kÄ±sa ve net bir ÅŸekilde ver."
    else:
        system_prompt = "KullanÄ±cÄ± bir kampanya hakkÄ±nda soru sormuÅŸ olabilir. EÄŸer kampanya kodu veya baÅŸlÄ±k belirttiyse, ona gÃ¶re yanÄ±t ver."
        user_prompt = f"KullanÄ±cÄ± Sorusu: {user_input}\nYanÄ±tÄ± kÄ±sa ve net bir ÅŸekilde ver."

    model = initialize_openai_client()
    response = model.predict("\n".join([system_prompt, user_prompt]))
    return response.strip()

# ğŸ“Œ KullanÄ±cÄ± GiriÅŸi Ä°ÅŸleme
def process_user_input(user_input):
    """Her yeni kullanÄ±cÄ± mesajÄ±nda sÄ±fÄ±rdan baÅŸlar ve tÃ¼m akÄ±ÅŸÄ± yÃ¶netir."""
    if user_input:
        with st.spinner("ğŸ’­ DÃ¼ÅŸÃ¼nÃ¼yorum..."):

            # ğŸ“Œ Kampanya kodu var mÄ±?
            campaign_code = extract_campaign_code(user_input)

            if len(st.session_state.chat_memory) == 0:
                if campaign_code:
                    campaign_info = es.get_best_related(campaign_code)
                    response = ask_openai(user_input, campaign_info=campaign_info)
                    add_message(user_input, response)
                    st.subheader(f"ğŸ“Œ {campaign_code} KampanyasÄ± YanÄ±t Ä°Ã§eriÄŸi")
                    st.write(response)

                else:
                    # ğŸ“Œ KullanÄ±cÄ±nÄ±n sorgu tipini analiz et
                    query_type = detect_query_type(user_input)

                    if query_type == "GENEL ARAMA":
                        search_result, formatted_result = es.search_campaign_by_header(user_input)
                        add_message(user_input, formatted_result)  # **ğŸ”¹ ArtÄ±k historyâ€™ye ekleniyor**
                        st.subheader("ğŸ“Œ En Ä°yi 3 Kampanya")
                        st.write(formatted_result)
                    
                    else:
                        # KullanÄ±cÄ± belirli bir kampanya hakkÄ±nda doÄŸrudan soru sorduysa
                        campaign_info = es.filter_campaign_by_title(query_type)
                        response = ask_openai(user_input, campaign_info=campaign_info)
                        add_message(user_input, response)
                        st.subheader(f"ğŸ“Œ {query_type} KampanyasÄ± Ä°Ã§eriÄŸi")
                        st.write(response)

        st.subheader("ğŸ’¬ Sohbet GeÃ§miÅŸi (Son 3 Mesaj)")
        st.write(get_formatted_history())

        if len(st.session_state.chat_memory) == 3:
            st.session_state.chat_memory.clear()
            st.warning("ğŸ“Œ Sohbet geÃ§miÅŸi dolduÄŸu iÃ§in sÄ±fÄ±rlandÄ±.")

# ğŸ“Œ Streamlit ArayÃ¼zÃ¼
if __name__ == "__main__":
    st.title("ğŸ“¢ Kampanya AsistanÄ±")
    st.markdown("---")

    user_input = st.text_input("LÃ¼tfen kampanya ile ilgili sorunuzu girin:")

    if user_input:
        process_user_input(user_input)

    st.subheader("ğŸ’¬ Sohbet GeÃ§miÅŸi (Son 3 Mesaj)")
    st.write(get_formatted_history())


















import streamlit as st
from langchain_community.chat_models import AzureChatOpenAI
from collections import deque

# ğŸ“Œ Streamlit session state ile chat memory saklama
if "chat_memory" not in st.session_state:
    st.session_state.chat_memory = deque(maxlen=3)  # En fazla 3 mesaj saklanÄ±r

# ğŸ“Œ OpenAI istemcisini baÅŸlatma
def initialize_openai_client():
    return AzureChatOpenAI(
        openai_api_key=config_info.azure_api_key,
        openai_api_version=config_info.azure_api_version,
        azure_endpoint=config_info.azure_endpoint,
        deployment_name="xyz",
        model_name="xyz",
        openai_api_type="azure"
    )

# ğŸ“Œ KullanÄ±cÄ±nÄ±n yeni sorusunun Ã¶nceki mesajla ilgili olup olmadÄ±ÄŸÄ±nÄ± kontrol etme
def check_follow_up_relevance(user_input, last_message):
    """KullanÄ±cÄ±nÄ±n yeni sorusunun Ã¶nceki mesajla iliÅŸkili olup olmadÄ±ÄŸÄ±nÄ± kontrol eder."""
    
    system_prompt = """KullanÄ±cÄ±nÄ±n sorusunu anla ve eÄŸer Ã¶nceki cevapta belirtilen kampanyalardan biriyle ilgiliyse hangi kampanya ile ilgili olduÄŸunu belirle.
    - EÄŸer Ã¶nceki kampanyalardan biriyle ilgiliyse **"kampanya kodu: <kampanya_kodu>"** ÅŸeklinde dÃ¶ndÃ¼r.
    - EÄŸer yeni bir kampanya hakkÄ±nda konuÅŸuyorsa **"NEW QUERY"** dÃ¶ndÃ¼r.
    - EÄŸer Ã¶nceki mesajla alakasÄ±zsa **"NONE"** dÃ¶ndÃ¼r."""

    user_prompt = f"Ã–nceki Mesaj: {last_message} \n Yeni KullanÄ±cÄ± Sorusu: {user_input}"
    
    client = initialize_openai_client()
    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_prompt}
    ]

    response = client.predict("\n".join([msg["content"] for msg in messages]))
    
    return response.strip()

# ğŸ“Œ Mesaj Ekleme Fonksiyonu
def add_message(user_input, response):
    """Sohbet geÃ§miÅŸine yeni mesaj ekler."""
    st.session_state.chat_memory.appendleft({"user": user_input, "bot": response})  # Yeni mesaj en Ã¼ste eklenir

# ğŸ“Œ History'yi Ekrana FormatlÄ± YazdÄ±rma
def get_formatted_history():
    """Sohbet geÃ§miÅŸini zaman sÄ±rasÄ±na gÃ¶re formatlÄ± dÃ¶ndÃ¼rÃ¼r."""
    if not st.session_state.chat_memory:
        return "Sohbet geÃ§miÅŸi henÃ¼z boÅŸ."
    return "\n\n".join([f"ğŸ—£ KullanÄ±cÄ±: {msg['user']}\nğŸ¤– Bot: {msg['bot']}" for msg in st.session_state.chat_memory])

# ğŸ“Œ OpenAI'ye Kampanya Bilgisiyle Soru GÃ¶nderme
def ask_openai(user_input, campaign_info=None):
    """OpenAI'ye Ã¶zel sistem prompt'larÄ± ile soru gÃ¶nderir."""
    if campaign_info:
        system_prompt = f"Kampanya bilgisi verilmiÅŸtir. Bu bilgiye gÃ¶re soruyu yanÄ±tla:\n\nKampanya AÃ§Ä±klamasÄ±: {campaign_info}"
        user_prompt = f"KullanÄ±cÄ± Sorusu: {user_input}\nYanÄ±tÄ± kÄ±sa ve net bir ÅŸekilde ver."
    else:
        system_prompt = "KullanÄ±cÄ± bir kampanya hakkÄ±nda soru sormuÅŸ olabilir. EÄŸer kampanya kodu veya baÅŸlÄ±k belirttiyse, ona gÃ¶re yanÄ±t ver."
        user_prompt = f"KullanÄ±cÄ± Sorusu: {user_input}\nYanÄ±tÄ± kÄ±sa ve net bir ÅŸekilde ver."

    model = initialize_openai_client()
    response = model.predict("\n".join([system_prompt, user_prompt]))
    return response.strip()

# ğŸ“Œ KullanÄ±cÄ± GiriÅŸi Ä°ÅŸleme
def process_user_input(user_input):
    """Her yeni kullanÄ±cÄ± mesajÄ±nda sÄ±fÄ±rdan baÅŸlar ve tÃ¼m akÄ±ÅŸÄ± yÃ¶netir."""
    if user_input:
        with st.spinner("ğŸ’­ DÃ¼ÅŸÃ¼nÃ¼yorum..."):

            # ğŸ“Œ Kampanya kodu var mÄ±?
            campaign_code = extract_campaign_code(user_input)

            if len(st.session_state.chat_memory) == 0:
                if campaign_code:
                    campaign_info = es.get_best_related(campaign_code)
                    response = ask_openai(user_input, campaign_info=campaign_info)
                    add_message(user_input, response)
                    st.subheader(f"ğŸ“Œ {campaign_code} KampanyasÄ± YanÄ±t Ä°Ã§eriÄŸi")
                    st.write(response)
                else:
                    search_result, formatted_result = es.search_campaign_by_header(user_input)
                    add_message(user_input, formatted_result)  # **ğŸ”¹ ArtÄ±k historyâ€™ye ekleniyor**
                    st.subheader("ğŸ“Œ En Ä°yi 3 Kampanya")
                    st.write(formatted_result)

            else:
                last_message = st.session_state.chat_memory[0]["bot"]
                follow_up_response = check_follow_up_relevance(user_input, last_message)

                st.warning(f"Follow-up response: {follow_up_response}")  # **ğŸ” Debugging iÃ§in ekledim**

                if follow_up_response.startswith("kampanya kodu:"):
                    campaign_code = follow_up_response.split(":")[1].strip()
                    campaign_info = es.get_best_related(campaign_code)
                    response = ask_openai(user_input, campaign_info=campaign_info)
                    add_message(user_input, response)
                    st.subheader(f"ğŸ“Œ {campaign_code} KampanyasÄ± YanÄ±t Ä°Ã§eriÄŸi")
                    st.write(response)

                elif follow_up_response == "NEW QUERY":
                    search_result, formatted_result = es.search_campaign_by_header(user_input)
                    add_message(user_input, formatted_result)
                    st.subheader("ğŸ“Œ En Ä°yi 3 Kampanya")
                    st.write(formatted_result)

                elif follow_up_response == "NONE":
                    st.warning("Bu sorunuz Ã¶nceki kampanyalarla ilgili deÄŸil. LÃ¼tfen soruyu farklÄ± ÅŸekilde sormayÄ± deneyin.")

        st.subheader("ğŸ’¬ Sohbet GeÃ§miÅŸi (Son 3 Mesaj)")
        st.write(get_formatted_history())

        if len(st.session_state.chat_memory) == 3:
            st.session_state.chat_memory.clear()
            st.warning("ğŸ“Œ Sohbet geÃ§miÅŸi dolduÄŸu iÃ§in sÄ±fÄ±rlandÄ±.")

# ğŸ“Œ Streamlit ArayÃ¼zÃ¼
if __name__ == "__main__":
    st.title("ğŸ“¢ Kampanya AsistanÄ±")
    st.markdown("---")

    user_input = st.text_input("LÃ¼tfen kampanya ile ilgili sorunuzu girin:")

    if user_input:
        process_user_input(user_input)

    st.subheader("ğŸ’¬ Sohbet GeÃ§miÅŸi (Son 3 Mesaj)")
    st.write(get_formatted_history())














import streamlit as st
from langchain_community.chat_models import AzureChatOpenAI
from collections import deque

# ğŸ“Œ Streamlit session state ile chat memory ve top N kampanyalarÄ± saklama
if "chat_memory" not in st.session_state:
    st.session_state.chat_memory = deque(maxlen=3)  # En fazla 3 mesaj saklanÄ±r

if "top_n_campaigns" not in st.session_state:
    st.session_state.top_n_campaigns = []  # En iyi kampanyalarÄ± saklamak iÃ§in

# ğŸ“Œ Mesaj Ekleme Fonksiyonu (En fazla 3 mesaj tutar)
def add_message(user_input, response):
    """Sohbet geÃ§miÅŸine yeni mesaj ekler."""
    st.session_state.chat_memory.appendleft({"user": user_input, "bot": response})  # Yeni mesaj en Ã¼ste eklenir

# ğŸ“Œ History'yi Ekrana FormatlÄ± YazdÄ±rma
def get_formatted_history():
    """Sohbet geÃ§miÅŸini zaman sÄ±rasÄ±na gÃ¶re formatlÄ± dÃ¶ndÃ¼rÃ¼r."""
    if not st.session_state.chat_memory:
        return "Sohbet geÃ§miÅŸi henÃ¼z boÅŸ."
    return "\n\n".join([f"ğŸ—£ KullanÄ±cÄ±: {msg['user']}\nğŸ¤– Bot: {msg['bot']}" for msg in st.session_state.chat_memory])

# ğŸ“Œ OpenAI'ye Kampanya Bilgisiyle Soru GÃ¶nderme
def ask_openai(user_input, campaign_info=None, history_analysis=None):
    """OpenAI'ye Ã¶zel sistem prompt'larÄ± ile soru gÃ¶nderir."""
    if campaign_info:
        system_prompt = f"Kampanya bilgisi verilmiÅŸtir. Bu bilgiye gÃ¶re soruyu yanÄ±tla:\n\nKampanya AÃ§Ä±klamasÄ±: {campaign_info}"
        user_prompt = f"KullanÄ±cÄ± Sorusu: {user_input}\nYanÄ±tÄ± kÄ±sa ve net bir ÅŸekilde ver."
    elif history_analysis:
        system_prompt = "KullanÄ±cÄ±nÄ±n yeni mesajÄ±, Ã¶nceki konuÅŸmalardaki bir bilgiye referans veriyor mu? EÄŸer veriyorsa, ilgili bilgiyi dÃ¶ndÃ¼r, eÄŸer tamamen yeni bir ÅŸey soruyorsa 'Yeni Konu' dÃ¶ndÃ¼r."
        user_prompt = f"Ã–nceki Mesajlar:\n{history_analysis}\nKullanÄ±cÄ±nÄ±n Yeni Sorusu: {user_input}"

    else:
        system_prompt = "KullanÄ±cÄ± bir kampanya hakkÄ±nda soru sormuÅŸ olabilir. EÄŸer kampanya kodu veya baÅŸlÄ±k belirttiyse, ona gÃ¶re yanÄ±t ver."
        user_prompt = f"KullanÄ±cÄ± Sorusu: {user_input}\nYanÄ±tÄ± kÄ±sa ve net bir ÅŸekilde ver."

    model = AzureChatOpenAI(
        openai_api_key=config_info.azure_api_key,
        openai_api_version=config_info.azure_api_version,
        azure_endpoint=config_info.azure_endpoint,
        deployment_name="cyz",
        model_name="xyz",
        openai_api_type="azure"
    )

    response = model.predict(system_prompt + "\n" + user_prompt)
    return response.strip()

# ğŸ“Œ KullanÄ±cÄ± GiriÅŸi Ä°ÅŸleme
def process_user_input(user_input):
    if user_input:
        with st.spinner("ğŸ’­ DÃ¼ÅŸÃ¼nÃ¼yorum..."):

            # ğŸ“Œ Kampanya kodu var mÄ±?
            campaign_code = extract_campaign_code(user_input)

            if len(st.session_state.chat_memory) == 0:
                if campaign_code:
                    campaign_info = es.search_campaign_by_code(campaign_code)
                    response = ask_openai(user_input, campaign_info=campaign_info)
                    add_message(user_input, response)
                    st.subheader("ğŸ“Œ YanÄ±t")
                    st.write(response)
                else:
                    search_result, formatted_result = es.search_campaign_by_header(user_input)
                    st.session_state.top_n_campaigns = search_result  # KampanyalarÄ± sakla
                    st.subheader("ğŸ“Œ En Ä°yi 3 Kampanya")
                    st.write(formatted_result)
            else:
                formatted_history = get_formatted_history()
                follow_up_response = ask_openai(user_input, history_analysis=formatted_history)

                if follow_up_response.lower() != "yeni konu":
                    # EÄŸer kullanÄ±cÄ± Ã¶nceki mesajlardan birine referans verdiyse o bilgiyi getir
                    campaign_info = es.search_campaign_by_code(follow_up_response)
                    response = ask_openai(user_input, campaign_info=campaign_info)
                    add_message(user_input, response)
                    st.subheader("ğŸ“Œ YanÄ±t")
                    st.write(response)

                else:
                    # EÄŸer tamamen yeni bir konuysa, hafÄ±zayÄ± temizlemeden yeni arama yap
                    search_result, formatted_result = es.search_campaign_by_header(user_input)
                    st.session_state.top_n_campaigns = search_result  # Yeni kampanyalarÄ± sakla
                    st.subheader("ğŸ“Œ En Ä°yi 3 Kampanya")
                    st.write(formatted_result)

        # ğŸ“Œ Sohbet GeÃ§miÅŸini GÃ¼ncelle ve Ekrana YazdÄ±r
        st.subheader("ğŸ’¬ Sohbet GeÃ§miÅŸi (Son 3 Mesaj)")
        st.write(get_formatted_history())

        # ğŸ“Œ EÄŸer 3 mesaj olduysa sÄ±fÄ±rla
        if len(st.session_state.chat_memory) == 3:
            st.session_state.chat_memory.clear()
            st.warning("ğŸ“Œ Sohbet geÃ§miÅŸi dolduÄŸu iÃ§in sÄ±fÄ±rlandÄ±.")

# ğŸ“Œ Streamlit ArayÃ¼zÃ¼
if __name__ == "__main__":
    st.title("ğŸ“¢ Kampanya AsistanÄ±")
    st.markdown("---")

    user_input = st.text_input("LÃ¼tfen kampanya ile ilgili sorunuzu girin:")

    if user_input:
        process_user_input(user_input)

    # ğŸ“Œ Sohbet GeÃ§miÅŸi Ekrana YazdÄ±rÄ±lÄ±yor
    st.subheader("ğŸ’¬ Sohbet GeÃ§miÅŸi (Son 3 Mesaj)")
    st.write(get_formatted_history())



















import streamlit as st
import logging
from langchain.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA
from langchain.memory import ConversationBufferMemory
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain.docstore.document import Document
import os
import re

# 1ï¸âƒ£ Logger Ayarla
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# 2ï¸âƒ£ API AnahtarÄ± TanÄ±mla
os.environ["OPENAI_API_KEY"] = "your_api_key_here"

# 3ï¸âƒ£ Ã–rnek Kampanya Verileri
campaigns = [
    {"code": "KAMP001", "title": "Migros Ä°ndirim KampanyasÄ±", "content": "Migros marketlerinde %20 indirim! 1-10 Åubat arasÄ±nda geÃ§erlidir.", "start_date": "01-02-2024", "end_date": "10-02-2024"},
    {"code": "KAMP002", "title": "Beyaz EÅŸya KampanyasÄ±", "content": "Beyaz eÅŸyalar 15 Mart'a kadar Ã¶zel fiyatlarla!", "start_date": "01-03-2024", "end_date": "15-03-2024"},
    {"code": "KAMP003", "title": "Giyim Sezon Sonu Ä°ndirimi", "content": "TÃ¼m giyim Ã¼rÃ¼nlerinde %30 indirim!", "start_date": "01-04-2024", "end_date": "30-04-2024"}
   
]

# 4ï¸âƒ£ OpenAI Embeddings kullanarak ChromaDB oluÅŸtur ve doldur
embeddings = OpenAIEmbeddings()
vector_store = Chroma(embedding_function=embeddings)

# Kampanya verilerini ChromaDB'ye ekleyelim
docs = [Document(page_content=f"{c['title']}: {c['content']} (GeÃ§erlilik: {c['start_date']} - {c['end_date']})", metadata={"code": c["code"]}) for c in campaigns]
vector_store.add_documents(docs)
retriever = vector_store.as_retriever(search_kwargs={"k": 3})

# 5ï¸âƒ£ LLM Modeli TanÄ±mla ve Sistem Prompt Ekle
system_prompt = "Sen bir reklam kampanya asistanÄ±sÄ±n. KullanÄ±cÄ±ya kampanyalar hakkÄ±nda bilgi ver, ama sadece kampanya metinlerinden referans al."
llm = ChatOpenAI(model_name="gpt-4", temperature=0, system_prompt=system_prompt)
qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)

# 6ï¸âƒ£ Sohbet HafÄ±zasÄ±nÄ± (Memory) TanÄ±mla
memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)
previous_retrieved_campaigns = {}
follow_up_count = 0
max_follow_up = 5  # KullanÄ±cÄ±nÄ±n aynÄ± kampanya iÃ§inde sorabileceÄŸi maksimum takip sorusu

# 7ï¸âƒ£ Kampanya Kodunu Ã‡Ä±kart ve DoÄŸrudan Bilgi Getir
def extract_campaign_code(user_input):
    try:
        match = re.search(r"KAMP\d{3}", user_input)
        return match.group(0) if match else None
    except Exception as e:
        logger.error(f"Kampanya kodu Ã§Ä±karma hatasÄ±: {e}")
        return None

# 8ï¸âƒ£ Yeni Kampanyaya GeÃ§iÅŸi AlgÄ±la
def detect_new_campaign(user_input):
    global previous_retrieved_campaigns, follow_up_count
    
    try:
        logger.info(f"Yeni kampanya tespiti iÃ§in giriÅŸ alÄ±ndÄ±: {user_input}")
        
        campaign_code = extract_campaign_code(user_input)
        if campaign_code:
            docs = retriever.get_relevant_documents(campaign_code)
            if docs:
                previous_retrieved_campaigns[campaign_code] = docs[0]
                follow_up_count = 0  # Yeni kampanya baÅŸladÄ±ÄŸÄ±nda follow-up sayacÄ±nÄ± sÄ±fÄ±rla
                logger.info(f"Belirtilen kampanya kodu bulundu: {campaign_code}, Ä°Ã§erik: {docs[0].page_content}")
                return docs[0].page_content
        
        # VectorStore kullanarak en alakalÄ± top_n kampanyayÄ± bul
        similar_docs = retriever.get_relevant_documents(user_input)
        if similar_docs:
            previous_retrieved_campaigns = {f"KAMP{i+1:03}": doc for i, doc in enumerate(similar_docs)}
            follow_up_count = 0  # Yeni kampanya bulunduÄŸunda follow-up sÄ±fÄ±rlanÄ±r
            result = "\n".join([f"{key} - {doc.page_content.split(' ', 5)[0]}..." for key, doc in previous_retrieved_campaigns.items()])
            return f"En alakalÄ± kampanyalar:\n{result}"
        
        return "Uygun kampanya bulunamadÄ±."
    except Exception as e:
        logger.error(f"Yeni kampanya tespitinde hata: {e}")
        return "Bir hata oluÅŸtu, lÃ¼tfen tekrar deneyin."

# 9ï¸âƒ£ KullanÄ±cÄ±dan GiriÅŸ Al ve YanÄ±t DÃ¶ndÃ¼r
def chat_with_bot(user_input):
    global previous_retrieved_campaigns, follow_up_count
    
    try:
        logger.info(f"KullanÄ±cÄ± giriÅŸi: {user_input}")
        
        if follow_up_count >= max_follow_up:
            return "âš  Maksimum takip soru sÄ±nÄ±rÄ±na ulaÅŸÄ±ldÄ±. Yeni bir kampanya hakkÄ±nda soru sorabilirsiniz."
        
        chat_history = memory.load_memory_variables({})["chat_history"]
        campaign_info = detect_new_campaign(user_input)
        if campaign_info:
            return campaign_info
        
        match = re.search(r"(KAMP\d{3}) hakkÄ±nda (.+)\??", user_input)
        if match:
            campaign_code = match.group(1)
            if campaign_code in previous_retrieved_campaigns:
                selected_campaign = previous_retrieved_campaigns[campaign_code]
                follow_up_count += 1  # Takip sorusu sayÄ±sÄ±nÄ± artÄ±r
                logger.info(f"SeÃ§ilen kampanya: {selected_campaign}")
                return qa_chain.run(f"{chat_history}\nKullanÄ±cÄ±: {user_input}\nBu kampanya hakkÄ±nda: {selected_campaign.page_content}")
            return "âš  GeÃ§ersiz kampanya kodu. LÃ¼tfen geÃ§erli bir kampanya girin."
        
        follow_up_count += 1  # Genel sorular iÃ§in de takip sorusu sayÄ±sÄ±nÄ± artÄ±r
        response = qa_chain.run(f"{chat_history}\nKullanÄ±cÄ±: {user_input}")
        memory.save_context({"input": user_input}, {"output": response})
        logger.info(f"LLM YanÄ±tÄ±: {response}")
        return response
    except Exception as e:
        logger.error(f"Chat iÅŸleminde hata: {e}")
        return "Bir hata oluÅŸtu, lÃ¼tfen tekrar deneyin."

# ğŸ”Ÿ Streamlit ArayÃ¼zÃ¼
st.title("ğŸ“¢ Reklam Kampanya Chatbotu")
st.write("SorularÄ±nÄ±zÄ± sorun, kampanyalar hakkÄ±nda bilgi alÄ±n!")

user_input = st.text_input("MesajÄ±nÄ±zÄ± girin:")
if st.button("GÃ¶nder"):
    if user_input:
        response = chat_with_bot(user_input)
        st.write(response)



---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------





import streamlit as st
import logging
from langchain.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA
from langchain.memory import ConversationBufferMemory
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain.docstore.document import Document
import os
import re

# 1ï¸âƒ£ Logger Ayarla - Hata ve iÅŸlem kayÄ±tlarÄ±nÄ± tutmak iÃ§in kullanÄ±lÄ±r
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# 2ï¸âƒ£ OpenAI API AnahtarÄ± TanÄ±mla - OpenAI LLM modelini kullanabilmek iÃ§in gerekli
os.environ["OPENAI_API_KEY"] = "your_api_key_here"

# 3ï¸âƒ£ Ã–rnek Kampanya Verileri - KullanÄ±cÄ±ya sunulacak kampanyalar burada tanÄ±mlanÄ±r
campaigns = [
    {"code": "KAMP001", "title": "Migros Ä°ndirim KampanyasÄ±", "content": "Migros marketlerinde %20 indirim! 1-10 Åubat arasÄ±nda geÃ§erlidir.", "start_date": "01-02-2024", "end_date": "10-02-2024"},
    {"code": "KAMP002", "title": "Beyaz EÅŸya KampanyasÄ±", "content": "Beyaz eÅŸyalar 15 Mart'a kadar Ã¶zel fiyatlarla!", "start_date": "01-03-2024", "end_date": "15-03-2024"},
    {"code": "KAMP003", "title": "Giyim Sezon Sonu Ä°ndirimi", "content": "TÃ¼m giyim Ã¼rÃ¼nlerinde %30 indirim!", "start_date": "01-04-2024", "end_date": "30-04-2024"}
]

# 4ï¸âƒ£ OpenAI Embeddings kullanarak ChromaDB oluÅŸtur ve doldur - Kampanyalar vektÃ¶r olarak saklanÄ±r
embeddings = OpenAIEmbeddings()
vector_store = Chroma(embedding_function=embeddings)

# Kampanya verilerini ChromaDB'ye ekleyelim
docs = [Document(page_content=f"{c['title']}: {c['content']} (GeÃ§erlilik: {c['start_date']} - {c['end_date']})", metadata={"code": c["code"]}) for c in campaigns]
vector_store.add_documents(docs)
retriever = vector_store.as_retriever(search_kwargs={"k": 3})

# 5ï¸âƒ£ LLM Modeli TanÄ±mla ve Sistem Prompt Ekle - Modelin nasÄ±l davranacaÄŸÄ±nÄ± belirler
system_prompt = "Sen bir reklam kampanya asistanÄ±sÄ±n. KullanÄ±cÄ±ya kampanyalar hakkÄ±nda bilgi ver, ama sadece kampanya metinlerinden referans al."
follow_up_prompt = "Bu bir takip sorusudur. Ã–nceki konuÅŸmalarÄ± dikkate alarak, sadece kampanya metinlerine dayanarak kesin ve kÄ±sa bir yanÄ±t ver."

llm = ChatOpenAI(model_name="gpt-4", temperature=0, system_prompt=system_prompt)
qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)

# 6ï¸âƒ£ Sohbet HafÄ±zasÄ±nÄ± (Memory) TanÄ±mla - KullanÄ±cÄ±nÄ±n konuÅŸmalarÄ±nÄ± saklar
memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)
previous_retrieved_campaigns = {}  # Ã–nceki getirilen kampanyalarÄ± saklar
follow_up_count = 0  # KullanÄ±cÄ±nÄ±n kaÃ§ tane takip sorusu sorduÄŸunu takip eder
max_follow_up = 5  # KullanÄ±cÄ±nÄ±n aynÄ± kampanya iÃ§inde sorabileceÄŸi maksimum takip sorusu

# 9ï¸âƒ£ KullanÄ±cÄ±dan GiriÅŸ Al ve YanÄ±t DÃ¶ndÃ¼r - KullanÄ±cÄ±nÄ±n mesajÄ±nÄ± alÄ±r ve uygun cevabÄ± dÃ¶ndÃ¼rÃ¼r
def chat_with_bot(user_input):
    global previous_retrieved_campaigns, follow_up_count
    
    try:
        logger.info(f"KullanÄ±cÄ± giriÅŸi: {user_input}")
        
        if follow_up_count >= max_follow_up:
            return "âš  Maksimum takip soru sÄ±nÄ±rÄ±na ulaÅŸÄ±ldÄ±. Yeni bir kampanya hakkÄ±nda soru sorabilirsiniz."
        
        chat_history = memory.load_memory_variables({})["chat_history"]
        campaign_info = detect_new_campaign(user_input)
        if campaign_info:
            return campaign_info
        
        match = re.search(r"(KAMP\d{3}) hakkÄ±nda (.+)\??", user_input)
        if match:
            campaign_code = match.group(1)
            if campaign_code in previous_retrieved_campaigns:
                selected_campaign = previous_retrieved_campaigns[campaign_code]
                follow_up_count += 1
                logger.info(f"SeÃ§ilen kampanya: {selected_campaign}")
                return qa_chain.run(f"{follow_up_prompt}\n{chat_history}\nKullanÄ±cÄ±: {user_input}\nBu kampanya hakkÄ±nda: {selected_campaign.page_content}")
        
        follow_up_count += 1
        if follow_up_count > 1:
            response = qa_chain.run(f"{follow_up_prompt}\n{chat_history}\nKullanÄ±cÄ±: {user_input}")
        else:
            response = qa_chain.run(f"{system_prompt}\n{chat_history}\nKullanÄ±cÄ±: {user_input}")
        
        memory.save_context({"input": user_input}, {"output": response})
        logger.info(f"LLM YanÄ±tÄ±: {response}")
        return response
    except Exception as e:
        logger.error(f"Chat iÅŸleminde hata: {e}")
        return "Bir hata oluÅŸtu, lÃ¼tfen tekrar deneyin."

# ğŸ”Ÿ Streamlit ArayÃ¼zÃ¼ - KullanÄ±cÄ±dan giriÅŸ alÄ±p chatbot ile iletiÅŸime geÃ§mesini saÄŸlar
st.title("ğŸ“¢ Reklam Kampanya Chatbotu")
st.write("SorularÄ±nÄ±zÄ± sorun, kampanyalar hakkÄ±nda bilgi alÄ±n!")

user_input = st.text_input("MesajÄ±nÄ±zÄ± girin:")
if st.button("GÃ¶nder"):
    if user_input:
        response = chat_with_bot(user_input)
        st.write(response)



------------------------------------------------------------------------------------------------------------------------------------------------



"""


Evet, kodun son hali yukarÄ±daki diyalog akÄ±ÅŸÄ±na uygun ÅŸekilde cevap verebilecek ÅŸekilde tasarlanmÄ±ÅŸtÄ±r. Ã–rneÄŸin:

KullanÄ±cÄ±: "KAMP001 kampanyasÄ± nedir ?"

Sorguda aÃ§Ä±kÃ§a "KAMP001" yer aldÄ±ÄŸÄ±ndan, sistem doÄŸrudan bu kampanyayÄ± tespit eder, global kampanya listesi ve takip sayacÄ± sÄ±fÄ±rlanÄ±r (konuÅŸma geÃ§miÅŸi temizlenir) ve KAMP001â€™in iÃ§erik bilgisi ile LLMâ€™ye sorgu gÃ¶nderilerek yanÄ±t Ã¼retilir.
KullanÄ±cÄ±: "Bana Migros kampanyasÄ±nÄ±n detaylarÄ±nÄ± sÃ¶yle."

Sorguda aÃ§Ä±k bir kampanya kodu olmadÄ±ÄŸÄ± iÃ§in, sistem vector store Ã¼zerinden TOP_N (3) kriterine gÃ¶re ilgili kampanyalarÄ± arar. EÄŸer Migros ile ilgili kampanyalar varsa, bu kampanyalarÄ±n kod ve baÅŸlÄ±k bilgileri liste halinde (Ã¶rneÄŸin, â€œ1. KAMP001: Migros Ä°ndirim KampanyasÄ±â€ gibi) sunulur.
KullanÄ±cÄ±: "2.gelen kampanyanÄ±n iÃ§eriÄŸi nedir?"

Bu takip (follow-up) sorgusunda, sistem Ã¶nceki listelenen kampanyalar ve konuÅŸma geÃ§miÅŸini LLMâ€™ye gÃ¶ndererek kullanÄ±cÄ±nÄ±n hangi kampanyaya atÄ±fta bulunduÄŸunu belirlemesini ister. LLMâ€™nin tespit ettiÄŸi kampanyanÄ±n iÃ§erik bilgisi, kullanÄ±cÄ±nÄ±n sorusu ile birlikte LLMâ€™ye gÃ¶nderilir ve LLMâ€™nin cevabÄ± ekrana basÄ±lÄ±r.
KullanÄ±cÄ±: "Peki 3.sÄ±radaki kampanyanÄ±n detayÄ± neydi yazar mÄ±sÄ±n?"

AynÄ± ÅŸekilde, LLM Ã¶nceki listeden (Ã¶rneÄŸin, 3. sÄ±radaki kampanya) hangi kampanyanÄ±n kastedildiÄŸini belirler, ilgili kampanyanÄ±n iÃ§erik bilgisi ve kullanÄ±cÄ± sorusu ile LLMâ€™den nihai yanÄ±t alÄ±nÄ±r.
KullanÄ±cÄ±: "Peki sonuncu yazan kampanyanÄ±n detayÄ±?"

LLM, "sonuncu" ifadesini de gÃ¶z Ã¶nÃ¼nde bulundurarak Ã¶nceki listeden en son elemanÄ± tespit eder ve bu kampanyanÄ±n detaylarÄ±, kullanÄ±cÄ±nÄ±n sorusu ile birlikte LLMâ€™ye gÃ¶nderilerek yanÄ±t Ã¼retilir.
KullanÄ±cÄ±: "Beyaz eÅŸya kampanyasÄ±nÄ±n detaylarÄ± neydi peki"

EÄŸer LLM, bu sorgunun Ã¶nceki listelenen kampanyalarla iliÅŸkili olmadÄ±ÄŸÄ±nÄ± belirlerse, sistem global durumu (last_retrieved_campaigns ve konuÅŸma geÃ§miÅŸini) temizler ve yeni kampanya sorgusu olarak "Beyaz EÅŸya KampanyasÄ±"nÄ± vector storeâ€™dan arar. BÃ¶ylece yeni kampanya sorgusu Ã¼zerinden ilgili kampanyanÄ±n detaylarÄ± LLMâ€™den alÄ±nÄ±r.
KullanÄ±cÄ±: "KAMP003 kampanyasÄ±nÄ±n detaylarÄ± nedir ?"

Sorguda aÃ§Ä±kÃ§a "KAMP003" yer aldÄ±ÄŸÄ±ndan, sistem doÄŸrudan KAMP003â€™Ã¼ tespit eder, global durum sÄ±fÄ±rlanÄ±r ve KAMP003â€™Ã¼n iÃ§erik bilgisi ile LLMâ€™ye sorgu gÃ¶nderilerek yanÄ±t alÄ±nÄ±r.
AyrÄ±ca, takip sorgularÄ±nda maksimum takip sayÄ±sÄ± (Ã¶rneÄŸin MAX_FOLLOW_UP = 5) uygulanmakta; eÄŸer kullanÄ±cÄ± 5 takip sorgusuna ulaÅŸÄ±rsa, sistem otomatik olarak global durumu temizleyip yeni kampanya sorgusu yapÄ±lmasÄ±nÄ± isteyecektir.

Bu yapÄ± sayesinde, kullanÄ±cÄ± hiÃ§bir ek numeric veya sÄ±ralama girdisi vermeden, tamamen doÄŸal diyalog akÄ±ÅŸÄ± iÃ§erisinde doÄŸru kampanyanÄ±n tespit edilip, ilgili kampanyanÄ±n iÃ§erik bilgisiyle LLM tarafÄ±ndan Ã¼retilen yanÄ±t ekrana basÄ±lacaktÄ±r.


"""


import streamlit as st
import logging
import os
import re
from langchain.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA
from langchain.memory import ConversationBufferMemory
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain.docstore.document import Document

# 1ï¸âƒ£ Logger Ayarla
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# 2ï¸âƒ£ OpenAI API AnahtarÄ± TanÄ±mla
os.environ["OPENAI_API_KEY"] = "your_api_key_here"  # API anahtarÄ±nÄ±zÄ± buraya girin

# 3ï¸âƒ£ Ã–rnek Kampanya Verileri
campaigns = [
    {"code": "KAMP001", "title": "Migros Ä°ndirim KampanyasÄ±", "content": "Migros marketlerinde %20 indirim! 1-10 Åubat arasÄ±nda geÃ§erlidir.", "start_date": "01-02-2024", "end_date": "10-02-2024"},
    {"code": "KAMP002", "title": "Beyaz EÅŸya KampanyasÄ±", "content": "Beyaz eÅŸyalar 15 Mart'a kadar Ã¶zel fiyatlarla!", "start_date": "01-03-2024", "end_date": "15-03-2024"},
    {"code": "KAMP003", "title": "Giyim Sezon Sonu Ä°ndirimi", "content": "TÃ¼m giyim Ã¼rÃ¼nlerinde %30 indirim!", "start_date": "01-04-2024", "end_date": "30-04-2024"}
]

# Parametrik olarak top_n deÄŸeri (ÅŸu anda 3 olarak ayarlandÄ±)
TOP_N = 3

# Takip sorgularÄ± iÃ§in maksimum sayÄ±yÄ± belirleyelim (Ã¶rneÄŸin, 5)
MAX_FOLLOW_UP = 5

# 4ï¸âƒ£ OpenAI Embeddings kullanarak ChromaDB oluÅŸtur ve doldur
embeddings = OpenAIEmbeddings()
vector_store = Chroma(embedding_function=embeddings)
docs = [
    Document(
        page_content=f"{c['title']}: {c['content']} (GeÃ§erlilik: {c['start_date']} - {c['end_date']})",
        metadata={"code": c["code"]}
    )
    for c in campaigns
]
vector_store.add_documents(docs)
# TOP_N kriteri kullanÄ±larak en iyi sonuÃ§lar alÄ±nÄ±r.
retriever = vector_store.as_retriever(search_kwargs={"k": TOP_N})

# 5ï¸âƒ£ LLM Modeli ve Prompt AyarlarÄ±
system_prompt = "Sen bir reklam kampanya asistanÄ±sÄ±n. KullanÄ±cÄ±ya kampanyalar hakkÄ±nda bilgi ver, yanÄ±tlarÄ±nÄ± sadece kampanya metinlerine dayandÄ±r."
follow_up_prompt = (
    "Bu bir takip (follow-up) sorusudur. AÅŸaÄŸÄ±daki konuÅŸma geÃ§miÅŸini ve listelenen kampanyalarÄ± inceleyerek, "
    "kullanÄ±cÄ±nÄ±n hangi kampanya hakkÄ±nda detay istediÄŸini belirle ve sadece o kampanyanÄ±n detaylarÄ±nÄ± ver."
)

llm = ChatOpenAI(model_name="gpt-4", temperature=0, system_prompt=system_prompt)
qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)

# 6ï¸âƒ£ KonuÅŸma HafÄ±zasÄ± ve Global Durum DeÄŸiÅŸkenleri
memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)
last_retrieved_campaigns = []   # Son sorgudan dÃ¶nen kampanyalarÄ±n listesini saklar
follow_up_count = 0              # Takip sorgularÄ± iÃ§in sayacÄ± tutar

# 7ï¸âƒ£ Yeni Kampanya SorgularÄ±nÄ± DoÄŸal Dil ile Tespit Eden Fonksiyon
def detect_new_campaign(user_input: str):
    """
    EÄŸer sorguda doÄŸrudan kampanya kodu geÃ§miyorsa,
    vector store Ã¼zerinden ilgili kampanyalarÄ± getirir.
    
    - EÄŸer tek bir kampanya bulunursa, kampanyanÄ±n contentâ€™i ve kullanÄ±cÄ±nÄ±n sorusu ile LLM'den yanÄ±t alÄ±nÄ±r.
    - EÄŸer birden fazla kampanya bulunursa, TOP_N kadar sonuÃ§ liste halinde sunulur.
    """
    global last_retrieved_campaigns
    if re.search(r"KAMP\d{3}", user_input, re.IGNORECASE):
        return None  # Sorguda aÃ§Ä±k kampanya kodu varsa bu fonksiyon devreye girmez.

    retrieved_docs = retriever.get_relevant_documents(user_input)
    if not retrieved_docs:
        return "ÃœzgÃ¼nÃ¼m, sorgunuza uygun kampanya bulunamadÄ±."
    
    last_retrieved_campaigns = retrieved_docs

    if len(retrieved_docs) == 1:
        doc = retrieved_docs[0]
        response = qa_chain.run(
            f"{system_prompt}\nKullanÄ±cÄ±: {user_input}\nBu kampanya hakkÄ±nda: {doc.page_content}"
        )
        return response
    else:
        # Birden fazla kampanya bulunduÄŸunda, TOP_N kadar sonuÃ§ liste halinde sunulur.
        response_lines = ["Ä°lgili kampanyalar:"]
        for i, doc in enumerate(retrieved_docs[:TOP_N], start=1):
            title = doc.page_content.split(":")[0].strip()
            code = doc.metadata.get("code", "Bilinmiyor")
            response_lines.append(f"{i}. {code}: {title}")
        return "\n".join(response_lines)

# 8ï¸âƒ£ KullanÄ±cÄ± Girdilerini Ä°ÅŸleyen Fonksiyon
def chat_with_bot(user_input: str):
    global last_retrieved_campaigns, follow_up_count
    try:
        logger.info(f"KullanÄ±cÄ± giriÅŸi: {user_input}")
        chat_history = memory.load_memory_variables({})["chat_history"]

        # (A) EÄŸer sorguda aÃ§Ä±kÃ§a kampanya kodu (Ã¶rn. "KAMP001") varsa:
        code_match = re.search(r"(KAMP\d{3})", user_input, re.IGNORECASE)
        if code_match:
            campaign_code = code_match.group(1).upper()
            selected_doc = next((doc for doc in docs if doc.metadata.get("code", "").upper() == campaign_code), None)
            if selected_doc:
                # Yeni kampanya sorgusu olduÄŸundan, global liste ve (opsiyonel) geÃ§miÅŸ temizlenir.
                last_retrieved_campaigns = [selected_doc]
                follow_up_count = 0
                memory.clear()  # KonuÅŸma geÃ§miÅŸini temizle
                # KampanyanÄ±n contentâ€™i ve kullanÄ±cÄ±nÄ±n sorusu ile LLM'den yanÄ±t alÄ±nÄ±r.
                response = qa_chain.run(
                    f"{system_prompt}\nKullanÄ±cÄ±: {user_input}\nBu kampanya hakkÄ±nda: {selected_doc.page_content}"
                )
                memory.save_context({"input": user_input}, {"output": response})
                return response
            else:
                return "Belirtilen kampanya bulunamadÄ±."

        # (B) EÄŸer daha Ã¶nceki sorgudan dÃ¶nen kampanya listesi boÅŸsa, yeni sorgu olarak ele al:
        if not last_retrieved_campaigns:
            new_campaign_response = detect_new_campaign(user_input)
            memory.save_context({"input": user_input}, {"output": new_campaign_response})
            return new_campaign_response

        # (C) Gelen sorgu bir takip (follow-up) sorgusuyse:
        # EÄŸer takip sorgularÄ±nÄ±n sayÄ±sÄ± maksimum deÄŸeri aÅŸtÄ±ysa:
        if follow_up_count >= MAX_FOLLOW_UP:
            # Maksimum takip sayÄ±sÄ±na ulaÅŸÄ±ldÄ±ÄŸÄ±nda, kullanÄ±cÄ±ya yeni kampanya sorgusu yapmasÄ± istenir.
            last_retrieved_campaigns = []
            memory.clear()  # KonuÅŸma geÃ§miÅŸini temizle
            follow_up_count = 0
            return "Maksimum takip soru sÄ±nÄ±rÄ±na ulaÅŸÄ±ldÄ±. LÃ¼tfen yeni kampanya sorgusu yapÄ±nÄ±z."

        # Takip sorgusunda, LLMâ€™den Ã¶nceki listelenen kampanyalar ve konuÅŸma geÃ§miÅŸine dayanarak,
        # kullanÄ±cÄ±nÄ±n hangi kampanyaya atÄ±fta bulunduÄŸunu belirlemesi istenir.
        campaigns_context = "\n".join(
            f"{doc.metadata.get('code','Bilinmiyor')}: {doc.page_content}"
            for doc in last_retrieved_campaigns
        )
        determination_prompt = (
            f"AÅŸaÄŸÄ±daki listelenen kampanyalar iÃ§erisinden, kullanÄ±cÄ±nÄ±n aÅŸaÄŸÄ±daki sorgusuyla en Ã§ok hangi kampanyaya atÄ±fta bulunduÄŸunu belirle. "
            f"EÄŸer sorgu, listelenen kampanyalarla ilgili deÄŸilse, sadece 'yeni kampanya' yaz.\n\n"
            f"Listelenen Kampanyalar:\n{campaigns_context}\n\n"
            f"KullanÄ±cÄ±nÄ±n Sorgusu: {user_input}\n\n"
            f"YanÄ±t (sadece ilgili kampanya kodunu ya da 'yeni kampanya' ifadesini ver): "
        )
        determination = llm.run(determination_prompt).strip().lower()
        logger.info(f"Determination: {determination}")

        # EÄŸer LLM yanÄ±tÄ±nda "yeni kampanya" ifadesi geÃ§iyorsa:
        if "yeni kampanya" in determination:
            last_retrieved_campaigns = []
            memory.clear()  # KonuÅŸma geÃ§miÅŸini temizle
            follow_up_count = 0
            new_campaign_response = detect_new_campaign(user_input)
            memory.save_context({"input": user_input}, {"output": new_campaign_response})
            return new_campaign_response
        else:
            # LLM yanÄ±tÄ±ndan tespit edilen kampanya kodunu kullanarak ilgili kampanyayÄ± seÃ§elim.
            campaign_code_match = re.search(r"(KAMP\d{3})", determination, re.IGNORECASE)
            if campaign_code_match:
                campaign_code = campaign_code_match.group(1).upper()
                selected_doc = next((doc for doc in last_retrieved_campaigns if doc.metadata.get("code", "").upper() == campaign_code), None)
                if not selected_doc:
                    return "Listede belirtilen kampanya bulunamadÄ±."
            else:
                return "LÃ¼tfen hangi kampanyadan bahsettiÄŸinizi netleÅŸtiriniz."
            
            follow_up_count += 1
            # KampanyanÄ±n contentâ€™i ve kullanÄ±cÄ±nÄ±n sorusu ile LLMâ€™den yardÄ±m alÄ±nÄ±r, son yanÄ±t ekrana basÄ±lÄ±r.
            response = qa_chain.run(
                f"{follow_up_prompt}\nKullanÄ±cÄ±: {user_input}\nBu kampanya hakkÄ±nda: {selected_doc.page_content}\nKonuÅŸma GeÃ§miÅŸi:\n{chat_history}"
            )
            memory.save_context({"input": user_input}, {"output": response})
            return response

    except Exception as e:
        logger.error(f"Chat iÅŸleminde hata: {e}")
        return "Bir hata oluÅŸtu, lÃ¼tfen tekrar deneyin."

# 9ï¸âƒ£ Streamlit ArayÃ¼zÃ¼
st.title("ğŸ“¢ Reklam Kampanya Chatbotu")
st.write("SorularÄ±nÄ±zÄ± sorun, kampanyalar hakkÄ±nda bilgi alÄ±n!")

user_input = st.text_input("MesajÄ±nÄ±zÄ± girin:")
if st.button("GÃ¶nder"):
    if user_input:
        response = chat_with_bot(user_input)
        st.write(response)





----------------------------------------------------------------------------------------------------

# LOG LU YAPI



import streamlit as st
import logging
import os
import re
import pandas as pd
from datetime import datetime
from langchain.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA
from langchain.memory import ConversationBufferMemory
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain.docstore.document import Document

# 1ï¸âƒ£ Logger Ayarla
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# 2ï¸âƒ£ OpenAI API AnahtarÄ± TanÄ±mla
os.environ["OPENAI_API_KEY"] = "your_api_key_here"  # API anahtarÄ±nÄ±zÄ± buraya girin

# 3ï¸âƒ£ Ã–rnek Kampanya Verileri
campaigns = [
    {"code": "KAMP001", "title": "Migros Ä°ndirim KampanyasÄ±", "content": "Migros marketlerinde %20 indirim! 1-10 Åubat arasÄ±nda geÃ§erlidir.", "start_date": "01-02-2024", "end_date": "10-02-2024"},
    {"code": "KAMP002", "title": "Beyaz EÅŸya KampanyasÄ±", "content": "Beyaz eÅŸyalar 15 Mart'a kadar Ã¶zel fiyatlarla!", "start_date": "01-03-2024", "end_date": "15-03-2024"},
    {"code": "KAMP003", "title": "Giyim Sezon Sonu Ä°ndirimi", "content": "TÃ¼m giyim Ã¼rÃ¼nlerinde %30 indirim!", "start_date": "01-04-2024", "end_date": "30-04-2024"}
]

# Parametrik olarak top_n deÄŸeri (ÅŸu anda 3 olarak ayarlandÄ±)
TOP_N = 3

# Takip sorgularÄ± iÃ§in maksimum sayÄ± (Ã¶rneÄŸin 5)
MAX_FOLLOW_UP = 5

# 4ï¸âƒ£ OpenAI Embeddings kullanarak ChromaDB oluÅŸtur ve doldur
embeddings = OpenAIEmbeddings()
vector_store = Chroma(embedding_function=embeddings)
docs = [
    Document(
        page_content=f"{c['title']}: {c['content']} (GeÃ§erlilik: {c['start_date']} - {c['end_date']})",
        metadata={"code": c["code"]}
    )
    for c in campaigns
]
vector_store.add_documents(docs)
retriever = vector_store.as_retriever(search_kwargs={"k": TOP_N})

# 5ï¸âƒ£ LLM Modeli ve Prompt AyarlarÄ±
system_prompt = "Sen bir reklam kampanya asistanÄ±sÄ±n. KullanÄ±cÄ±ya kampanyalar hakkÄ±nda bilgi ver, yanÄ±tlarÄ±nÄ± sadece kampanya metinlerine dayandÄ±r."
follow_up_prompt = (
    "Bu bir takip (follow-up) sorusudur. AÅŸaÄŸÄ±daki konuÅŸma geÃ§miÅŸini ve listelenen kampanyalarÄ± inceleyerek, "
    "kullanÄ±cÄ±nÄ±n hangi kampanya hakkÄ±nda detay istediÄŸini belirle ve sadece o kampanyanÄ±n detaylarÄ±nÄ± ver."
)

llm = ChatOpenAI(model_name="gpt-4", temperature=0, system_prompt=system_prompt)
qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)

# 6ï¸âƒ£ KonuÅŸma HafÄ±zasÄ± ve Global Durum DeÄŸiÅŸkenleri
memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)

# Global kampanya listesi ve takip sayÄ±sÄ±
last_retrieved_campaigns = []   # Son sorgudan dÃ¶nen kampanyalarÄ±n listesini saklar
follow_up_count = 0              # Takip sorgularÄ± iÃ§in sayaÃ§

# Session yÃ¶netimi iÃ§in: kampanya kodu ve session id bilgileri
if "current_campaign_code" not in st.session_state:
    st.session_state["current_campaign_code"] = None
if "session_id" not in st.session_state:
    st.session_state["session_id"] = 0
if "session_counter" not in st.session_state:
    st.session_state["session_counter"] = 0

# Excel loglarÄ±nÄ± tutmak iÃ§in st.session_state kullanÄ±yoruz
if "chat_logs" not in st.session_state:
    st.session_state["chat_logs"] = []

def log_conversation(user_input: str, bot_response: str, campaign_code: str):
    """Her etkileÅŸimi st.session_state Ã¼zerinden kaydeder ve Excel dosyasÄ±na yazar."""
    log_entry = {
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "session_id": st.session_state["session_id"],
        "campaign_code": campaign_code,
        "user_input": user_input,
        "bot_response": bot_response
    }
    st.session_state["chat_logs"].append(log_entry)
    # Pandas DataFrame'e Ã§evirip Excel dosyasÄ±na yazalÄ±m (her mesaj sonrasÄ± gÃ¼ncelleme)
    df = pd.DataFrame(st.session_state["chat_logs"])
    df.to_excel("chat_logs.xlsx", index=False)

def update_session(campaign_code: str):
    """
    Yeni kampanya kodu geldiyse session id gÃ¼ncellenir, 
    aynÄ± kampanya kodu devam ediyorsa aynÄ± session id kullanÄ±lÄ±r.
    """
    if st.session_state["current_campaign_code"] is None:
        st.session_state["current_campaign_code"] = campaign_code
        st.session_state["session_counter"] = 1
        st.session_state["session_id"] = 1
    elif st.session_state["current_campaign_code"] != campaign_code:
        st.session_state["session_counter"] += 1
        st.session_state["current_campaign_code"] = campaign_code
        st.session_state["session_id"] = st.session_state["session_counter"]
    # EÄŸer kampanya kodu aynÄ± ise, session_id deÄŸiÅŸmeden kalÄ±r.

# 7ï¸âƒ£ Yeni Kampanya SorgularÄ±nÄ± DoÄŸal Dil ile Tespit Eden Fonksiyon
def detect_new_campaign(user_input: str):
    """
    EÄŸer sorguda doÄŸrudan kampanya kodu geÃ§miyorsa,
    vector store Ã¼zerinden ilgili kampanyalarÄ± getirir.
    
    - EÄŸer tek bir kampanya bulunursa, kampanyanÄ±n contentâ€™i ve kullanÄ±cÄ±nÄ±n sorusu ile LLM'den yanÄ±t alÄ±nÄ±r.
    - EÄŸer birden fazla kampanya bulunursa, TOP_N kadar sonuÃ§ liste halinde sunulur.
    """
    global last_retrieved_campaigns
    if re.search(r"KAMP\d{3}", user_input, re.IGNORECASE):
        return None  # Sorguda aÃ§Ä±k kampanya kodu varsa bu fonksiyon devreye girmez.

    retrieved_docs = retriever.get_relevant_documents(user_input)
    if not retrieved_docs:
        return "ÃœzgÃ¼nÃ¼m, sorgunuza uygun kampanya bulunamadÄ±."
    
    last_retrieved_campaigns = retrieved_docs

    # EÄŸer sadece 1 kampanya bulunduysa, session gÃ¼ncellemesi yapalÄ±m.
    if len(retrieved_docs) == 1:
        doc = retrieved_docs[0]
        campaign_code = doc.metadata.get("code", "").upper()
        update_session(campaign_code)
        response = qa_chain.run(
            f"{system_prompt}\nKullanÄ±cÄ±: {user_input}\nBu kampanya hakkÄ±nda: {doc.page_content}"
        )
        return response
    else:
        # Birden fazla kampanya bulunursa, TOP_N kadar sonuÃ§ liste halinde sunulur.
        response_lines = ["Ä°lgili kampanyalar:"]
        for i, doc in enumerate(retrieved_docs[:TOP_N], start=1):
            title = doc.page_content.split(":")[0].strip()
            code = doc.metadata.get("code", "Bilinmiyor")
            response_lines.append(f"{i}. {code}: {title}")
        return "\n".join(response_lines)

# 8ï¸âƒ£ KullanÄ±cÄ± Girdilerini Ä°ÅŸleyen Fonksiyon
def chat_with_bot(user_input: str):
    global last_retrieved_campaigns, follow_up_count
    try:
        logger.info(f"KullanÄ±cÄ± giriÅŸi: {user_input}")
        chat_history = memory.load_memory_variables({})["chat_history"]

        # (A) Sorguda aÃ§Ä±kÃ§a kampanya kodu varsa:
        code_match = re.search(r"(KAMP\d{3})", user_input, re.IGNORECASE)
        if code_match:
            campaign_code = code_match.group(1).upper()
            update_session(campaign_code)
            selected_doc = next((doc for doc in docs if doc.metadata.get("code", "").upper() == campaign_code), None)
            if selected_doc:
                last_retrieved_campaigns = [selected_doc]
                follow_up_count = 0
                memory.clear()  # KonuÅŸma geÃ§miÅŸini temizle
                # KampanyanÄ±n contentâ€™i ve kullanÄ±cÄ±nÄ±n sorusu ile LLMâ€™den yanÄ±t alÄ±nÄ±r.
                response = qa_chain.run(
                    f"{system_prompt}\nKullanÄ±cÄ±: {user_input}\nBu kampanya hakkÄ±nda: {selected_doc.page_content}"
                )
                log_conversation(user_input, response, campaign_code)
                memory.save_context({"input": user_input}, {"output": response})
                return response
            else:
                return "Belirtilen kampanya bulunamadÄ±."

        # (B) EÄŸer Ã¶nceki kampanya listesi boÅŸsa, yeni sorgu olarak ele al:
        if not last_retrieved_campaigns:
            new_campaign_response = detect_new_campaign(user_input)
            # EÄŸer tek kampanya bulunduysa, session bilgileri detect_new_campaign iÃ§inde gÃ¼ncellenecektir.
            # Kampanya kodÄ±nÄ±, global listeden (varsa) alalÄ±m.
            campaign_code = last_retrieved_campaigns[0].metadata.get("code", "").upper() if last_retrieved_campaigns else ""
            log_conversation(user_input, new_campaign_response, campaign_code)
            memory.save_context({"input": user_input}, {"output": new_campaign_response})
            return new_campaign_response

        # (C) Gelen sorgu bir takip (follow-up) sorgusuysa:
        if follow_up_count >= MAX_FOLLOW_UP:
            last_retrieved_campaigns = []
            memory.clear()  # KonuÅŸma geÃ§miÅŸini temizle
            follow_up_count = 0
            return "Maksimum takip soru sÄ±nÄ±rÄ±na ulaÅŸÄ±ldÄ±. LÃ¼tfen yeni kampanya sorgusu yapÄ±nÄ±z."

        # Takip sorgusunda, LLMâ€™den Ã¶nceki listelenen kampanyalar ve konuÅŸma geÃ§miÅŸi Ã¼zerinden hangi kampanyaya atÄ±fta bulunduÄŸunu belirlemesi istenir.
        campaigns_context = "\n".join(
            f"{doc.metadata.get('code','Bilinmiyor')}: {doc.page_content}"
            for doc in last_retrieved_campaigns
        )
        determination_prompt = (
            f"AÅŸaÄŸÄ±daki listelenen kampanyalar iÃ§erisinden, kullanÄ±cÄ±nÄ±n aÅŸaÄŸÄ±daki sorgusuyla en Ã§ok hangi kampanyaya atÄ±fta bulunduÄŸunu belirle. "
            f"EÄŸer sorgu, listelenen kampanyalarla ilgili deÄŸilse, sadece 'yeni kampanya' yaz.\n\n"
            f"Listelenen Kampanyalar:\n{campaigns_context}\n\n"
            f"KullanÄ±cÄ±nÄ±n Sorgusu: {user_input}\n\n"
            f"YanÄ±t (sadece ilgili kampanya kodunu ya da 'yeni kampanya' ifadesini ver): "
        )
        determination = llm.run(determination_prompt).strip().lower()
        logger.info(f"Determination: {determination}")

        if "yeni kampanya" in determination:
            last_retrieved_campaigns = []
            memory.clear()  # KonuÅŸma geÃ§miÅŸini temizle
            follow_up_count = 0
            new_campaign_response = detect_new_campaign(user_input)
            campaign_code = last_retrieved_campaigns[0].metadata.get("code", "").upper() if last_retrieved_campaigns else ""
            log_conversation(user_input, new_campaign_response, campaign_code)
            memory.save_context({"input": user_input}, {"output": new_campaign_response})
            return new_campaign_response
        else:
            campaign_code_match = re.search(r"(KAMP\d{3})", determination, re.IGNORECASE)
            if campaign_code_match:
                campaign_code = campaign_code_match.group(1).upper()
                selected_doc = next((doc for doc in last_retrieved_campaigns if doc.metadata.get("code", "").upper() == campaign_code), None)
                if not selected_doc:
                    return "Listede belirtilen kampanya bulunamadÄ±."
                update_session(campaign_code)
            else:
                return "LÃ¼tfen hangi kampanyadan bahsettiÄŸinizi netleÅŸtiriniz."
            
            follow_up_count += 1
            response = qa_chain.run(
                f"{follow_up_prompt}\nKullanÄ±cÄ±: {user_input}\nBu kampanya hakkÄ±nda: {selected_doc.page_content}\nKonuÅŸma GeÃ§miÅŸi:\n{chat_history}"
            )
            log_conversation(user_input, response, campaign_code)
            memory.save_context({"input": user_input}, {"output": response})
            return response

    except Exception as e:
        logger.error(f"Chat iÅŸleminde hata: {e}")
        return "Bir hata oluÅŸtu, lÃ¼tfen tekrar deneyin."

# 9ï¸âƒ£ Streamlit ArayÃ¼zÃ¼
st.title("ğŸ“¢ Reklam Kampanya Chatbotu")
st.write("SorularÄ±nÄ±zÄ± sorun, kampanyalar hakkÄ±nda bilgi alÄ±n!")
st.markdown("---")

# Sohbet geÃ§miÅŸini gÃ¶stermek iÃ§in basit bir alan
if "conversation" not in st.session_state:
    st.session_state["conversation"] = []

user_input = st.text_input("MesajÄ±nÄ±zÄ± girin:")

if st.button("GÃ¶nder"):
    if user_input:
        bot_response = chat_with_bot(user_input)
        # KonuÅŸma geÃ§miÅŸini gÃ¼ncelleyelim (sadece metin olarak)
        st.session_state["conversation"].append(("KullanÄ±cÄ±", user_input))
        st.session_state["conversation"].append(("Bot", bot_response))
        # Sohbet geÃ§miÅŸini ekranda gÃ¶sterelim
        for speaker, message in st.session_state["conversation"]:
            if speaker == "KullanÄ±cÄ±":
                st.markdown(f"**KullanÄ±cÄ±:** {message}")
            else:
                st.markdown(f"**Bot:** {message}")


























Ä°ÅŸte tÃ¼m gereksinimleri karÅŸÄ±layan gÃ¼ncel kod sÃ¼rÃ¼mÃ¼ (TÃ¼rkÃ§e yorum satÄ±rlarÄ± ile birlikte):

```python
"""
ğŸ¯ AKILLI KAMPANYA ASÄ°STANI v3.1
Ã–zellikler:
- Parametrik TarihÃ§e YÃ¶netimi
- BaÄŸlamsal KonuÅŸma DesteÄŸi
- Dinamik SÄ±nÄ±r Kontrolleri
"""

# ------------------------------ ğŸ“¦ PAKETLER ------------------------------
import os
import openai
import streamlit as st
import logging
import json
import numpy as np
from elasticsearch import Elasticsearch
from dotenv import load_dotenv
from typing import Optional, List, Dict, Tuple
from sentence_transformers import SentenceTransformer

# ------------------------------ âš™ï¸ KONFÄ°GÃœRASYON ------------------------------
load_dotenv()

class HistoryConfig:
    """TarihÃ§e yÃ¶netimi iÃ§in parametreler"""
    MAX_HISTORY_LENGTH = 10          # Maksimum saklanacak mesaj sayÄ±sÄ±
    CONTEXT_HISTORY_COUNT = 3        # BaÄŸlam iÃ§in kullanÄ±lacak mesaj Ã§ifti sayÄ±sÄ±
    ENABLE_HISTORY = True            # TarihÃ§e kaydÄ±nÄ± aktif/pasif yap
    AUTO_PRUNE = True                # Otomatik temizlik aktif mi?
    ALLOWED_ROLES = ("user", "assistant")  # Ä°zin verilen roller

class AIConfig:
    """AI ile ilgili ayarlar"""
    EMBEDDING_MODEL_NAME = "all-MiniLM-L6-v2"
    MODEL_CACHE_PATH = "./model_cache"
    LLM_MODEL = "gpt-4-turbo"

class ElasticConfig:
    """Elasticsearch ayarlarÄ±"""
    ELASTICSEARCH_URL = os.getenv("ELASTICSEARCH_URL")
    INDEX_NAME = "campaigns"
    VECTOR_FIELD = "campaign_header_description_embedding_vector"
    KNN_K = 3

# ------------------------------ ğŸ¤– SÄ°STEM Ä°NÄ°T ------------------------------
es = Elasticsearch(ElasticConfig.ELASTICSEARCH_URL)
embedding_model = SentenceTransformer(
    AIConfig.EMBEDDING_MODEL_NAME,
    cache_folder=AIConfig.MODEL_CACHE_PATH
)

# ------------------------------ ğŸ“ LOGGING ------------------------------
logging.basicConfig(
    filename="campaign_assistant.log",
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S"
)

def log_event(event_type: str, message: str):
    """Log kaydÄ± oluÅŸturma"""
    logging.info(f"[{event_type.upper()}] {message}")

# ------------------------------ ğŸ§  HISTORY MANAGER ------------------------------
class HistoryManager:
    """KonuÅŸma tarihÃ§esi yÃ¶netim sÄ±nÄ±fÄ±"""
    
    @staticmethod
    def initialize():
        """Session state'i baÅŸlat"""
        if "conversation_history" not in st.session_state:
            st.session_state.conversation_history = []
            
    @staticmethod
    def add_message(role: str, content: str):
        """Yeni mesaj ekleme"""
        if role not in HistoryConfig.ALLOWED_ROLES:
            log_event("HISTORY_ERROR", f"GeÃ§ersiz rol: {role}")
            return
            
        if HistoryConfig.ENABLE_HISTORY:
            st.session_state.conversation_history.append({
                "role": role,
                "content": content
            })
            HistoryManager._apply_limits()
            
    @staticmethod
    def clear_history():
        """TÃ¼m tarihÃ§eyi temizle"""
        if HistoryConfig.ENABLE_HISTORY:
            st.session_state.conversation_history = []
            log_event("HISTORY", "TarihÃ§e temizlendi")
    
    @staticmethod
    def _apply_limits():
        """TarihÃ§e sÄ±nÄ±rlarÄ±nÄ± uygula"""
        if HistoryConfig.AUTO_PRUNE:
            current_len = len(st.session_state.conversation_history)
            if current_len > HistoryConfig.MAX_HISTORY_LENGTH:
                remove_count = current_len - HistoryConfig.MAX_HISTORY_LENGTH
                st.session_state.conversation_history = st.session_state.conversation_history[remove_count:]
                log_event("HISTORY", f"{remove_count} eski mesaj silindi")
    
    @staticmethod
    def get_context_history() -> List[Tuple[str, str]]:
        """BaÄŸlam iÃ§in kullanÄ±lacak tarihÃ§eyi getir"""
        # Her bir Ã§ift iÃ§in 2 mesaj olduÄŸundan count*2 alÄ±yoruz
        lookback = HistoryConfig.CONTEXT_HISTORY_COUNT * 2
        return HistoryManager.get_formatted_history()[-lookback:]
    
    @staticmethod
    def get_formatted_history() -> List[Tuple[str, str]]:
        """FormatlanmÄ±ÅŸ tÃ¼m tarihÃ§eyi getir"""
        return [(msg["role"], msg["content"]) for msg in st.session_state.conversation_history]

# ------------------------------ ğŸ”§ YARDIMCI FONKSÄ°YONLAR ------------------------------
def get_embedding(text: str) -> List[float]:
    """Metni vektÃ¶re dÃ¶nÃ¼ÅŸtÃ¼r"""
    try:
        return embedding_model.encode(
            text,
            convert_to_numpy=True,
            normalize_embeddings=True
        ).tolist()
    except Exception as e:
        log_event("EMBEDDING_ERROR", f"Hata: {str(e)}")
        return []

# ------------------------------ ğŸ” ELASTICSEARCH OPERASYONLARI ------------------------------
def hybrid_search(query: str) -> Tuple[Optional[Dict], List[Dict]]:
    """Hibrit arama stratejisi"""
    campaign_code = extract_campaign_code(query)
    exact_result = exact_campaign_search(campaign_code) if campaign_code else None
    vector_results = vector_semantic_search(query)
    return exact_result, vector_results

def exact_campaign_search(campaign_number: str) -> Optional[Dict]:
    """Tam eÅŸleÅŸme aramasÄ±"""
    try:
        response = es.search(
            index=ElasticConfig.INDEX_NAME,
            body={"query": {"term": {"campaign_number.keyword": campaign_number}}}
        )
        return response['hits']['hits'][0]['_source'] if response['hits']['hits'] else None
    except Exception as e:
        log_event("ELASTICSEARCH_ERROR", f"Exact search error: {str(e)}")
        return None

def vector_semantic_search(query: str) -> List[Dict]:
    """VektÃ¶rel benzerlik aramasÄ±"""
    try:
        query_embedding = get_embedding(query)
        if not query_embedding:
            return []

        response = es.search(
            index=ElasticConfig.INDEX_NAME,
            body={
                "knn": {
                    "field": ElasticConfig.VECTOR_FIELD,
                    "query_vector": query_embedding,
                    "k": ElasticConfig.KNN_K,
                    "num_candidates": 100
                },
                "_source": ["campaign_number", "campaign_header", "campaign_description"]
            }
        )
        return [hit["_source"] for hit in response["hits"]["hits"]]
    except Exception as e:
        log_event("ELASTICSEARCH_ERROR", f"Vector search error: {str(e)}")
        return []

# ------------------------------ ğŸ¤– AI ENTEGRASYONLARI ------------------------------
def extract_campaign_code(query: str) -> Optional[str]:
    """Kampanya kodu Ã§Ä±karma"""
    try:
        response = openai.ChatCompletion.create(
            model=AIConfig.LLM_MODEL,
            messages=[{"role": "user", "content": query}],
            functions=[{
                "name": "extract_campaign_code",
                "description": "Kampanya kodunu Ã§Ä±karÄ±r",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "campaign_number": {"type": "string"}
                    },
                    "required": ["campaign_number"]
                }
            }],
            function_call={"name": "extract_campaign_code"}
        )
        args = json.loads(response.choices[0].message.function_call.arguments)
        return args.get("campaign_number")
    except Exception as e:
        log_event("OPENAI_ERROR", f"Code extraction failed: {str(e)}")
        return None

def generate_response(query: str, context: str) -> str:
    """AkÄ±llÄ± yanÄ±t oluÅŸturma"""
    try:
        # BaÄŸlam iÃ§in son 3 Ã§ift mesajÄ± kullan
        history_context = "\n".join([f"{role}: {content}" for role, content in HistoryManager.get_context_history()])
        
        response = openai.ChatCompletion.create(
            model=AIConfig.LLM_MODEL,
            messages=[
                {"role": "system", "content": f"""
                Kampanya UzmanÄ± Asistan - Son {HistoryConfig.CONTEXT_HISTORY_COUNT} konuÅŸma geÃ§miÅŸi:
                {history_context}
                """},
                {"role": "user", "content": query}
            ],
            temperature=0.3
        )
        return response.choices[0].message.content
    except Exception as e:
        log_event("OPENAI_ERROR", f"LLM response failed: {str(e)}")
        return "ÃœzgÃ¼nÃ¼m, bir hata oluÅŸtu. LÃ¼tfen daha sonra tekrar deneyin."

# ------------------------------ ğŸ–¥ï¸ KULLANICI ARAYÃœZÃœ ------------------------------
def render_sidebar():
    """Yan menÃ¼yÃ¼ oluÅŸtur"""
    with st.sidebar:
        st.header("âš™ï¸ Sistem AyarlarÄ±")
        
        # TarihÃ§e yÃ¶netim dÃ¼ÄŸmeleri
        col1, col2 = st.columns(2)
        with col1:
            if st.button("ğŸ—‘ï¸ TarihÃ§eyi Temizle"):
                HistoryManager.clear_history()
                st.experimental_rerun()
                
        with col2:
            if st.button("ğŸ”„ Otomatik Temizle"):
                HistoryManager._apply_limits()
                st.experimental_rerun()

        # Sistem istatistikleri
        st.markdown(f"""
        **ğŸ“Š Sistem Durumu:**
        - **Maks. TarihÃ§e:** {HistoryConfig.MAX_HISTORY_LENGTH} mesaj
        - **BaÄŸlam Penceresi:** Son {HistoryConfig.CONTEXT_HISTORY_COUNT} Ã§ift
        - **Aktif KayÄ±t:** `{'âœ…' if HistoryConfig.ENABLE_HISTORY else 'âŒ'}`
        - **Mevcut KayÄ±t:** {len(st.session_state.conversation_history)} mesaj
        """)

def render_chat_interface():
    """Ana sohbet arayÃ¼zÃ¼nÃ¼ oluÅŸtur"""
    st.title("ğŸ” AkÄ±llÄ± Kampanya AsistanÄ± v3.1")
    
    # KonuÅŸma geÃ§miÅŸi
    for role, content in HistoryManager.get_formatted_history():
        with st.chat_message(name=role):
            st.markdown(content)
            if role == "assistant" and "Kampanya DetaylarÄ±:" in content:
                with st.expander("ğŸ“œ DetaylarÄ± GÃ¶ster"):
                    st.markdown(f"```json\n{json.dumps(content, indent=2, ensure_ascii=False)}\n```")

    # KullanÄ±cÄ± giriÅŸi
    if user_input := st.chat_input("MesajÄ±nÄ±zÄ± yazÄ±n..."):
        HistoryManager.add_message("user", user_input)
        process_user_query(user_input)

def process_user_query(query: str):
    """Sorgu iÅŸleme mantÄ±ÄŸÄ±"""
    exact_result, vector_results = hybrid_search(query)
    
    if exact_result:
        context = f"""
        âœ… **{exact_result['campaign_number']} NumaralÄ± Kampanya**
        **BaÅŸlÄ±k:** {exact_result['campaign_header']}
        **AÃ§Ä±klama:** {exact_result['campaign_description']}
        """
        response = generate_response(query, context)
        HistoryManager.add_message("assistant", response)
    elif vector_results:
        response = format_search_results(vector_results)
        HistoryManager.add_message("assistant", response)
    else:
        HistoryManager.add_message("assistant", "âš ï¸ Ä°lgili kampanya bulunamadÄ±")
    
    st.experimental_rerun()

def format_search_results(results: List[Dict]) -> str:
    """Arama sonuÃ§larÄ±nÄ± formatla"""
    formatted = ["ğŸ” Arama SonuÃ§larÄ±:"]
    for i, res in enumerate(results, 1):
        formatted.append(f"""
        {i}. **{res['campaign_header']}**  
        `{res['campaign_number']}`  
        {res['campaign_description'][:100]}...
        """)
    return "\n".join(formatted)

# ------------------------------ ğŸš€ UYGULAMA BAÅLATMA ------------------------------
if __name__ == "__main__":
    HistoryManager.initialize()
    render_sidebar()
    render_chat_interface()
```

**Ã–nemli GÃ¼ncellemeler ve AÃ§Ä±klamalar:**

1. **Parametrik TarihÃ§e Kontrolleri:**
   ```python
   class HistoryConfig:
       CONTEXT_HISTORY_COUNT = 3  # BaÄŸlam iÃ§in kullanÄ±lacak mesaj Ã§ifti sayÄ±sÄ±
   ```

2. **BaÄŸlam TabanlÄ± TarihÃ§e YÃ¶netimi:**
   ```python
   def get_context_history() -> List[Tuple[str, str]]:
       lookback = HistoryConfig.CONTEXT_HISTORY_COUNT * 2
       return get_formatted_history()[-lookback:]
   ```

3. **Yeni Sistem Ä°statistikleri:**
   ```python
   st.markdown(f"""
   **ğŸ“Š Sistem Durumu:**
   - **BaÄŸlam Penceresi:** Son {HistoryConfig.CONTEXT_HISTORY_COUNT} Ã§ift
   """)
   ```

4. **GeliÅŸtirilmiÅŸ YanÄ±t Ãœretimi:**
   ```python
   history_context = "\n".join([f"{role}: {content}" for role, content in HistoryManager.get_context_history()])
   ```

5. **Dinamik Detay GÃ¶rÃ¼nÃ¼mÃ¼:**
   ```python
   with st.expander("ğŸ“œ DetaylarÄ± GÃ¶ster"):
       st.markdown(f"```json\n{json.dumps(content, indent=2, ensure_ascii=False)}\n```")
   ```

**Test Senaryosu Ã‡Ä±ktÄ±larÄ± ile Uyumluluk:**

1. **BaÄŸlam Takibi:**  
   Sistem artÄ±k son 3 konuÅŸma Ã§iftini dikkate alarak baÄŸlamsal referanslarÄ± daha iyi yÃ¶netebiliyor.

2. **SÄ±ralÄ± Referanslar:**  
   "ikinci", "3.sÄ±radaki" gibi ifadelerde Ã¶nceki sonuÃ§ listesini koruyarak doÄŸru kampanyayÄ± bulabiliyor.

3. **Dinamik SÄ±nÄ±r YÃ¶netimi:**  
   `MAX_HISTORY_LENGTH` ve `CONTEXT_HISTORY_COUNT` parametreleri baÄŸÄ±msÄ±z olarak yÃ¶netilebiliyor.

**KullanÄ±m Senaryo Ã–rneÄŸi:**

```python
# HistoryConfig.CONTEXT_HISTORY_COUNT = 3 iken
KullanÄ±cÄ±: "1. kampanya nedir?" â†’ TarihÃ§eye eklenir
Asistan: Cevap1 â†’ TarihÃ§eye eklenir

KullanÄ±cÄ±: "2. kampanyayÄ± aÃ§Ä±kla" â†’ Ã–nceki 2 mesaj baÄŸlama dahil
Asistan: Cevap2 â†’ TarihÃ§eye eklenir

KullanÄ±cÄ±: "Son kampanyada ne vardÄ±?" â†’ TÃ¼m 6 mesaj baÄŸlamda kullanÄ±lÄ±r
Asistan: TÃ¼m tarihÃ§eyi kullanarak cevap verir
```

**YapÄ±landÄ±rma SeÃ§enekleri:**
```python
# BaÄŸlam derinliÄŸini deÄŸiÅŸtirmek iÃ§in
HistoryConfig.CONTEXT_HISTORY_COUNT = 5  # Son 5 konuÅŸma Ã§iftini kullan

# TarihÃ§e boyutunu ayarlamak iÃ§in
HistoryConfig.MAX_HISTORY_LENGTH = 20  # Maksimum 20 mesaj sakla
```

Bu gÃ¼ncellemelerle sistem, kullanÄ±cÄ± etkileÅŸimlerini daha akÄ±llÄ± bir ÅŸekilde takip edebiliyor ve karmaÅŸÄ±k sorgulara baÄŸlama duyarlÄ± yanÄ±tlar Ã¼retebiliyor.






"""
ğŸ¯ AKILLI KAMPANYA ASÄ°STANI v3.1
Ã–zellikler:
- Parametrik TarihÃ§e YÃ¶netimi
- BaÄŸlamsal KonuÅŸma DesteÄŸi
- Dinamik SÄ±nÄ±r Kontrolleri
"""

# ------------------------------ ğŸ“¦ PAKETLER ------------------------------
import os
import openai
import streamlit as st
import logging
import json
import numpy as np
from elasticsearch import Elasticsearch
from dotenv import load_dotenv
from typing import Optional, List, Dict, Tuple
from sentence_transformers import SentenceTransformer

# ------------------------------ âš™ï¸ KONFÄ°GÃœRASYON ------------------------------
load_dotenv()

class HistoryConfig:
    """TarihÃ§e yÃ¶netimi iÃ§in parametreler"""
    MAX_HISTORY_LENGTH = 10          # Maksimum saklanacak mesaj sayÄ±sÄ±
    CONTEXT_HISTORY_COUNT = 3        # BaÄŸlam iÃ§in kullanÄ±lacak mesaj Ã§ifti sayÄ±sÄ±
    ENABLE_HISTORY = True            # TarihÃ§e kaydÄ±nÄ± aktif/pasif yap
    AUTO_PRUNE = True                # Otomatik temizlik aktif mi?
    ALLOWED_ROLES = ("user", "assistant")  # Ä°zin verilen roller

class AIConfig:
    """AI ile ilgili ayarlar"""
    EMBEDDING_MODEL_NAME = "all-MiniLM-L6-v2"
    MODEL_CACHE_PATH = "./model_cache"
    LLM_MODEL = "gpt-4-turbo"

class ElasticConfig:
    """Elasticsearch ayarlarÄ±"""
    ELASTICSEARCH_URL = os.getenv("ELASTICSEARCH_URL")
    INDEX_NAME = "campaigns"
    VECTOR_FIELD = "campaign_header_description_embedding_vector"
    KNN_K = 3

# ------------------------------ ğŸ¤– SÄ°STEM Ä°NÄ°T ------------------------------
es = Elasticsearch(ElasticConfig.ELASTICSEARCH_URL)
embedding_model = SentenceTransformer(
    AIConfig.EMBEDDING_MODEL_NAME,
    cache_folder=AIConfig.MODEL_CACHE_PATH
)

# ------------------------------ ğŸ“ LOGGING ------------------------------
logging.basicConfig(
    filename="campaign_assistant.log",
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S"
)

def log_event(event_type: str, message: str):
    """Log kaydÄ± oluÅŸturma"""
    logging.info(f"[{event_type.upper()}] {message}")

# ------------------------------ ğŸ§  HISTORY MANAGER ------------------------------
class HistoryManager:
    """KonuÅŸma tarihÃ§esi yÃ¶netim sÄ±nÄ±fÄ±"""
    
    @staticmethod
    def initialize():
        """Session state'i baÅŸlat"""
        if "conversation_history" not in st.session_state:
            st.session_state.conversation_history = []
            
    @staticmethod
    def add_message(role: str, content: str):
        """Yeni mesaj ekleme"""
        if role not in HistoryConfig.ALLOWED_ROLES:
            log_event("HISTORY_ERROR", f"GeÃ§ersiz rol: {role}")
            return
            
        if HistoryConfig.ENABLE_HISTORY:
            st.session_state.conversation_history.append({
                "role": role,
                "content": content
            })
            HistoryManager._apply_limits()
            
    @staticmethod
    def clear_history():
        """TÃ¼m tarihÃ§eyi temizle"""
        if HistoryConfig.ENABLE_HISTORY:
            st.session_state.conversation_history = []
            log_event("HISTORY", "TarihÃ§e temizlendi")
    
    @staticmethod
    def _apply_limits():
        """TarihÃ§e sÄ±nÄ±rlarÄ±nÄ± uygula"""
        if HistoryConfig.AUTO_PRUNE:
            current_len = len(st.session_state.conversation_history)
            if current_len > HistoryConfig.MAX_HISTORY_LENGTH:
                remove_count = current_len - HistoryConfig.MAX_HISTORY_LENGTH
                st.session_state.conversation_history = st.session_state.conversation_history[remove_count:]
                log_event("HISTORY", f"{remove_count} eski mesaj silindi")
    
    @staticmethod
    def get_context_history() -> List[Tuple[str, str]]:
        """BaÄŸlam iÃ§in kullanÄ±lacak tarihÃ§eyi getir"""
        # Her bir Ã§ift iÃ§in 2 mesaj olduÄŸundan count*2 alÄ±yoruz
        lookback = HistoryConfig.CONTEXT_HISTORY_COUNT * 2
        return HistoryManager.get_formatted_history()[-lookback:]
    
    @staticmethod
    def get_formatted_history() -> List[Tuple[str, str]]:
        """FormatlanmÄ±ÅŸ tÃ¼m tarihÃ§eyi getir"""
        return [(msg["role"], msg["content"]) for msg in st.session_state.conversation_history]

# ------------------------------ ğŸ”§ YARDIMCI FONKSÄ°YONLAR ------------------------------
def get_embedding(text: str) -> List[float]:
    """Metni vektÃ¶re dÃ¶nÃ¼ÅŸtÃ¼r"""
    try:
        return embedding_model.encode(
            text,
            convert_to_numpy=True,
            normalize_embeddings=True
        ).tolist()
    except Exception as e:
        log_event("EMBEDDING_ERROR", f"Hata: {str(e)}")
        return []

# ------------------------------ ğŸ” ELASTICSEARCH OPERASYONLARI ------------------------------
def hybrid_search(query: str) -> Tuple[Optional[Dict], List[Dict]]:
    """Hibrit arama stratejisi"""
    campaign_code = extract_campaign_code(query)
    exact_result = exact_campaign_search(campaign_code) if campaign_code else None
    vector_results = vector_semantic_search(query)
    return exact_result, vector_results

def exact_campaign_search(campaign_number: str) -> Optional[Dict]:
    """Tam eÅŸleÅŸme aramasÄ±"""
    try:
        response = es.search(
            index=ElasticConfig.INDEX_NAME,
            body={"query": {"term": {"campaign_number.keyword": campaign_number}}}
        )
        return response['hits']['hits'][0]['_source'] if response['hits']['hits'] else None
    except Exception as e:
        log_event("ELASTICSEARCH_ERROR", f"Exact search error: {str(e)}")
        return None

def vector_semantic_search(query: str) -> List[Dict]:
    """VektÃ¶rel benzerlik aramasÄ±"""
    try:
        query_embedding = get_embedding(query)
        if not query_embedding:
            return []

        response = es.search(
            index=ElasticConfig.INDEX_NAME,
            body={
                "knn": {
                    "field": ElasticConfig.VECTOR_FIELD,
                    "query_vector": query_embedding,
                    "k": ElasticConfig.KNN_K,
                    "num_candidates": 100
                },
                "_source": ["campaign_number", "campaign_header", "campaign_description"]
            }
        )
        return [hit["_source"] for hit in response["hits"]["hits"]]
    except Exception as e:
        log_event("ELASTICSEARCH_ERROR", f"Vector search error: {str(e)}")
        return []

# ------------------------------ ğŸ¤– AI ENTEGRASYONLARI ------------------------------
def extract_campaign_code(query: str) -> Optional[str]:
    """Kampanya kodu Ã§Ä±karma"""
    try:
        response = openai.ChatCompletion.create(
            model=AIConfig.LLM_MODEL,
            messages=[{"role": "user", "content": query}],
            functions=[{
                "name": "extract_campaign_code",
                "description": "Kampanya kodunu Ã§Ä±karÄ±r",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "campaign_number": {"type": "string"}
                    },
                    "required": ["campaign_number"]
                }
            }],
            function_call={"name": "extract_campaign_code"}
        )
        args = json.loads(response.choices[0].message.function_call.arguments)
        return args.get("campaign_number")
    except Exception as e:
        log_event("OPENAI_ERROR", f"Code extraction failed: {str(e)}")
        return None

def generate_response(query: str, context: str) -> str:
    """AkÄ±llÄ± yanÄ±t oluÅŸturma"""
    try:
        # BaÄŸlam iÃ§in son 3 Ã§ift mesajÄ± kullan
        history_context = "\n".join([f"{role}: {content}" for role, content in HistoryManager.get_context_history()])
        
        response = openai.ChatCompletion.create(
            model=AIConfig.LLM_MODEL,
            messages=[
                {"role": "system", "content": f"""
                Kampanya UzmanÄ± Asistan - Son {HistoryConfig.CONTEXT_HISTORY_COUNT} konuÅŸma geÃ§miÅŸi:
                {history_context}
                """},
                {"role": "user", "content": query}
            ],
            temperature=0.3
        )
        return response.choices[0].message.content
    except Exception as e:
        log_event("OPENAI_ERROR", f"LLM response failed: {str(e)}")
        return "ÃœzgÃ¼nÃ¼m, bir hata oluÅŸtu. LÃ¼tfen daha sonra tekrar deneyin."

# ------------------------------ ğŸ–¥ï¸ KULLANICI ARAYÃœZÃœ ------------------------------
def render_sidebar():
    """Yan menÃ¼yÃ¼ oluÅŸtur"""
    with st.sidebar:
        st.header("âš™ï¸ Sistem AyarlarÄ±")
        
        # TarihÃ§e yÃ¶netim dÃ¼ÄŸmeleri
        col1, col2 = st.columns(2)
        with col1:
            if st.button("ğŸ—‘ï¸ TarihÃ§eyi Temizle"):
                HistoryManager.clear_history()
                st.experimental_rerun()
                
        with col2:
            if st.button("ğŸ”„ Otomatik Temizle"):
                HistoryManager._apply_limits()
                st.experimental_rerun()

        # Sistem istatistikleri
        st.markdown(f"""
        **ğŸ“Š Sistem Durumu:**
        - **Maks. TarihÃ§e:** {HistoryConfig.MAX_HISTORY_LENGTH} mesaj
        - **BaÄŸlam Penceresi:** Son {HistoryConfig.CONTEXT_HISTORY_COUNT} Ã§ift
        - **Aktif KayÄ±t:** `{'âœ…' if HistoryConfig.ENABLE_HISTORY else 'âŒ'}`
        - **Mevcut KayÄ±t:** {len(st.session_state.conversation_history)} mesaj
        """)

def render_chat_interface():
    """Ana sohbet arayÃ¼zÃ¼nÃ¼ oluÅŸtur"""
    st.title("ğŸ” AkÄ±llÄ± Kampanya AsistanÄ± v3.1")
    
    # KonuÅŸma geÃ§miÅŸi
    for role, content in HistoryManager.get_formatted_history():
        with st.chat_message(name=role):
            st.markdown(content)
            if role == "assistant" and "Kampanya DetaylarÄ±:" in content:
                with st.expander("ğŸ“œ DetaylarÄ± GÃ¶ster"):
                    st.markdown(f"```json\n{json.dumps(content, indent=2, ensure_ascii=False)}\n```")

    # KullanÄ±cÄ± giriÅŸi
    if user_input := st.chat_input("MesajÄ±nÄ±zÄ± yazÄ±n..."):
        HistoryManager.add_message("user", user_input)
        process_user_query(user_input)

def process_user_query(query: str):
    """Sorgu iÅŸleme mantÄ±ÄŸÄ±"""
    exact_result, vector_results = hybrid_search(query)
    
    if exact_result:
        context = f"""
        âœ… **{exact_result['campaign_number']} NumaralÄ± Kampanya**
        **BaÅŸlÄ±k:** {exact_result['campaign_header']}
        **AÃ§Ä±klama:** {exact_result['campaign_description']}
        """
        response = generate_response(query, context)
        HistoryManager.add_message("assistant", response)
    elif vector_results:
        response = format_search_results(vector_results)
        HistoryManager.add_message("assistant", response)
    else:
        HistoryManager.add_message("assistant", "âš ï¸ Ä°lgili kampanya bulunamadÄ±")
    
    st.experimental_rerun()

def format_search_results(results: List[Dict]) -> str:
    """Arama sonuÃ§larÄ±nÄ± formatla"""
    formatted = ["ğŸ” Arama SonuÃ§larÄ±:"]
    for i, res in enumerate(results, 1):
        formatted.append(f"""
        {i}. **{res['campaign_header']}**  
        `{res['campaign_number']}`  
        {res['campaign_description'][:100]}...
        """)
    return "\n".join(formatted)

# ------------------------------ ğŸš€ UYGULAMA BAÅLATMA ------------------------------
if __name__ == "__main__":
    HistoryManager.initialize()
    render_sidebar()
    render_chat_interface()




























**AkÄ±ÅŸ DiyagramÄ± (Mermaid.js Syntax):**

```mermaid
%%{init: {'theme': 'neutral', 'themeVariables': { 'fontSize': '14px'}}}%%
graph TD
    A[KullanÄ±cÄ± Sorgusu] --> B{Kampanya Kodu Var mÄ±?}
    B -->|Evet| C[Tam EÅŸleÅŸme Ara]
    B -->|HayÄ±r| D[VektÃ¶rel Benzerlik Ara]
    C --> E{SonuÃ§ Bulundu mu?}
    E -->|Evet| F[DetaylarÄ± GÃ¶ster]
    E -->|HayÄ±r| D
    D --> G[SonuÃ§larÄ± Formatla]
    G --> H{Ã–nceki SonuÃ§larda Referans Var mÄ±?}
    H -->|Evet| I[ContextManager'dan Getir]
    H -->|HayÄ±r| J[Yeni SonuÃ§larÄ± GÃ¶ster]
    I --> K[Ä°lgili Kampanya DetayÄ±nÄ± GÃ¶ster]
    J --> L[SonuÃ§larÄ± TarihÃ§eye Ekle]
    K --> L
    F --> L
    L --> M[TarihÃ§e SÄ±nÄ±r KontrolÃ¼]
    M -->|MAX_HISTORY AÅŸÄ±ldÄ±| N[Eski MesajlarÄ± Temizle]
    M -->|Limit Dahilinde| O[Sonraki Sorguyu Bekle]
    N --> O
    O --> A
```

**AkÄ±ÅŸ AÃ§Ä±klamalarÄ±:**

1. **BaÅŸlangÄ±Ã§:** KullanÄ±cÄ± Streamlit arayÃ¼zÃ¼ne sorgu giriyor
2. **Kampanya Kodu Analizi:** 
   - Sorguda kampanya kodu olup olmadÄ±ÄŸÄ± kontrol ediliyor
3. **Tam EÅŸleÅŸme Arama:** 
   - Kod varsa Elasticsearch'te `term` query ile direkt arama
4. **VektÃ¶rel Arama:** 
   - Kod yoksa veya bulunamazsa embedding model ile semantik arama
5. **Context KontrolÃ¼:** 
   - "ikinci", "son" gibi referanslar iÃ§in ContextManager kontrol ediliyor
6. **SonuÃ§ Formatlama:** 
   - SonuÃ§lar kullanÄ±cÄ± dostu formatta dÃ¼zenleniyor
7. **TarihÃ§e YÃ¶netimi:** 
   - `MAX_HISTORY_LENGTH` parametresine gÃ¶re otomatik temizlik
8. **DÃ¶ngÃ¼:** 
   - Sistem yeni sorgular iÃ§in hazÄ±r bekliyor

**Ã–nemli Karar NoktalarÄ±:**

```mermaid
graph TD
    A[ReferanslÄ± Sorgu] --> B{ContextManager'da KayÄ±t Var mÄ±?}
    B -->|Evet| C[Index ile Kampanya Getir]
    B -->|HayÄ±r| D[Elasticsearch'te Yeniden Ara]
    C --> E[DetaylarÄ± GÃ¶ster]
    D --> F[Yeni SonuÃ§larÄ± Ä°ÅŸle]
```

**Sistem BileÅŸenleri:**

```mermaid
classDiagram
    class HistoryManager{
        +initialize()
        +add_message()
        +clear_history()
        +get_context_history()
    }
    
    class ContextManager{
        +update_search_results()
        +get_campaign_by_index()
    }
    
    class Elasticsearch{
        +exact_search()
        +vector_search()
    }
    
    class OpenAI{
        +extract_code()
        +generate_response()
    }
    
    HistoryManager --> ContextManager : Veri PaylaÅŸÄ±mÄ±
    Elasticsearch --> ContextManager : SonuÃ§larÄ± GÃ¼nceller
    OpenAI --> HistoryManager : TarihÃ§eyi KullanÄ±r
```

**Ã–rnek Ã‡alÄ±ÅŸma AkÄ±ÅŸÄ±:**

```mermaid
sequenceDiagram
    participant KullanÄ±cÄ±
    participant Streamlit
    participant ContextManager
    participant Elasticsearch
    
    KullanÄ±cÄ±->>Streamlit: "Migros kampanyalarÄ±"
    Streamlit->>Elasticsearch: vector_search("Migros kampanyalarÄ±")
    Elasticsearch-->>Streamlit: 3 sonuÃ§ dÃ¶ner
    Streamlit->>ContextManager: SonuÃ§larÄ± kaydet
    Streamlit->>KullanÄ±cÄ±: SonuÃ§larÄ± gÃ¶ster
    
    KullanÄ±cÄ±->>Streamlit: "Ä°kinci kampanyayÄ± aÃ§Ä±kla"
    Streamlit->>ContextManager: get_campaign_by_index(2)
    ContextManager-->>Streamlit: MIG-FAMILY detaylarÄ±
    Streamlit->>KullanÄ±cÄ±: Kampanya detaylarÄ±nÄ± gÃ¶ster
```

Bu yapÄ±, kullanÄ±cÄ± etkileÅŸimlerini yÃ¶netirken hem performans hem de baÄŸlamsal tutarlÄ±lÄ±k saÄŸlar. TÃ¼m akÄ±ÅŸ parametrik kontrollerle optimize edilmiÅŸtir.















import streamlit as st
from langchain.chains.conversation.memory import ConversationBufferWindowMemory
from langchain_community.chat_models import AzureChatOpenAI
from langchain.callbacks.base import BaseCallbackHandler

# ğŸ“Œ Bellek YÃ¶netimi (En fazla 3 mesaj tutulacak)
def get_memory(n=3):
    client = AzureChatOpenAI(
        openai_api_key=config_info.azure_api_key,
        openai_api_version=config_info.azure_api_version,
        azure_endpoint=config_info.azure_endpoint,
        deployment_name="cyz",
        model_name="xyz",
        openai_api_type="azure"
    )
    return ConversationBufferWindowMemory(
        llm=client,
        memory_key="chat_history",
        k=n,
        return_messages=True
    )

memory = get_memory(n=3)

# ğŸ“Œ Streaming iÃ§in Callback Handler
class StreamHandler(BaseCallbackHandler):
    def __init__(self, display_element):
        self.display_element = display_element
        self.collected_text = ""

    def on_llm_new_token(self, token: str, **kwargs):
        self.collected_text += token
        self.display_element.markdown(self.collected_text)

# ğŸ“Œ OpenAIâ€™ye Kampanya Bilgisiyle Soru GÃ¶nderme
def ask_openai(user_input, campaign_info=None, follow_up_info=None):
    """
    OpenAI'ye Ã¶zel sistem prompt'larÄ± ile soru gÃ¶nderir.
    """
    if campaign_info:
        system_prompt = f"Kampanya hakkÄ±nda bilgi verilmiÅŸtir. Bu bilgi doÄŸrultusunda soruyu yanÄ±tla:\n\nKampanya Bilgisi: {campaign_info}"
        user_prompt = f"KullanÄ±cÄ± Sorusu: {user_input}\nYanÄ±tÄ± kÄ±sa ve net bir ÅŸekilde ver."
    elif follow_up_info:
        system_prompt = "KullanÄ±cÄ±nÄ±n Ã¶nceki kampanyalarla ilgili mi yoksa tamamen yeni bir konuda mÄ± konuÅŸtuÄŸunu belirle."
        user_prompt = f"Ã–nceki Kampanyalar: {follow_up_info}\nKullanÄ±cÄ±nÄ±n yeni sorusu: {user_input}\nBu Ã¶nceki kampanyalarla alakalÄ± mÄ±? EÄŸer alakalÄ±ysa ilgili kampanya kodunu veya baÅŸlÄ±ÄŸÄ±nÄ± dÃ¶ndÃ¼r, deÄŸilse 'HiÃ§biri' yaz."
    else:
        system_prompt = "KullanÄ±cÄ± kampanya hakkÄ±nda soru sormuÅŸ olabilir, ancak kesin bir bilgi yok. Soruyu anlamaya Ã§alÄ±ÅŸ ve eÄŸer gerekirse kampanya bilgisi sor."
        user_prompt = f"KullanÄ±cÄ± Sorusu: {user_input}\nYanÄ±tÄ± kÄ±sa ve net bir ÅŸekilde ver."

    model = AzureChatOpenAI(
        openai_api_key=config_info.azure_api_key,
        openai_api_version=config_info.azure_api_version,
        azure_endpoint=config_info.azure_endpoint,
        deployment_name="cyz",
        model_name="xyz",
        openai_api_type="azure"
    )

    response = model.predict(system_prompt + "\n" + user_prompt)
    return response.strip()

# ğŸ“Œ KullanÄ±cÄ± GiriÅŸi Ä°ÅŸleme
def process_user_input(user_input):
    if user_input:
        with st.spinner("ğŸ’­ DÃ¼ÅŸÃ¼nÃ¼yorum..."):
            # ğŸ” Kampanya kodu var mÄ± kontrol et
            campaign_code = extract_campaign_code(user_input)

            if campaign_code:
                # ğŸ“Œ Elasticsearch'ten kampanya bilgisi Ã§ek
                campaign_info = es.search_campaign_by_code(campaign_code)

                # ğŸ“Œ OpenAIâ€™ye soru gÃ¶nder
                response = ask_openai(user_input, campaign_info=campaign_info)

                # ğŸ” HafÄ±zaya ekle
                memory.save_context({"input": user_input, "response": response})

                st.subheader("ğŸ“Œ YanÄ±t")
                st.write(response)

            else:
                # ğŸ“Œ Kampanya kodu yok, en alakalÄ± 3 kampanyayÄ± getir
                search_result, formatted_result = es.search_campaign_by_header(user_input)

                st.subheader("ğŸ“Œ En Ä°yi 3 Kampanya")
                st.write(formatted_result)

                # ğŸ“Œ KullanÄ±cÄ±nÄ±n yeni sorusu Ã¶nceki kampanyalarla mÄ± ilgili?
                follow_up_response = ask_openai(user_input, follow_up_info=formatted_result)

                if follow_up_response.lower() != "hiÃ§biri":
                    st.write(f"ğŸš€ KullanÄ±cÄ±nÄ±n yeni sorusu `{follow_up_response}` kampanyasÄ±yla ilgili.")

                    if follow_up_response.startswith("CAMP-"):
                        # Kampanya kodu bulundu, Elasticsearch'ten bilgi Ã§ek ve OpenAI'ye gÃ¶nder
                        campaign_info = es.search_campaign_by_code(follow_up_response)
                        response = ask_openai(user_input, campaign_info=campaign_info)
                        st.subheader("ğŸ“Œ YanÄ±t")
                        st.write(response)
                    else:
                        # BaÅŸlÄ±k bulundu, Elasticsearch'ten filtreleme yapÄ±lacak
                        campaign_info = es.filter_campaign_by_title(follow_up_response)
                        response = ask_openai(user_input, campaign_info=campaign_info)
                        st.subheader(f"ğŸ“Œ {follow_up_response} KampanyasÄ± Ä°Ã§eriÄŸi")
                        st.write(response)

                else:
                    # ğŸ“Œ HiÃ§bir kampanyayla alakalÄ± deÄŸilse, OpenAIâ€™ye genel soru olarak gÃ¶nder
                    response = ask_openai(user_input)
                    st.subheader("ğŸ“Œ YanÄ±t")
                    st.write(response)

# ğŸ“Œ Streamlit ArayÃ¼zÃ¼
if __name__ == "__main__":
    st.title("ğŸ“¢ Kampanya AsistanÄ±")
    st.markdown("---")

    user_input = st.text_input("LÃ¼tfen kampanya ile ilgili sorunuzu girin:")

    # ğŸ“Œ Bellekteki verileri yÃ¼kleme
    memory_variables = memory.load_memory_variables({})
    chat_history = memory_variables.get('chat_history', [])

    if not isinstance(chat_history, list):
        chat_history = []

    if "top_n_results" not in st.session_state:
        st.session_state.top_n_results = []

    # KullanÄ±cÄ± giriÅŸini iÅŸleme fonksiyonunu Ã§aÄŸÄ±r
    if user_input:
        process_user_input(user_input)

    # ğŸ“Œ Sohbet GeÃ§miÅŸi (En fazla 3 mesaj gÃ¶sterilecek)
    st.subheader("ğŸ’¬ Sohbet GeÃ§miÅŸi")
    for msg in chat_history[-3:]:  # En son 3 mesajÄ± gÃ¶ster
        st.write(msg)







import streamlit as st
from langchain.chains.conversation.memory import ConversationBufferWindowMemory
from langchain_community.chat_models import AzureChatOpenAI
from langchain.callbacks.base import BaseCallbackHandler

# ğŸ“Œ Kampanya kodu kontrolÃ¼
def is_valid_campaign_code(code):
    """
    Kampanya kodunun geÃ§erli olup olmadÄ±ÄŸÄ±nÄ± kontrol eden fonksiyon.
    - Tamamen sayÄ±sal mÄ±?
    - "CAMP-12345" gibi bir formatta mÄ±?
    """
    return code.isdigit() or (code.startswith("CAMP-") and code[5:].isdigit())

# ğŸ“Œ KullanÄ±cÄ± GiriÅŸi Ä°ÅŸleme
def process_user_input(user_input):
    if user_input:
        with st.spinner("ğŸ’­ DÃ¼ÅŸÃ¼nÃ¼yorum..."):
            # ğŸ” Kampanya kodu var mÄ± kontrol et
            campaign_code = extract_campaign_code(user_input)

            if campaign_code:
                # ğŸ“Œ Elasticsearch'ten kampanya bilgisi Ã§ek
                campaign_info = es.search_campaign_by_code(campaign_code)

                # ğŸ“Œ OpenAIâ€™ye soru gÃ¶nder
                response = ask_openai(user_input, campaign_info=campaign_info)

                # ğŸ” HafÄ±zaya ekle
                memory.save_context({"input": user_input, "response": response})

                st.subheader("ğŸ“Œ YanÄ±t")
                st.write(response)

            else:
                # ğŸ“Œ Kampanya kodu yok, en alakalÄ± 3 kampanyayÄ± getir
                search_result, formatted_result = es.search_campaign_by_header(user_input)

                st.subheader("ğŸ“Œ En Ä°yi 3 Kampanya")
                st.write(formatted_result)

                # ğŸ“Œ KullanÄ±cÄ±nÄ±n yeni sorusu Ã¶nceki kampanyalarla mÄ± ilgili?
                follow_up_response = ask_openai(user_input, follow_up_info=formatted_result)

                if is_valid_campaign_code(follow_up_response):
                    st.write(f"ğŸš€ KullanÄ±cÄ±nÄ±n yeni sorusu `{follow_up_response}` kampanyasÄ±yla ilgili.")

                    # Kampanya kodu bulundu, Elasticsearch'ten bilgi Ã§ek ve OpenAI'ye gÃ¶nder
                    campaign_info = es.search_campaign_by_code(follow_up_response)
                    response = ask_openai(user_input, campaign_info=campaign_info)
                    st.subheader("ğŸ“Œ YanÄ±t")
                    st.write(response)

                elif follow_up_response != "HiÃ§biri":
                    # Kampanya adÄ± bulundu, Elasticsearch'te baÅŸlÄ±ÄŸa gÃ¶re arama yapÄ±lacak
                    campaign_info = es.filter_campaign_by_title(follow_up_response)
                    response = ask_openai(user_input, campaign_info=campaign_info)
                    st.subheader(f"ğŸ“Œ {follow_up_response} KampanyasÄ± Ä°Ã§eriÄŸi")
                    st.write(response)

                else:
                    # ğŸ“Œ HiÃ§bir kampanyayla alakalÄ± deÄŸilse, OpenAIâ€™ye genel soru olarak gÃ¶nder
                    response = ask_openai(user_input)
                    st.subheader("ğŸ“Œ YanÄ±t")
                    st.write(response)









import streamlit as st
from langchain.chains.conversation.memory import ConversationBufferWindowMemory
from langchain_community.chat_models import AzureChatOpenAI
from langchain.callbacks.base import BaseCallbackHandler

# ğŸ“Œ Kampanya kodu kontrolÃ¼
def is_valid_campaign_code(code):
    """
    Kampanya kodunun geÃ§erli olup olmadÄ±ÄŸÄ±nÄ± kontrol eden fonksiyon.
    - Tamamen sayÄ±sal mÄ±?
    - "CAMP-12345" gibi bir formatta mÄ±?
    """
    return code.isdigit() or (code.startswith("CAMP-") and code[5:].isdigit())

# ğŸ“Œ KullanÄ±cÄ±nÄ±n yeni sorusunun son mesaj ile ilgili olup olmadÄ±ÄŸÄ±nÄ± doÄŸrulama
def check_follow_up_relevance(user_input, last_message):
    """
    KullanÄ±cÄ±nÄ±n yeni sorusunun sohbet geÃ§miÅŸindeki son mesajla ilgili olup olmadÄ±ÄŸÄ±nÄ± kontrol eder.
    """
    system_prompt = "KullanÄ±cÄ±nÄ±n yeni mesajÄ± Ã¶nceki mesajla ilgili mi? EÄŸer ilgiliyse 'Evet' dÃ¶ndÃ¼r, deÄŸilse 'HayÄ±r' dÃ¶ndÃ¼r."
    user_prompt = f"Ã–nceki Mesaj: {last_message}\nYeni KullanÄ±cÄ± Sorusu: {user_input}"

    model = AzureChatOpenAI(
        openai_api_key=config_info.azure_api_key,
        openai_api_version=config_info.azure_api_version,
        azure_endpoint=config_info.azure_endpoint,
        deployment_name="cyz",
        model_name="xyz",
        openai_api_type="azure"
    )

    response = model.predict(system_prompt + "\n" + user_prompt)
    return response.strip().lower() == "evet"

# ğŸ“Œ KullanÄ±cÄ± GiriÅŸi Ä°ÅŸleme
def process_user_input(user_input):
    if user_input:
        with st.spinner("ğŸ’­ DÃ¼ÅŸÃ¼nÃ¼yorum..."):
            # ğŸ” Kampanya kodu var mÄ± kontrol et
            campaign_code = extract_campaign_code(user_input)

            # ğŸ“Œ Sohbet geÃ§miÅŸinden son mesajÄ± al
            memory_variables = memory.load_memory_variables({})
            chat_history = memory_variables.get('chat_history', [])
            last_message = chat_history[-1] if chat_history else ""

            # ğŸ“Œ Yeni soru Ã¶nceki mesaj ile ilgili mi?
            if last_message and not check_follow_up_relevance(user_input, last_message):
                st.warning("LÃ¼tfen sorunuzu baÅŸka tÃ¼rlÃ¼ tekrar sorunuz.")
                return

            if campaign_code:
                # ğŸ“Œ Elasticsearch'ten kampanya bilgisi Ã§ek
                campaign_info = es.search_campaign_by_code(campaign_code)

                # ğŸ“Œ OpenAIâ€™ye soru gÃ¶nder
                response = ask_openai(user_input, campaign_info=campaign_info)

                # ğŸ” HafÄ±zaya ekle
                memory.save_context({"input": user_input, "response": response})

                st.subheader("ğŸ“Œ YanÄ±t")
                st.write(response)

            else:
                # ğŸ“Œ Kampanya kodu yok, en alakalÄ± 3 kampanyayÄ± getir
                search_result, formatted_result = es.search_campaign_by_header(user_input)

                st.subheader("ğŸ“Œ En Ä°yi 3 Kampanya")
                st.write(formatted_result)

                # ğŸ“Œ KullanÄ±cÄ±nÄ±n yeni sorusu Ã¶nceki kampanyalarla mÄ± ilgili?
                follow_up_response = ask_openai(user_input, follow_up_info=formatted_result)

                if is_valid_campaign_code(follow_up_response):
                    st.write(f"ğŸš€ KullanÄ±cÄ±nÄ±n yeni sorusu `{follow_up_response}` kampanyasÄ±yla ilgili.")

                    # Kampanya kodu bulundu, Elasticsearch'ten bilgi Ã§ek ve OpenAI'ye gÃ¶nder
                    campaign_info = es.search_campaign_by_code(follow_up_response)
                    response = ask_openai(user_input, campaign_info=campaign_info)
                    st.subheader("ğŸ“Œ YanÄ±t")
                    st.write(response)

                elif follow_up_response != "HiÃ§biri":
                    # Kampanya adÄ± bulundu, Elasticsearch'te baÅŸlÄ±ÄŸa gÃ¶re arama yapÄ±lacak
                    campaign_info = es.filter_campaign_by_title(follow_up_response)
                    response = ask_openai(user_input, campaign_info=campaign_info)
                    st.subheader(f"ğŸ“Œ {follow_up_response} KampanyasÄ± Ä°Ã§eriÄŸi")
                    st.write(response)

                else:
                    # ğŸ“Œ KullanÄ±cÄ±nÄ±n sorusu Ã¶nceki mesajla ilgili deÄŸilse, uyarÄ± ver
                    st.warning("LÃ¼tfen sorunuzu baÅŸka tÃ¼rlÃ¼ tekrar sorunuz.")















import streamlit as st
from langchain_community.chat_models import AzureChatOpenAI
from collections import deque

# ğŸ“Œ GeliÅŸmiÅŸ Memory YÃ¶netimi (Son 3 mesaj formatlÄ± saklanacak)
class ConversationMemory:
    def __init__(self, max_size=3):
        self.history = deque(maxlen=max_size)

    def add_message(self, user_input, response):
        """Sohbet geÃ§miÅŸine mesaj ekler"""
        self.history.append({"user": user_input, "bot": response})

    def get_formatted_history(self):
        """GeÃ§miÅŸ mesajlarÄ± formatlÄ± ÅŸekilde dÃ¶ndÃ¼rÃ¼r"""
        return "\n".join([f"KullanÄ±cÄ±: {msg['user']}\nBot: {msg['bot']}" for msg in self.history])

memory = ConversationMemory()

# ğŸ“Œ OpenAIâ€™ye Kampanya Bilgisiyle Soru GÃ¶nderme
def ask_openai(user_input, campaign_info=None, follow_up_info=None):
    """
    OpenAI'ye Ã¶zel sistem prompt'larÄ± ile soru gÃ¶nderir.
    """
    if campaign_info:
        system_prompt = f"Kampanya hakkÄ±nda bilgi verilmiÅŸtir. Bu bilgi doÄŸrultusunda soruyu yanÄ±tla:\n\nKampanya Bilgisi: {campaign_info}"
        user_prompt = f"KullanÄ±cÄ± Sorusu: {user_input}\nYanÄ±tÄ± kÄ±sa ve net bir ÅŸekilde ver."
    elif follow_up_info:
        system_prompt = "KullanÄ±cÄ±nÄ±n Ã¶nceki kampanyalarla ilgili mi yoksa tamamen yeni bir konuda mÄ± konuÅŸtuÄŸunu belirle."
        user_prompt = f"Ã–nceki Kampanyalar: {follow_up_info}\nKullanÄ±cÄ±nÄ±n yeni sorusu: {user_input}\nEÄŸer ilgiliyse ilgili kampanya kodunu veya baÅŸlÄ±ÄŸÄ±nÄ± dÃ¶ndÃ¼r. EÄŸer hiÃ§biri ile ilgili deÄŸilse 'HiÃ§biri' yaz. EÄŸer ilgili deÄŸil ama yeni bir kampanya belirtiyorsa, yeni kampanya adÄ±nÄ± dÃ¶ndÃ¼r."
    else:
        system_prompt = "KullanÄ±cÄ± kampanya hakkÄ±nda soru sormuÅŸ olabilir, ancak kesin bir bilgi yok. Soruyu anlamaya Ã§alÄ±ÅŸ ve eÄŸer gerekirse kampanya bilgisi sor."
        user_prompt = f"KullanÄ±cÄ± Sorusu: {user_input}\nYanÄ±tÄ± kÄ±sa ve net bir ÅŸekilde ver."

    model = AzureChatOpenAI(
        openai_api_key=config_info.azure_api_key,
        openai_api_version=config_info.azure_api_version,
        azure_endpoint=config_info.azure_endpoint,
        deployment_name="cyz",
        model_name="xyz",
        openai_api_type="azure"
    )

    response = model.predict(system_prompt + "\n" + user_prompt)
    return response.strip()

# ğŸ“Œ KullanÄ±cÄ± GiriÅŸi Ä°ÅŸleme
def process_user_input(user_input):
    if user_input:
        with st.spinner("ğŸ’­ DÃ¼ÅŸÃ¼nÃ¼yorum..."):
            # ğŸ” Kampanya kodu var mÄ± kontrol et
            campaign_code = extract_campaign_code(user_input)

            # ğŸ“Œ Sohbet geÃ§miÅŸini al
            formatted_history = memory.get_formatted_history()

            if campaign_code:
                # ğŸ“Œ Elasticsearch'ten kampanya bilgisi Ã§ek
                campaign_info = es.search_campaign_by_code(campaign_code)

                # ğŸ“Œ OpenAIâ€™ye soru gÃ¶nder
                response = ask_openai(user_input, campaign_info=campaign_info)

                # ğŸ” HafÄ±zaya ekle
                memory.add_message(user_input, response)

                st.subheader("ğŸ“Œ YanÄ±t")
                st.write(response)

            else:
                # ğŸ“Œ Kampanya kodu yok, en alakalÄ± 3 kampanyayÄ± getir
                search_result, formatted_result = es.search_campaign_by_header(user_input)

                st.subheader("ğŸ“Œ En Ä°yi 3 Kampanya")
                st.write(formatted_result)

                # ğŸ“Œ KullanÄ±cÄ±nÄ±n yeni sorusu Ã¶nceki kampanyalarla mÄ± ilgili?
                follow_up_response = ask_openai(user_input, follow_up_info=formatted_history)

                if follow_up_response.lower() == "hiÃ§biri":
                    st.warning("LÃ¼tfen sorunuzu baÅŸka tÃ¼rlÃ¼ tekrar sorunuz.")
                    return

                elif follow_up_response.lower().startswith("kampanya kodu:"):
                    campaign_code = follow_up_response.split(":")[1].strip()
                    campaign_info = es.search_campaign_by_code(campaign_code)
                    response = ask_openai(user_input, campaign_info=campaign_info)
                    memory.add_message(user_input, response)
                    st.subheader("ğŸ“Œ YanÄ±t")
                    st.write(response)

                elif follow_up_response.lower().startswith("kampanya adÄ±:"):
                    campaign_title = follow_up_response.split(":")[1].strip()
                    campaign_info = es.filter_campaign_by_title(campaign_title)
                    response = ask_openai(user_input, campaign_info=campaign_info)
                    memory.add_message(user_input, response)
                    st.subheader(f"ğŸ“Œ {campaign_title} KampanyasÄ± Ä°Ã§eriÄŸi")
                    st.write(response)

                else:
                    st.warning(f"Yeni kampanya belirttiniz: {follow_up_response}. AkÄ±ÅŸ yeniden baÅŸlatÄ±lÄ±yor...")
                    process_user_input(f"Yeni kampanya arÄ±yorum: {follow_up_response}")

# ğŸ“Œ Streamlit ArayÃ¼zÃ¼
if __name__ == "__main__":
    st.title("ğŸ“¢ Kampanya AsistanÄ±")
    st.markdown("---")

    user_input = st.text_input("LÃ¼tfen kampanya ile ilgili sorunuzu girin:")

    # KullanÄ±cÄ± giriÅŸini iÅŸleme fonksiyonunu Ã§aÄŸÄ±r
    if user_input:
        process_user_input(user_input)

    # ğŸ“Œ Sohbet GeÃ§miÅŸi
    st.subheader("ğŸ’¬ Sohbet GeÃ§miÅŸi")
    st.write(memory.get_formatted_history())













import streamlit as st
from langchain_community.chat_models import AzureChatOpenAI
from collections import deque

# ğŸ“Œ HafÄ±za (History) YÃ¶netimi: Son 3 mesajÄ± tutan yapÄ±
class ConversationMemory:
    def __init__(self, max_size=3):
        self.history = deque(maxlen=max_size)  # En fazla 3 mesaj tutulur

    def add_message(self, user_input, response):
        """Sohbet geÃ§miÅŸine mesaj ekler (Yeni mesaj en Ã¼ste gelir)."""
        self.history.appendleft({"user": user_input, "bot": response})  # Yeni mesaj en baÅŸa eklenir

    def get_formatted_history(self):
        """GeÃ§miÅŸ mesajlarÄ± zaman sÄ±rasÄ±na gÃ¶re (sondan baÅŸa) formatlÄ± ÅŸekilde dÃ¶ndÃ¼rÃ¼r."""
        return "\n".join([f"KullanÄ±cÄ±: {msg['user']}\nBot: {msg['bot']}" for msg in self.history])

    def clear_memory(self):
        """HafÄ±zayÄ± temizler (Yeni soru geldiÄŸinde sÄ±fÄ±rlamak iÃ§in)."""
        self.history.clear()

memory = ConversationMemory()

# ğŸ“Œ OpenAI'ye Kampanya Bilgisiyle Soru GÃ¶nderme
def ask_openai(user_input, campaign_info=None, history_analysis=None):
    """
    OpenAI'ye Ã¶zel sistem prompt'larÄ± ile soru gÃ¶nderir.
    - Kampanya bilgisi varsa ona gÃ¶re cevaplar.
    - GeÃ§miÅŸ mesajlardan analiz yapÄ±yorsa ona gÃ¶re yorum yapar.
    """
    if campaign_info:
        system_prompt = f"Kampanya bilgisi verilmiÅŸtir. Bu bilgiye gÃ¶re soruyu yanÄ±tla:\n\nKampanya AÃ§Ä±klamasÄ±: {campaign_info}"
        user_prompt = f"KullanÄ±cÄ± Sorusu: {user_input}\nYanÄ±tÄ± kÄ±sa ve net bir ÅŸekilde ver."
    elif history_analysis:
        system_prompt = "KullanÄ±cÄ±nÄ±n yeni mesajÄ±, Ã¶nceki konuÅŸmalar ile ilgili mi? Kampanya kodu mu sÃ¶yledi, baÅŸlÄ±k mÄ± belirtti, yeni mi baÅŸladÄ±? EÄŸer kampanya kodu verdiyse 'Kampanya Kodu: XXX', baÅŸlÄ±k verdiyse 'Kampanya AdÄ±: XXX', hiÃ§birine uymuyorsa 'HiÃ§biri', eÄŸer tamamen farklÄ± yeni bir konuysa 'BaÅŸtan Yeni' dÃ¶ndÃ¼r."
        user_prompt = f"Ã–nceki Mesajlar:\n{history_analysis}\nKullanÄ±cÄ±nÄ±n Yeni Sorusu: {user_input}"

    else:
        system_prompt = "KullanÄ±cÄ± bir kampanya hakkÄ±nda soru sormuÅŸ olabilir. EÄŸer kampanya kodu veya baÅŸlÄ±k belirttiyse, ona gÃ¶re yanÄ±t ver."
        user_prompt = f"KullanÄ±cÄ± Sorusu: {user_input}\nYanÄ±tÄ± kÄ±sa ve net bir ÅŸekilde ver."

    model = AzureChatOpenAI(
        openai_api_key=config_info.azure_api_key,
        openai_api_version=config_info.azure_api_version,
        azure_endpoint=config_info.azure_endpoint,
        deployment_name="cyz",
        model_name="xyz",
        openai_api_type="azure"
    )

    response = model.predict(system_prompt + "\n" + user_prompt)
    return response.strip()

# ğŸ“Œ KullanÄ±cÄ± GiriÅŸi Ä°ÅŸleme
def process_user_input(user_input):
    if user_input:
        with st.spinner("ğŸ’­ DÃ¼ÅŸÃ¼nÃ¼yorum..."):

            # ğŸ“Œ Kampanya kodu var mÄ±?
            campaign_code = extract_campaign_code(user_input)

            # ğŸ“Œ EÄŸer history boÅŸsa (Ä°lk mesaj)
            if len(memory.history) == 0:
                if campaign_code:
                    # Kampanya kodu varsa, Elasticsearch'ten kampanya bilgisi Ã§ek
                    campaign_info = es.search_campaign_by_code(campaign_code)
                    response = ask_openai(user_input, campaign_info=campaign_info)
                    memory.add_message(user_input, response)  # HafÄ±zaya ekle
                    st.subheader("ğŸ“Œ YanÄ±t")
                    st.write(response)
                else:
                    # Kampanya kodu yoksa, Elasticsearch ile top 3 kampanya getir
                    search_result, formatted_result = es.search_campaign_by_header(user_input)
                    st.subheader("ğŸ“Œ En Ä°yi 3 Kampanya")
                    st.write(formatted_result)
            else:
                # ğŸ“Œ History doluysa OpenAIâ€™ye sorarak kullanÄ±cÄ±nÄ±n amacÄ±nÄ± analiz et
                formatted_history = memory.get_formatted_history()
                follow_up_response = ask_openai(user_input, history_analysis=formatted_history)

                # ğŸ” 1. KullanÄ±cÄ± direkt kampanya kodu sÃ¶yledi mi?
                if follow_up_response.lower().startswith("kampanya kodu:"):
                    campaign_code = follow_up_response.split(":")[1].strip()
                    campaign_info = es.search_campaign_by_code(campaign_code)
                    response = ask_openai(user_input, campaign_info=campaign_info)
                    memory.add_message(user_input, response)  # HafÄ±zaya ekle
                    st.subheader("ğŸ“Œ YanÄ±t")
                    st.write(response)

                # ğŸ” 2. KullanÄ±cÄ± kampanya adÄ±nÄ± mÄ± belirtti?
                elif follow_up_response.lower().startswith("kampanya adÄ±:"):
                    campaign_title = follow_up_response.split(":")[1].strip()
                    campaign_info = es.filter_campaign_by_title(campaign_title)
                    response = ask_openai(user_input, campaign_info=campaign_info)
                    memory.add_message(user_input, response)  # HafÄ±zaya ekle
                    st.subheader(f"ğŸ“Œ {campaign_title} KampanyasÄ± Ä°Ã§eriÄŸi")
                    st.write(response)

                # ğŸ” 3. KullanÄ±cÄ±nÄ±n sorusu hiÃ§birine uymadÄ±ysa
                elif follow_up_response.lower() == "hiÃ§biri":
                    st.warning("Soruyu baÅŸka tÃ¼rlÃ¼ sorarsanÄ±z yardÄ±mcÄ± olabilirim.")

                # ğŸ” 4. KullanÄ±cÄ± baÅŸtan yeni bir konu aÃ§tÄ±ysa, hafÄ±zayÄ± sÄ±fÄ±rla
                elif follow_up_response.lower() == "baÅŸtan yeni":
                    memory.clear_memory()
                    st.warning("Yeni bir konu baÅŸlattÄ±nÄ±z, Ã¶nceki konuÅŸmalar sÄ±fÄ±rlandÄ±.")
                    process_user_input(user_input)  # SÃ¼reci baÅŸtan baÅŸlat

# ğŸ“Œ Streamlit ArayÃ¼zÃ¼
if __name__ == "__main__":
    st.title("ğŸ“¢ Kampanya AsistanÄ±")
    st.markdown("---")

    user_input = st.text_input("LÃ¼tfen kampanya ile ilgili sorunuzu girin:")

    if user_input:
        process_user_input(user_input)

    # ğŸ“Œ Sohbet GeÃ§miÅŸi
    st.subheader("ğŸ’¬ Sohbet GeÃ§miÅŸi")
    st.write(memory.get_formatted_history())

















    import os
import json
import logging
import re
import time
import requests
from typing import TypedDict, Optional, Literal, List, Dict
from elasticsearch import Elasticsearch
from elasticsearch.helpers import bulk

# Configuration
AZURE_OPENAI_KEY = os.getenv("AZURE_OPENAI_API_KEY", "your-openai-key")
AZURE_OPENAI_ENDPOINT = os.getenv("AZURE_OPENAI_ENDPOINT", "https://your-openai-endpoint.openai.azure.com")
ES_HOST = os.getenv("ES_HOST", "http://localhost:9200")
ES_INDEX = "banking_campaigns"
EMBEDDING_DEPLOYMENT = "text-embedding-ada-002"
DEPLOYMENT_NAME_INTENT = "gpt-4-intent"
DEPLOYMENT_NAME_RESPONSE = "gpt-4-response"
API_VERSION = "2023-07-01-preview"
EMBEDDING_DIM = 1536  # For text-embedding-ada-002

# Initialize clients
es = Elasticsearch(ES_HOST)
logging.basicConfig(level=logging.INFO)

class ChatbotState(TypedDict):
    user_input: str
    intent: Optional[Literal["retrieval", "follow_up", "general"]]
    conversation_history: List[dict]
    retrieved_info: Optional[dict]
    candidate_campaigns: Optional[List[Dict]]
    current_response: Optional[str]
    last_campaign_mentioned: Optional[str]

def create_es_index():
    """Create Elasticsearch index with hybrid search configuration"""
    body = {
        "settings": {
            "number_of_shards": 1,
            "number_of_replicas": 1,
            "index": {
                "similarity": {
                    "bm25_similarity": {
                        "type": "BM25"
                    }
                }
            }
        },
        "mappings": {
            "properties": {
                "name": {"type": "text"},
                "details": {
                    "type": "text",
                    "fields": {
                        "embedding": {
                            "type": "dense_vector",
                            "dims": EMBEDDING_DIM,
                            "index": True,
                            "similarity": "cosine"
                        }
                    }
                },
                "keywords": {"type": "keyword"},
                "eligibility": {"type": "text"},
                "valid_until": {"type": "date"}
            }
        }
    }
    
    if not es.indices.exists(index=ES_INDEX):
        es.indices.create(index=ES_INDEX, body=body)
        logging.info("Created Elasticsearch index")

def index_campaigns():
    """Index sample banking campaigns with embeddings"""
    campaigns = [
        {
            "name": "Summer Savings Campaign",
            "details": "Earn a 5% bonus interest rate on deposits from June to August.",
            "keywords": ["summer", "savings", "bonus"],
            "eligibility": "Minimum deposit of $1,000 required",
            "valid_until": "2024-08-31"
        },
        {
            "name": "Home Loan Special",
            "details": "Fixed-rate mortgages starting at 3.99% APR with low down payments.",
            "keywords": ["mortgage", "home", "loan"],
            "eligibility": "700+ credit score required",
            "valid_until": "2024-12-31"
        }
    ]
    
    # Generate and add embeddings
    for campaign in campaigns:
        campaign["details.embedding"] = get_embedding(campaign["details"])
    
    # Bulk index documents
    actions = [
        {
            "_op_type": "index",
            "_index": ES_INDEX,
            "_source": campaign
        }
        for campaign in campaigns
    ]
    
    bulk(es, actions)
    logging.info(f"Indexed {len(campaigns)} campaigns")

def get_embedding(text: str) -> List[float]:
    """Get text embedding using Azure OpenAI"""
    url = f"{AZURE_OPENAI_ENDPOINT}/openai/deployments/{EMBEDDING_DEPLOYMENT}/embeddings?api-version={API_VERSION}"
    headers = {"Content-Type": "application/json", "api-key": AZURE_OPENAI_KEY}
    body = {"input": text}
    
    try:
        response = requests.post(url, headers=headers, json=body)
        response.raise_for_status()
        return response.json()["data"][0]["embedding"]
    except Exception as e:
        logging.error(f"Embedding generation failed: {e}")
        return []

def hybrid_search(query: str) -> List[Dict]:
    """Perform hybrid search combining BM25 and vector search"""
    query_embedding = get_embedding(query)
    
    search_body = {
        "query": {
            "bool": {
                "should": [
                    {
                        "match": {
                            "details": {
                                "query": query,
                                "boost": 0.5
                            }
                        }
                    },
                    {
                        "knn": {
                            "details.embedding": {
                                "vector": query_embedding,
                                "k": 10,
                                "num_candidates": 100,
                                "boost": 0.5
                            }
                        }
                    }
                ]
            }
        },
        "size": 3,
        "_source": ["name", "details", "eligibility", "valid_until"]
    }
    
    try:
        result = es.search(index=ES_INDEX, body=search_body)
        return [hit["_source"] for hit in result["hits"]["hits"]]
    except Exception as e:
        logging.error(f"Elasticsearch search failed: {e}")
        return []

def retrieve_campaign_candidates(query: str) -> List[Dict]:
    """Retrieve a list of candidate campaigns using hybrid search"""
    return hybrid_search(query)

def truncate_history(history: List[dict], max_tokens: int = 1000) -> List[dict]:
    """Truncate conversation history based on token count"""
    token_count = 0
    truncated = []
    for msg in reversed(history):
        tokens = len(msg["content"].split()) + 5
        if token_count + tokens > max_tokens:
            break
        token_count += tokens
        truncated.insert(0, msg)
    return truncated

def call_openai(deployment: str, messages: list, temperature: float = 0.3) -> str:
    """Call Azure OpenAI API"""
    url = f"{AZURE_OPENAI_ENDPOINT}/openai/deployments/{deployment}/chat/completions?api-version={API_VERSION}"
    headers = {"Content-Type": "application/json", "api-key": AZURE_OPENAI_KEY}
    body = {"messages": messages, "temperature": temperature, "max_tokens": 500}
    
    try:
        response = requests.post(url, headers=headers, json=body)
        response.raise_for_status()
        return response.json()["choices"][0]["message"]["content"]
    except Exception as e:
        logging.error(f"API call failed: {e}")
        return "I'm having trouble processing your request. Please try again."

def classify_intent(state: ChatbotState) -> ChatbotState:
    """Classify banking intent with LLM"""
    history_str = "\n".join([f"{msg['role']}: {msg['content']}" for msg in truncate_history(state["conversation_history"])])
    
    system_prompt = """Classify banking intent. Respond in JSON with 'intent' and 'reason'."""
    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": f"History:\n{history_str}\n\nQuery: {state['user_input']}"}
    ]
    
    response = call_openai(DEPLOYMENT_NAME_INTENT, messages)
    try:
        result = json.loads(re.search(r'\{.*\}', response, re.DOTALL).group())
        state["intent"] = result.get("intent", "general").lower()
    except:
        state["intent"] = "general"
    
    return state

def generate_response(state: ChatbotState) -> ChatbotState:
    """Generate response using LLM with Elasticsearch context"""
    context = []
    if state["intent"] == "retrieval":
        # Use the selected campaign if available.
        if state.get("retrieved_info"):
            campaign = state["retrieved_info"]
            context.append(
                f"Campaign: {campaign['name']}\n"
                f"Details: {campaign['details']}\n"
                f"Eligibility: {campaign['eligibility']}\n"
                f"Valid Until: {campaign.get('valid_until', 'N/A')}"
            )
            state["last_campaign_mentioned"] = campaign["name"]
        else:
            context.append("No matching campaigns found. Offer general banking help.")
    
    history_str = "\n".join([f"{msg['role']}: {msg['content']}" for msg in truncate_history(state["conversation_history"])[-3:]])
    
    system_prompt = f"""Banking assistant. Use context:
{'\n'.join(context)}

History:
{history_str}"""
    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": state["user_input"]}
    ]
    
    response = call_openai(DEPLOYMENT_NAME_RESPONSE, messages, temperature=0.5)
    state["current_response"] = re.sub(r'\s+', ' ', response).strip()
    state["conversation_history"].append({"role": "assistant", "content": state["current_response"]})
    return state

def handle_campaign_selection(state: ChatbotState) -> bool:
    """
    Check if the current user input is a campaign selection.
    If so, update state["retrieved_info"] with the chosen campaign and clear candidate_campaigns.
    Returns True if a selection was made.
    """
    selection = state["user_input"].strip().lower()
    candidates = state.get("candidate_campaigns", [])
    chosen_campaign = None

    # Try to interpret input as a number (ordinal selection)
    if selection.isdigit():
        index = int(selection) - 1
        if 0 <= index < len(candidates):
            chosen_campaign = candidates[index]
    else:
        # Otherwise try matching campaign name or id.
        for candidate in candidates:
            candidate_name = candidate.get("name", "").lower()
            candidate_id = str(candidate.get("id", "")).lower()  # if an id field exists
            if candidate_name in selection or candidate_id in selection:
                chosen_campaign = candidate
                break

    if chosen_campaign:
        state["retrieved_info"] = chosen_campaign
        state["candidate_campaigns"] = None
        return True
    else:
        print("I couldn't understand your selection. Please try again by specifying a number or campaign name/ID.")
        return False

def main():
    """Main chat loop"""
    create_es_index()
    index_campaigns()
    
    state: ChatbotState = {
        "user_input": "",
        "intent": None,
        "conversation_history": [],
        "retrieved_info": None,
        "candidate_campaigns": None,
        "current_response": None,
        "last_campaign_mentioned": None
    }
    
    print("\nğŸ¦ Welcome to BankAI! Ask about our campaigns or banking services.")
    print("Type 'exit' to end the chat.\n")
    
    while True:
        try:
            user_input = input("You: ").strip()
        except (EOFError, KeyboardInterrupt):
            print("\nğŸ‘‹ Goodbye!")
            break

        if user_input.lower() in ('exit', 'quit'):
            print("\nğŸ’¼ Thank you for using BankAI!")
            break

        state["user_input"] = user_input
        state["conversation_history"].append({"role": "user", "content": user_input})
        
        # If we are in selection mode, handle campaign selection
        if state.get("candidate_campaigns"):
            if not handle_campaign_selection(state):
                # Selection not made, wait for correct input.
                continue
            # Once a valid selection is made, inform the user.
            print(f"Selected campaign: {state['retrieved_info']['name']}")
        
        # Classify intent if not already in selection mode.
        state = classify_intent(state)
        
        if state["intent"] == "retrieval" and not state.get("retrieved_info"):
            # Retrieve candidate campaigns using hybrid search.
            candidates = retrieve_campaign_candidates(user_input)
            if len(candidates) == 0:
                state["retrieved_info"] = None
            elif len(candidates) == 1:
                state["retrieved_info"] = candidates[0]
            else:
                # More than one candidate found; store them for selection.
                state["candidate_campaigns"] = candidates
                print("I found multiple matching campaigns:")
                for i, campaign in enumerate(candidates):
                    campaign_id = campaign.get("id", "N/A")
                    print(f"{i+1}. {campaign.get('name')} (ID: {campaign_id})")
                print("Please select one by typing the corresponding number, campaign name, or campaign ID.")
                continue  # Wait for user selection in next loop iteration
        
        print("ğŸ’­...", end="", flush=True)
        start_time = time.time()
        state = generate_response(state)
        elapsed_time = time.time() - start_time
        
        print(f"\r{' '*20}\r", end="")
        print(f"BankAI: {state['current_response']} (Response time: {elapsed_time:.2f}s)\n")

if __name__ == "__main__":
    main()

