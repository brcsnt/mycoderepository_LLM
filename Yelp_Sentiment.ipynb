{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDrvMTlFpKXB"
      },
      "source": [
        "# Homework: Sentiment Analysis with Yelp Review Dataset\n",
        "\n",
        "https://huggingface.co/datasets/Yelp/yelp_review_full"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEOdW76PBYS7"
      },
      "source": [
        "## What is the Yelp Dataset?\n",
        "\n",
        "This dataset is derived from Yelp reviews, where each review expresses a sentiment (1 to 5 stars) about a particular service, product, or experience. The task focuses on analyzing these reviews to extract the sentiment conveyed.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGEBy-Z7BeUn"
      },
      "source": [
        "##  Motivation\n",
        "\n",
        "Yelp is a platform where users share their experiences and opinions about various businesses, such as restaurants, stores, and services. By analyzing these reviews, we can gain insights into customer satisfaction, identify trends in consumer behavior, and understand the general perception of different businesses. This analysis can be valuable for businesses aiming to improve their services based on customer feedback.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmuH-z1ZBeW6"
      },
      "source": [
        "## Problem Statement\n",
        "\n",
        "The task is to classify each review based on its star rating, ranging from 1 to 5 stars, reflecting the sentiment expressed by the user.\n",
        "This analysis will help understand the general perception of various businesses and services based on user feedback, providing valuable insights into\n",
        "customer satisfaction and areas for improvement for businesses.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjZTF7q2BeZQ"
      },
      "source": [
        "## What Do We Expect from You in This Assignment?\n",
        "\n",
        "We expect you to use NLP techniques and potentially deep learning methods to analyze the text data from Yelp reviews. Your goal is to accurately classify each review based on its star rating, ranging from 1 to 5 stars.\n",
        "This classification will help interpret the sentiment expressed in each review, giving insights into customer satisfaction levels across different businesses.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOtxROcTpVSn"
      },
      "source": [
        "## Dataset Information\n",
        "\n",
        "The Yelp dataset consists of two files:\n",
        "- `yelp_review_train.csv`: Training dataset containing labeled reviews for model training.\n",
        "- `yelp_review_test.csv`: Validation dataset for evaluating the model's performance on unseen data.\n",
        "\n",
        "Each review is associated with a `label` ranging from 0 to 4, where:\n",
        "- `label 0`: 1 star\n",
        "- `label 1`: 2 stars\n",
        "- `label 2`: 3 stars\n",
        "- `label 3`: 4 stars\n",
        "- `label 4`: 5 stars\n",
        "\n",
        "The code provided below includes a step to map these labels to their corresponding star ratings for better interpretability."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnVfKAigDq0d"
      },
      "source": [
        "## If you have any question about the homework, you can contact us at the following e-mail adresses:\n",
        "\n",
        "\n",
        "\n",
        "*   burcusunturlu@gmail.com\n",
        "*   ozgeflzcn@gmail.com\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjXnzMjapk0-"
      },
      "source": [
        "## 1 - Import Libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avrGn5L7pk3o"
      },
      "source": [
        "Main Libraries for you to deploy your model (Feel free to use other libraries that you think helpful):\n",
        "\n",
        "*   Pandas\n",
        "*   Numpy\n",
        "*   Sklearn\n",
        "*   nltk\n",
        "*   keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKhDGTafpk56"
      },
      "source": [
        "## 2 - Importing the Data (65 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bfp1_GuFpk8Q"
      },
      "source": [
        "## 2.1 - Loading the Data\n",
        "\n",
        "\n",
        "*   Import datasets from the file.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dBLzkG_Lwp3g"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the datasets\n",
        "train_df = pd.read_csv('yelp_review_train.csv')\n",
        "val_df = pd.read_csv('yelp_review_test.csv')\n",
        "\n",
        "# Map labels to star ratings\n",
        "label_to_star = {0: '1 star', 1: '2 stars', 2: '3 stars', 3: '4 stars', 4: '5 stars'}\n",
        "train_df['star_rating'] = train_df['label'].map(label_to_star)\n",
        "val_df['star_rating'] = val_df['label'].map(label_to_star)\n",
        "\n",
        "# Display the first few rows to confirm the mapping\n",
        "print(train_df.head())\n",
        "print(val_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3FLQUZyEqE-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "op4AIUbcpk-D"
      },
      "source": [
        "## 2.2 - Exploratory Data Analysis (EDA) (25 points)\n",
        "\n",
        "Please investigate your data according to:\n",
        "* Understand the\n",
        "classes.\n",
        "* Check distributions.\n",
        "* Check null values.\n",
        "* Drop unnecessary columns (e.g., unrelated metadata).\n",
        "* Visualize the data distribution across sentiment categories (1 to 5 stars).\n",
        "* Consider creating other insightful visualizations from the dataset, such as analyzing the average star rating across different categories, frequently used words in positive versus negative reviews, or creating word clouds for each star rating.\n",
        "* What trends or patterns can you identify in the Yelp reviews' star ratings? For instance, are there more positive (4-5 stars) or negative (1-2 stars) reviews?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FMTbu0D6EQi4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QuEXxLegEQm2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9AXj4OY3EQuB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LRyZjvopk_-"
      },
      "source": [
        "## 2.3 - Data Preparation (25 points)\n",
        "\n",
        "* Clean the comments. Remove irrelevant characters (e.g., URLs, mentions). Normalize the text (lowercasing, removing punctuation, etc.).\n",
        "* Remove/unremove stopwords based on your assumption.\n",
        "* Tokenize the comments.\n",
        "* Lemmatize the comments.\n",
        "* Vectorization.\n",
        "* Word count analysis and outlier detection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PuRVQ1STERTb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oPTI-Ic2ERV-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e2jQ2ry7ERZm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tZIOAwvvRLr"
      },
      "source": [
        "## 2.4 - TF(Term Frequency) - IDF(Inverse Document Frequency) (15 points)\n",
        "\n",
        "* Explain TF & IDF.\n",
        "* Apply TF & IDF methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fShYEdzdESEf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g4oMVPQYESHG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fBFwxoDFESJ9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1ZVJq1BvXk2"
      },
      "source": [
        "# 3 - Training Deep Learning Models (30 Points)\n",
        "\n",
        "* Import relevant libraries.\n",
        "* Explain the differences between Neural Networks (NN), Convolutional Neural Networks (CNN), and Recurrent Neural Networks (RNN)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fVL7pgac-IZw"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv1D, GlobalMaxPooling1D, Flatten\n",
        "from keras.layers import Dense, Input, Embedding, Dropout, Activation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQIZXGPOETck"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IoUg42amETfv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0i6xthP1ETkF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxud-Jm3vXnV"
      },
      "source": [
        "## 3.1 - Training NN, RNN and CNN models\n",
        "\n",
        "* Construct models starting from a simple neural network (NN) with a single layer, and incrementally add layers to build more complex architectures. Include experiments with RNN and CNN models, and analyze the performance differences among them.\n",
        "* Experiment with different activation functions, optimizers, and regularization techniques (such as dropout rates). For each trial, document the effects of these changes. For example, observe how adding or removing layers, changing activation functions, or adjusting dropout rates impacts performance.\n",
        "* Tune hyperparameters like learning rate, number of layers, and dropout percentage. Explain how each adjustment affects overfitting, underfitting, and generalization on the test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pSWthCV8EUHo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_tIhIqZhEUJz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-3c4_T9ZEUNX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4 - Model Evaluation on the Validation Set (10 points)\n",
        "\n",
        "* Evaluate the best model's performance on the validation set using a Confusion Matrix along with metrics such as accuracy, precision, recall, and F1-score. How well does the model generalize to new data based on these metrics?\n",
        "\n"
      ],
      "metadata": {
        "id": "AEqTQejXNuBE"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SLD1EA2kCP_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JuoWBVjkCQRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hFw_aQbXCRET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nhoLxfgvXpp"
      },
      "source": [
        "## 4.1 - Testing with your Own Input\n",
        "\n",
        "* You can test the trained model by inputting your own sentences to predict the sentiment:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBI5zxXF-72Q"
      },
      "outputs": [],
      "source": [
        "# Example of testing with a custom input sentence\n",
        "sentence = 'The food and ambiance at this restaurant were fantastic!'\n",
        "tmp_pred, tmp_sentiment = predict(sentence)\n",
        "print(f'The predicted sentiment for the review is: {tmp_sentiment} (based on star ratings)')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dBbqrDp9EVDh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBosLlRAvRN4"
      },
      "source": [
        "# 5 - Bonus - Adding Transformer Layer to the NN Model (15 points)\n",
        "\n",
        "* How can a transformer layer be added to the NN model created in Chapter 3. Research and implement a solution to add a transformer layer to the neural network model. Document your findings, including how the transformer layer integrates with the existing architecture, its impact on model performance, and any adjustments required. Explain your approach and reasoning based on your research."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_VVisRp9EVqn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ew-Y8jssEVtL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r9QK5RZAEVwD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHgWpcvSvRQd"
      },
      "source": [
        "## Additional Notes\n",
        "\n",
        "* Ensure all models and visualizations are well-commented.\n",
        "* Include all explanations for key steps like tokenization, vectorization, hyperparameter tuning and model selection.\n",
        "* Please complete your homework using this notebook."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hLhWvLYTFq_j"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}