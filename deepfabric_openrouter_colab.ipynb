{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DeepFabric ile OpenRouter (GPT-OSS-20B) Kullanarak Sentetik Veri Ãœretimi\n",
        "\n",
        "Bu notebook, Google Colab'da DeepFabric kÃ¼tÃ¼phanesini kullanarak OpenRouter API Ã¼zerinden GPT-OSS-20B modeli ile sentetik veri Ã¼retimini gÃ¶stermektedir.\n",
        "\n",
        "## Ä°Ã§indekiler\n",
        "1. Kurulum ve KonfigÃ¼rasyon\n",
        "2. OpenRouter API BaÄŸlantÄ±sÄ±\n",
        "3. Temel Sentetik Veri Ãœretimi\n",
        "4. FarklÄ± Veri TÃ¼rleri:\n",
        "   - Soru-Cevap Ã‡iftleri\n",
        "   - KonuÅŸma Verileri\n",
        "   - Kod Ã–rnekleri\n",
        "   - Tool Calling Ã–rnekleri\n",
        "5. Veri Analizi ve GÃ¶rselleÅŸtirme\n",
        "6. Fine-tuning iÃ§in HazÄ±rlÄ±k\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Kurulum ve KonfigÃ¼rasyon\n",
        "\n",
        "### DeepFabric Nedir?\n",
        "\n",
        "DeepFabric, yapay zeka modelleri iÃ§in yÃ¼ksek kaliteli eÄŸitim verileri oluÅŸturmak Ã¼zere tasarlanmÄ±ÅŸ bir sentetik veri Ã¼retim framework'Ã¼dÃ¼r.\n",
        "\n",
        "### OpenRouter Nedir?\n",
        "\n",
        "OpenRouter, birden fazla LLM modelini tek bir API Ã¼zerinden kullanmanÄ±zÄ± saÄŸlayan bir servis. OpenAI-uyumlu API formatÄ± kullanÄ±r.\n",
        "\n",
        "### GPT-OSS-20B\n",
        "\n",
        "20 milyar parametre iÃ§eren aÃ§Ä±k kaynak bir dil modeli."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DeepFabric ve gerekli kÃ¼tÃ¼phaneleri kur\n",
        "!pip install deepfabric datasets pandas matplotlib seaborn pyyaml -q\n",
        "\n",
        "print(\"âœ… Kurulum tamamlandÄ±!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Gerekli kÃ¼tÃ¼phaneleri import et\n",
        "import os\n",
        "import json\n",
        "import yaml\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "from datasets import load_dataset\n",
        "from google.colab import userdata\n",
        "\n",
        "# GÃ¶rselleÅŸtirme ayarlarÄ±\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (14, 6)\n",
        "\n",
        "print(\"âœ… KÃ¼tÃ¼phaneler yÃ¼klendi!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. OpenRouter API KonfigÃ¼rasyonu\n",
        "\n",
        "### OpenRouter API Key NasÄ±l AlÄ±nÄ±r?\n",
        "\n",
        "1. https://openrouter.ai/ adresine gidin\n",
        "2. Hesap oluÅŸturun veya giriÅŸ yapÄ±n\n",
        "3. API Keys bÃ¶lÃ¼mÃ¼nden yeni bir key oluÅŸturun\n",
        "4. Key'i kopyalayÄ±n\n",
        "\n",
        "### Google Colab'da API Key KullanÄ±mÄ±\n",
        "\n",
        "**YÃ¶ntem 1: Colab Secrets (Ã–nerilen)**\n",
        "- Sol tarafta ğŸ”‘ (Secrets) simgesine tÄ±klayÄ±n\n",
        "- \"Add new secret\" ile `OPENROUTER_API_KEY` ekleyin\n",
        "\n",
        "**YÃ¶ntem 2: DoÄŸrudan Kod Ä°Ã§inde (Dikkatli kullanÄ±n)**\n",
        "- AÅŸaÄŸÄ±daki hÃ¼crede `YOUR_OPENROUTER_API_KEY_HERE` yerine key'inizi yapÄ±ÅŸtÄ±rÄ±n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# OpenRouter API KonfigÃ¼rasyonu\n",
        "\n",
        "# YÃ¶ntem 1: Colab Secrets kullanarak (Ã–nerilen)\n",
        "try:\n",
        "    OPENROUTER_API_KEY = userdata.get('OPENROUTER_API_KEY')\n",
        "    print(\"âœ… API Key Colab Secrets'dan yÃ¼klendi\")\n",
        "except:\n",
        "    # YÃ¶ntem 2: Manuel olarak girin (Sadece test iÃ§in)\n",
        "    OPENROUTER_API_KEY = \"YOUR_OPENROUTER_API_KEY_HERE\"  # Buraya kendi key'inizi girin\n",
        "    print(\"âš ï¸  API Key manuel olarak girildi\")\n",
        "\n",
        "# OpenRouter konfigÃ¼rasyonu\n",
        "os.environ['OPENAI_API_KEY'] = OPENROUTER_API_KEY\n",
        "os.environ['OPENAI_BASE_URL'] = 'https://openrouter.ai/api/v1'\n",
        "\n",
        "# Model seÃ§imi - OpenRouter'daki model adlarÄ±\n",
        "# GPT-OSS-20B veya baÅŸka modeller:\n",
        "# - \"mistralai/mistral-7b-instruct\"\n",
        "# - \"meta-llama/llama-3.1-8b-instruct\"\n",
        "# - \"qwen/qwen-2.5-7b-instruct\"\n",
        "# - \"google/gemma-2-9b-it\"\n",
        "\n",
        "MODEL_NAME = \"openai/gpt-3.5-turbo\"  # GPT-OSS-20B iÃ§in model adÄ±nÄ± buraya girin\n",
        "PROVIDER = \"openai\"  # OpenRouter, OpenAI-uyumlu API kullanÄ±r\n",
        "\n",
        "print(f\"\\nğŸ“¡ OpenRouter KonfigÃ¼rasyonu:\")\n",
        "print(f\"  Base URL: {os.environ['OPENAI_BASE_URL']}\")\n",
        "print(f\"  Provider: {PROVIDER}\")\n",
        "print(f\"  Model: {MODEL_NAME}\")\n",
        "print(f\"  API Key: {'*' * 20}{OPENROUTER_API_KEY[-8:]}\" if len(OPENROUTER_API_KEY) > 8 else \"  API Key: [SET]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# API baÄŸlantÄ±sÄ±nÄ± test et (Opsiyonel)\n",
        "import requests\n",
        "\n",
        "headers = {\n",
        "    \"Authorization\": f\"Bearer {OPENROUTER_API_KEY}\",\n",
        "    \"Content-Type\": \"application/json\"\n",
        "}\n",
        "\n",
        "test_data = {\n",
        "    \"model\": MODEL_NAME,\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": \"Merhaba, bu bir test mesajÄ±dÄ±r.\"}],\n",
        "    \"max_tokens\": 50\n",
        "}\n",
        "\n",
        "try:\n",
        "    response = requests.post(\n",
        "        \"https://openrouter.ai/api/v1/chat/completions\",\n",
        "        headers=headers,\n",
        "        json=test_data,\n",
        "        timeout=30\n",
        "    )\n",
        "    \n",
        "    if response.status_code == 200:\n",
        "        result = response.json()\n",
        "        print(\"âœ… OpenRouter API baÄŸlantÄ±sÄ± baÅŸarÄ±lÄ±!\")\n",
        "        print(f\"\\nTest YanÄ±tÄ±: {result['choices'][0]['message']['content'][:100]}...\")\n",
        "    else:\n",
        "        print(f\"âŒ BaÄŸlantÄ± hatasÄ±: {response.status_code}\")\n",
        "        print(f\"Hata mesajÄ±: {response.text}\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Hata: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Temel Sentetik Veri Ãœretimi\n",
        "\n",
        "DeepFabric'in CLI kullanarak basit bir sentetik veri seti oluÅŸturalÄ±m."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ã‡alÄ±ÅŸma dizinleri oluÅŸtur\n",
        "output_dir = Path('sentetik_veriler')\n",
        "config_dir = Path('konfigurasyonlar')\n",
        "\n",
        "output_dir.mkdir(exist_ok=True)\n",
        "config_dir.mkdir(exist_ok=True)\n",
        "\n",
        "print(\"âœ… Dizinler oluÅŸturuldu\")\n",
        "print(f\"  Veri Ã§Ä±ktÄ± dizini: {output_dir}\")\n",
        "print(f\"  KonfigÃ¼rasyon dizini: {config_dir}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Basit CLI kullanÄ±mÄ± - Ä°lk sentetik veri setimiz\n",
        "!deepfabric generate \\\n",
        "  --mode tree \\\n",
        "  --provider {PROVIDER} \\\n",
        "  --model \"{MODEL_NAME}\" \\\n",
        "  --depth 2 \\\n",
        "  --degree 2 \\\n",
        "  --num-steps 8 \\\n",
        "  --topic-prompt \"Yapay Zeka ve Makine Ã–ÄŸrenmesi Temelleri\" \\\n",
        "  --dataset-save-as sentetik_veriler/temel_dataset.jsonl\n",
        "\n",
        "print(\"\\nâœ… Temel veri seti oluÅŸturuldu!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# OluÅŸturulan veriyi inceleyelim\n",
        "def veri_goster(dosya_yolu, adet=2):\n",
        "    \"\"\"JSONL dosyasÄ±ndaki verileri gÃ¶sterir\"\"\"\n",
        "    if not Path(dosya_yolu).exists():\n",
        "        print(f\"âŒ Dosya bulunamadÄ±: {dosya_yolu}\")\n",
        "        return\n",
        "    \n",
        "    print(f\"\\nğŸ“Š Veri Seti: {dosya_yolu}\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    with open(dosya_yolu, 'r', encoding='utf-8') as f:\n",
        "        for i, line in enumerate(f):\n",
        "            if i >= adet:\n",
        "                break\n",
        "            \n",
        "            data = json.loads(line)\n",
        "            print(f\"\\nğŸ”¹ Ã–rnek {i+1}:\")\n",
        "            print(\"-\" * 80)\n",
        "            \n",
        "            if 'messages' in data:\n",
        "                for msg in data['messages']:\n",
        "                    role = msg.get('role', 'unknown').upper()\n",
        "                    content = msg.get('content', '')\n",
        "                    print(f\"\\n[{role}]\")\n",
        "                    print(content[:300] if len(content) > 300 else content)\n",
        "                    if len(content) > 300:\n",
        "                        print(\"...\")\n",
        "            else:\n",
        "                print(json.dumps(data, indent=2, ensure_ascii=False)[:500])\n",
        "            \n",
        "            print(\"\\n\" + \"=\" * 80)\n",
        "\n",
        "veri_goster('sentetik_veriler/temel_dataset.jsonl', adet=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. FarklÄ± TÃ¼rde Sentetik Veri Ãœretimi\n",
        "\n",
        "Åimdi farklÄ± use case'ler iÃ§in Ã¶zelleÅŸtirilmiÅŸ veri setleri oluÅŸturalÄ±m."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.1 Soru-Cevap Veri Seti (Q&A Dataset)\n",
        "\n",
        "EÄŸitim ve bilgi amaÃ§lÄ± soru-cevap Ã§iftleri Ã¼retelim."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Soru-Cevap konfigÃ¼rasyonu\n",
        "qa_config = f\"\"\"\n",
        "dataset_system_prompt: |\n",
        "  Sen yardÄ±mcÄ± bir TÃ¼rkÃ§e AI asistanÄ±sÄ±n. Ã–ÄŸrencilere konularÄ± aÃ§Ä±k, \n",
        "  anlaÅŸÄ±lÄ±r ve detaylÄ± ÅŸekilde anlatÄ±yorsun.\n",
        "\n",
        "topic_tree:\n",
        "  topic_prompt: |\n",
        "    Python Programlama Dili:\n",
        "    - Temel veri yapÄ±larÄ± (listeler, dict, tuple, set)\n",
        "    - Fonksiyonlar ve lambda ifadeleri\n",
        "    - Dosya iÅŸlemleri\n",
        "    - Hata yÃ¶netimi (try-except)\n",
        "    - ModÃ¼ller ve paketler\n",
        "  \n",
        "  provider: \"{PROVIDER}\"\n",
        "  model: \"{MODEL_NAME}\"\n",
        "  temperature: 0.7\n",
        "  degree: 3\n",
        "  depth: 2\n",
        "\n",
        "data_engine:\n",
        "  generation_system_prompt: |\n",
        "    Verilen konular hakkÄ±nda TÃ¼rkÃ§e soru-cevap Ã§iftleri oluÅŸtur.\n",
        "    Her cevap:\n",
        "    - AÃ§Ä±k ve anlaÅŸÄ±lÄ±r olmalÄ±\n",
        "    - Ã–rnekler iÃ§ermeli\n",
        "    - Orta seviye teknik detay iÃ§ermeli\n",
        "    - Pratik kullanÄ±m alanlarÄ±nÄ± gÃ¶stermeli\n",
        "  \n",
        "  temperature: 0.6\n",
        "  provider: \"{PROVIDER}\"\n",
        "  model: \"{MODEL_NAME}\"\n",
        "\n",
        "dataset:\n",
        "  creation:\n",
        "    num_steps: 15\n",
        "    batch_size: 2\n",
        "    sys_msg: true\n",
        "  template: \"builtin://chatml.py\"\n",
        "\"\"\"\n",
        "\n",
        "qa_config_path = config_dir / 'qa_config.yaml'\n",
        "with open(qa_config_path, 'w', encoding='utf-8') as f:\n",
        "    f.write(qa_config)\n",
        "\n",
        "print(f\"âœ… Soru-Cevap konfigÃ¼rasyonu oluÅŸturuldu: {qa_config_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Soru-Cevap veri setini Ã¼ret\n",
        "!deepfabric generate \\\n",
        "  --config {qa_config_path} \\\n",
        "  --dataset-save-as sentetik_veriler/python_qa_dataset.jsonl\n",
        "\n",
        "print(\"\\nâœ… Python Soru-Cevap veri seti oluÅŸturuldu!\")\n",
        "veri_goster('sentetik_veriler/python_qa_dataset.jsonl', adet=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2 KonuÅŸma Veri Seti (Conversation Dataset)\n",
        "\n",
        "Ã‡ok turlu, gerÃ§ekÃ§i konuÅŸmalar iÃ§in veri seti."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# KonuÅŸma veri seti konfigÃ¼rasyonu\n",
        "conversation_config = f\"\"\"\n",
        "dataset_system_prompt: |\n",
        "  Sen mÃ¼ÅŸteri hizmetleri temsilcisisin. MÃ¼ÅŸterilere yardÄ±mcÄ±, \n",
        "  nazik ve Ã§Ã¶zÃ¼m odaklÄ± yaklaÅŸÄ±yorsun.\n",
        "\n",
        "topic_tree:\n",
        "  topic_prompt: |\n",
        "    E-ticaret MÃ¼ÅŸteri Hizmetleri SenaryolarÄ±:\n",
        "    - SipariÅŸ takibi ve teslimat sorunlarÄ±\n",
        "    - ÃœrÃ¼n iade ve deÄŸiÅŸim iÅŸlemleri\n",
        "    - Ã–deme ve fatura sorunlarÄ±\n",
        "    - ÃœrÃ¼n bilgileri ve Ã¶neriler\n",
        "    - Hesap ve Ã¼yelik iÅŸlemleri\n",
        "  \n",
        "  provider: \"{PROVIDER}\"\n",
        "  model: \"{MODEL_NAME}\"\n",
        "  temperature: 0.8\n",
        "  degree: 3\n",
        "  depth: 2\n",
        "\n",
        "data_engine:\n",
        "  generation_system_prompt: |\n",
        "    MÃ¼ÅŸteri-temsilci konuÅŸmalarÄ± oluÅŸtur. Her konuÅŸma:\n",
        "    - GerÃ§ekÃ§i ve doÄŸal olmalÄ±\n",
        "    - 3-5 mesaj alÄ±ÅŸveriÅŸi iÃ§ermeli\n",
        "    - MÃ¼ÅŸterinin sorununu Ã§Ã¶zmeli\n",
        "    - Profesyonel ama samimi olmalÄ±\n",
        "    - TÃ¼rkÃ§e yazÄ±m ve ifade kurallarÄ±na uymalÄ±\n",
        "  \n",
        "  temperature: 0.7\n",
        "  provider: \"{PROVIDER}\"\n",
        "  model: \"{MODEL_NAME}\"\n",
        "\n",
        "dataset:\n",
        "  creation:\n",
        "    num_steps: 12\n",
        "    batch_size: 2\n",
        "    sys_msg: true\n",
        "  template: \"builtin://chatml.py\"\n",
        "\"\"\"\n",
        "\n",
        "conv_config_path = config_dir / 'conversation_config.yaml'\n",
        "with open(conv_config_path, 'w', encoding='utf-8') as f:\n",
        "    f.write(conversation_config)\n",
        "\n",
        "print(f\"âœ… KonuÅŸma konfigÃ¼rasyonu oluÅŸturuldu: {conv_config_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# KonuÅŸma veri setini Ã¼ret\n",
        "!deepfabric generate \\\n",
        "  --config {conv_config_path} \\\n",
        "  --dataset-save-as sentetik_veriler/musteri_konusma_dataset.jsonl\n",
        "\n",
        "print(\"\\nâœ… MÃ¼ÅŸteri konuÅŸma veri seti oluÅŸturuldu!\")\n",
        "veri_goster('sentetik_veriler/musteri_konusma_dataset.jsonl', adet=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.3 Kod Ã–rnekleri Veri Seti (Code Examples Dataset)\n",
        "\n",
        "Programlama Ã¶ÄŸretimi iÃ§in kod Ã¶rnekleri iÃ§eren veri seti."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Kod Ã¶rnekleri konfigÃ¼rasyonu\n",
        "code_config = f\"\"\"\n",
        "dataset_system_prompt: |\n",
        "  Sen bir programlama eÄŸitmenisin. Her yanÄ±tta Ã§alÄ±ÅŸan, \n",
        "  aÃ§Ä±klamalÄ± kod Ã¶rnekleri veriyorsun.\n",
        "\n",
        "topic_tree:\n",
        "  topic_prompt: |\n",
        "    Python ile Veri Analizi:\n",
        "    - Pandas ile veri manipÃ¼lasyonu\n",
        "    - NumPy ile matematiksel iÅŸlemler\n",
        "    - Matplotlib ile gÃ¶rselleÅŸtirme\n",
        "    - Veri temizleme ve preprocessing\n",
        "    - Ä°statistiksel analizler\n",
        "  \n",
        "  provider: \"{PROVIDER}\"\n",
        "  model: \"{MODEL_NAME}\"\n",
        "  temperature: 0.6\n",
        "  degree: 3\n",
        "  depth: 2\n",
        "\n",
        "data_engine:\n",
        "  generation_system_prompt: |\n",
        "    Veri analizi hakkÄ±nda soru-cevap Ã¼ret. Her cevap:\n",
        "    1. Konsepti kÄ±saca aÃ§Ä±kla\n",
        "    2. Ã‡alÄ±ÅŸan Python kodu ver\n",
        "    3. Kodu satÄ±r satÄ±r aÃ§Ä±kla\n",
        "    4. Beklenen Ã§Ä±ktÄ±yÄ± gÃ¶ster\n",
        "    5. Pratik kullanÄ±m Ã¶rnekleri ver\n",
        "  \n",
        "  temperature: 0.5\n",
        "  provider: \"{PROVIDER}\"\n",
        "  model: \"{MODEL_NAME}\"\n",
        "\n",
        "dataset:\n",
        "  creation:\n",
        "    num_steps: 12\n",
        "    batch_size: 2\n",
        "    sys_msg: true\n",
        "  template: \"builtin://chatml.py\"\n",
        "\"\"\"\n",
        "\n",
        "code_config_path = config_dir / 'code_config.yaml'\n",
        "with open(code_config_path, 'w', encoding='utf-8') as f:\n",
        "    f.write(code_config)\n",
        "\n",
        "print(f\"âœ… Kod Ã¶rnekleri konfigÃ¼rasyonu oluÅŸturuldu: {code_config_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Kod Ã¶rnekleri veri setini Ã¼ret\n",
        "!deepfabric generate \\\n",
        "  --config {code_config_path} \\\n",
        "  --dataset-save-as sentetik_veriler/python_kod_ornekleri.jsonl\n",
        "\n",
        "print(\"\\nâœ… Python kod Ã¶rnekleri veri seti oluÅŸturuldu!\")\n",
        "veri_goster('sentetik_veriler/python_kod_ornekleri.jsonl', adet=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.4 Tool Calling Veri Seti\n",
        "\n",
        "Fonksiyon Ã§aÄŸÄ±rma ve API kullanÄ±mÄ± iÃ§in veri seti."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tool calling konfigÃ¼rasyonu\n",
        "tool_config = f\"\"\"\n",
        "dataset_system_prompt: |\n",
        "  Sen bir API yardÄ±mcÄ±sÄ±sÄ±n. KullanÄ±cÄ±lara doÄŸru fonksiyonlarÄ± \n",
        "  seÃ§ip Ã§aÄŸÄ±rmayÄ± Ã¶ÄŸretiyorsun.\n",
        "\n",
        "topic_tree:\n",
        "  topic_prompt: |\n",
        "    API ve Fonksiyon Ã‡aÄŸÄ±rma SenaryolarÄ±:\n",
        "    - VeritabanÄ± sorgularÄ± (SQL, NoSQL)\n",
        "    - Dosya iÅŸlemleri (okuma, yazma, silme)\n",
        "    - HTTP istekleri (GET, POST, PUT, DELETE)\n",
        "    - Veri dÃ¶nÃ¼ÅŸÃ¼mleri ve validasyon\n",
        "    - Asenkron iÅŸlemler\n",
        "  \n",
        "  provider: \"{PROVIDER}\"\n",
        "  model: \"{MODEL_NAME}\"\n",
        "  temperature: 0.7\n",
        "  degree: 3\n",
        "  depth: 2\n",
        "\n",
        "data_engine:\n",
        "  generation_system_prompt: |\n",
        "    Fonksiyon Ã§aÄŸÄ±rma Ã¶rnekleri oluÅŸtur. Her Ã¶rnek:\n",
        "    - KullanÄ±cÄ± isteÄŸini iÃ§ermeli\n",
        "    - Uygun fonksiyon(lar)Ä± seÃ§meli\n",
        "    - Parametreleri doÄŸru belirlenmeli\n",
        "    - Fonksiyon Ã§Ä±ktÄ±sÄ±nÄ± yorumlamalÄ±\n",
        "    - Hata durumlarÄ±nÄ± ele almalÄ±\n",
        "  \n",
        "  temperature: 0.6\n",
        "  provider: \"{PROVIDER}\"\n",
        "  model: \"{MODEL_NAME}\"\n",
        "\n",
        "dataset:\n",
        "  creation:\n",
        "    num_steps: 10\n",
        "    batch_size: 2\n",
        "    sys_msg: true\n",
        "  template: \"builtin://chatml.py\"\n",
        "\"\"\"\n",
        "\n",
        "tool_config_path = config_dir / 'tool_config.yaml'\n",
        "with open(tool_config_path, 'w', encoding='utf-8') as f:\n",
        "    f.write(tool_config)\n",
        "\n",
        "print(f\"âœ… Tool calling konfigÃ¼rasyonu oluÅŸturuldu: {tool_config_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tool calling veri setini Ã¼ret\n",
        "!deepfabric generate \\\n",
        "  --config {tool_config_path} \\\n",
        "  --dataset-save-as sentetik_veriler/tool_calling_dataset.jsonl\n",
        "\n",
        "print(\"\\nâœ… Tool calling veri seti oluÅŸturuldu!\")\n",
        "veri_goster('sentetik_veriler/tool_calling_dataset.jsonl', adet=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Veri Analizi ve GÃ¶rselleÅŸtirme\n",
        "\n",
        "OluÅŸturduÄŸumuz tÃ¼m veri setlerini analiz edelim."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def veri_seti_analizi(dosya_yolu):\n",
        "    \"\"\"JSONL veri setini analiz eder\"\"\"\n",
        "    if not Path(dosya_yolu).exists():\n",
        "        return None\n",
        "    \n",
        "    veriler = []\n",
        "    with open(dosya_yolu, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            try:\n",
        "                veriler.append(json.loads(line))\n",
        "            except:\n",
        "                pass\n",
        "    \n",
        "    if not veriler:\n",
        "        return None\n",
        "    \n",
        "    # Ä°statistikler\n",
        "    toplam = len(veriler)\n",
        "    mesaj_sayilari = []\n",
        "    mesaj_uzunluklari = []\n",
        "    \n",
        "    for veri in veriler:\n",
        "        if 'messages' in veri:\n",
        "            mesaj_sayilari.append(len(veri['messages']))\n",
        "            for msg in veri['messages']:\n",
        "                if 'content' in msg:\n",
        "                    mesaj_uzunluklari.append(len(msg['content']))\n",
        "    \n",
        "    return {\n",
        "        'dosya': Path(dosya_yolu).name,\n",
        "        'toplam_ornek': toplam,\n",
        "        'ort_mesaj_sayisi': sum(mesaj_sayilari) / len(mesaj_sayilari) if mesaj_sayilari else 0,\n",
        "        'ort_mesaj_uzunlugu': sum(mesaj_uzunluklari) / len(mesaj_uzunluklari) if mesaj_uzunluklari else 0,\n",
        "        'toplam_mesaj': len(mesaj_uzunluklari)\n",
        "    }\n",
        "\n",
        "# TÃ¼m veri setlerini analiz et\n",
        "veri_setleri = [\n",
        "    'sentetik_veriler/temel_dataset.jsonl',\n",
        "    'sentetik_veriler/python_qa_dataset.jsonl',\n",
        "    'sentetik_veriler/musteri_konusma_dataset.jsonl',\n",
        "    'sentetik_veriler/python_kod_ornekleri.jsonl',\n",
        "    'sentetik_veriler/tool_calling_dataset.jsonl'\n",
        "]\n",
        "\n",
        "analizler = []\n",
        "for dosya in veri_setleri:\n",
        "    analiz = veri_seti_analizi(dosya)\n",
        "    if analiz:\n",
        "        analizler.append(analiz)\n",
        "\n",
        "# DataFrame oluÅŸtur\n",
        "df_analiz = pd.DataFrame(analizler)\n",
        "\n",
        "print(\"\\nğŸ“Š Veri Setleri Ã–zet Ä°statistikleri:\")\n",
        "print(\"=\" * 100)\n",
        "print(df_analiz.to_string(index=False))\n",
        "print(\"=\" * 100)\n",
        "print(f\"\\nâœ… Toplam {df_analiz['toplam_ornek'].sum():.0f} Ã¶rnek Ã¼retildi!\")\n",
        "print(f\"âœ… Toplam {df_analiz['toplam_mesaj'].sum():.0f} mesaj oluÅŸturuldu!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# GÃ¶rselleÅŸtirme\n",
        "if len(analizler) > 0:\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "    \n",
        "    # Grafik 1: Veri seti boyutlarÄ±\n",
        "    axes[0].bar(range(len(df_analiz)), df_analiz['toplam_ornek'], \n",
        "                color=['#3498db', '#e74c3c', '#2ecc71', '#f39c12', '#9b59b6'])\n",
        "    axes[0].set_xticks(range(len(df_analiz)))\n",
        "    axes[0].set_xticklabels([f.replace('_dataset.jsonl', '').replace('_', ' ').title() \n",
        "                              for f in df_analiz['dosya']], rotation=45, ha='right')\n",
        "    axes[0].set_ylabel('Ã–rnek SayÄ±sÄ±', fontsize=11)\n",
        "    axes[0].set_title('Veri Seti BoyutlarÄ±', fontsize=13, fontweight='bold')\n",
        "    axes[0].grid(axis='y', alpha=0.3)\n",
        "    \n",
        "    # Grafik 2: Ortalama mesaj sayÄ±larÄ±\n",
        "    axes[1].bar(range(len(df_analiz)), df_analiz['ort_mesaj_sayisi'], \n",
        "                color=['#3498db', '#e74c3c', '#2ecc71', '#f39c12', '#9b59b6'])\n",
        "    axes[1].set_xticks(range(len(df_analiz)))\n",
        "    axes[1].set_xticklabels([f.replace('_dataset.jsonl', '').replace('_', ' ').title() \n",
        "                              for f in df_analiz['dosya']], rotation=45, ha='right')\n",
        "    axes[1].set_ylabel('Ortalama Mesaj/Ã–rnek', fontsize=11)\n",
        "    axes[1].set_title('Ã–rnek BaÅŸÄ±na Ortalama Mesaj SayÄ±sÄ±', fontsize=13, fontweight='bold')\n",
        "    axes[1].grid(axis='y', alpha=0.3)\n",
        "    \n",
        "    # Grafik 3: Ortalama mesaj uzunluklarÄ±\n",
        "    axes[2].bar(range(len(df_analiz)), df_analiz['ort_mesaj_uzunlugu'], \n",
        "                color=['#3498db', '#e74c3c', '#2ecc71', '#f39c12', '#9b59b6'])\n",
        "    axes[2].set_xticks(range(len(df_analiz)))\n",
        "    axes[2].set_xticklabels([f.replace('_dataset.jsonl', '').replace('_', ' ').title() \n",
        "                              for f in df_analiz['dosya']], rotation=45, ha='right')\n",
        "    axes[2].set_ylabel('Karakter SayÄ±sÄ±', fontsize=11)\n",
        "    axes[2].set_title('Ortalama Mesaj UzunluÄŸu', fontsize=13, fontweight='bold')\n",
        "    axes[2].grid(axis='y', alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig('sentetik_veriler/analiz_grafikleri.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"\\nâœ… Grafikler kaydedildi: sentetik_veriler/analiz_grafikleri.png\")\n",
        "else:\n",
        "    print(\"âš ï¸  Analiz iÃ§in yeterli veri yok\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Veri Setlerini BirleÅŸtirme ve Fine-tuning iÃ§in HazÄ±rlama"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TÃ¼m veri setlerini birleÅŸtir\n",
        "birlesik_veri = []\n",
        "\n",
        "for dosya in veri_setleri:\n",
        "    if Path(dosya).exists():\n",
        "        with open(dosya, 'r', encoding='utf-8') as f:\n",
        "            for line in f:\n",
        "                try:\n",
        "                    birlesik_veri.append(json.loads(line))\n",
        "                except:\n",
        "                    pass\n",
        "\n",
        "# BirleÅŸtirilmiÅŸ veri setini kaydet\n",
        "birlesik_dosya = output_dir / 'birlesik_dataset.jsonl'\n",
        "with open(birlesik_dosya, 'w', encoding='utf-8') as f:\n",
        "    for veri in birlesik_veri:\n",
        "        f.write(json.dumps(veri, ensure_ascii=False) + '\\n')\n",
        "\n",
        "print(f\"âœ… BirleÅŸtirilmiÅŸ veri seti oluÅŸturuldu: {birlesik_dosya}\")\n",
        "print(f\"   Toplam Ã¶rnek: {len(birlesik_veri)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# HuggingFace datasets formatÄ±na Ã§evir\n",
        "try:\n",
        "    dataset = load_dataset('json', data_files=str(birlesik_dosya))\n",
        "    print(\"âœ… Veri seti HuggingFace formatÄ±nda yÃ¼klendi!\")\n",
        "    print(f\"\\nVeri seti bilgileri:\")\n",
        "    print(dataset)\n",
        "    \n",
        "    if len(dataset['train']) > 0:\n",
        "        print(\"\\nğŸ“ Ã–rnek bir satÄ±r:\")\n",
        "        print(json.dumps(dataset['train'][0], indent=2, ensure_ascii=False)[:500])\n",
        "        print(\"...\")\n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸  Hata: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Fine-tuning Ã–rnek Kodu\n",
        "\n",
        "Ãœretilen veri ile model fine-tuning yapmak iÃ§in Ã¶rnek kod."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fine-tuning Ã¶rnek kodu\n",
        "finetuning_kod = '''\n",
        "# Model Fine-tuning iÃ§in Ã–rnek Kod\n",
        "# Gerekli kÃ¼tÃ¼phaneler: transformers, trl, peft, accelerate, bitsandbytes\n",
        "\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments\n",
        "from trl import SFTTrainer\n",
        "from datasets import load_dataset\n",
        "from peft import LoraConfig, get_peft_model\n",
        "import torch\n",
        "\n",
        "# 1. Model ve tokenizer yÃ¼kle\n",
        "model_name = \"meta-llama/Llama-3.2-1B-Instruct\"  # veya baÅŸka bir model\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\",\n",
        "    load_in_4bit=True  # QLoRA iÃ§in\n",
        ")\n",
        "\n",
        "# 2. Veri setini yÃ¼kle\n",
        "dataset = load_dataset(\"json\", data_files=\"sentetik_veriler/birlesik_dataset.jsonl\")\n",
        "\n",
        "# 3. LoRA konfigÃ¼rasyonu\n",
        "peft_config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        "    target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\"]\n",
        ")\n",
        "\n",
        "# 4. Training parametreleri\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./finetuned_model\",\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=2,\n",
        "    gradient_accumulation_steps=4,\n",
        "    learning_rate=2e-4,\n",
        "    fp16=True,\n",
        "    logging_steps=10,\n",
        "    save_steps=100,\n",
        "    warmup_steps=50,\n",
        "    optim=\"paged_adamw_8bit\"\n",
        ")\n",
        "\n",
        "# 5. Trainer oluÅŸtur\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset[\"train\"],\n",
        "    tokenizer=tokenizer,\n",
        "    peft_config=peft_config,\n",
        "    max_seq_length=2048,\n",
        "    dataset_text_field=\"messages\"  # ChatML formatÄ± iÃ§in\n",
        ")\n",
        "\n",
        "# 6. EÄŸitimi baÅŸlat\n",
        "trainer.train()\n",
        "\n",
        "# 7. Modeli kaydet\n",
        "trainer.save_model(\"./finetuned_model\")\n",
        "tokenizer.save_pretrained(\"./finetuned_model\")\n",
        "\n",
        "print(\"âœ… Model eÄŸitimi tamamlandÄ±!\")\n",
        "'''\n",
        "\n",
        "# Kodu dosyaya kaydet\n",
        "with open(output_dir / 'ornek_finetuning.py', 'w', encoding='utf-8') as f:\n",
        "    f.write(finetuning_kod)\n",
        "\n",
        "print(\"Fine-tuning Ã–rnek Kodu:\")\n",
        "print(\"=\" * 80)\n",
        "print(finetuning_kod)\n",
        "print(\"=\" * 80)\n",
        "print(f\"\\nâœ… Kod kaydedildi: {output_dir / 'ornek_finetuning.py'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. DosyalarÄ± Ä°ndirme\n",
        "\n",
        "OluÅŸturduÄŸunuz veri setlerini bilgisayarÄ±nÄ±za indirin."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Google Drive'a kaydet (opsiyonel)\n",
        "from google.colab import drive\n",
        "\n",
        "try:\n",
        "    drive.mount('/content/drive')\n",
        "    \n",
        "    # Veri setlerini Drive'a kopyala\n",
        "    !mkdir -p '/content/drive/MyDrive/DeepFabric_Datasets'\n",
        "    !cp -r sentetik_veriler/* '/content/drive/MyDrive/DeepFabric_Datasets/'\n",
        "    \n",
        "    print(\"âœ… Veri setleri Google Drive'a kaydedildi!\")\n",
        "    print(\"   Konum: MyDrive/DeepFabric_Datasets/\")\n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸  Drive baÄŸlantÄ±sÄ± kurulamadÄ±: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Veya ZIP olarak indir\n",
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "# ZIP oluÅŸtur\n",
        "shutil.make_archive('sentetik_veri_setleri', 'zip', 'sentetik_veriler')\n",
        "\n",
        "print(\"âœ… ZIP dosyasÄ± oluÅŸturuldu!\")\n",
        "print(\"\\nÄ°ndirmek iÃ§in aÅŸaÄŸÄ±daki satÄ±rÄ±n yorum iÅŸaretini kaldÄ±rÄ±n:\")\n",
        "# files.download('sentetik_veri_setleri.zip')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Ã–zet ve Sonraki AdÄ±mlar\n",
        "\n",
        "### ğŸ“‹ Bu Notebook'ta Neler YaptÄ±k?\n",
        "\n",
        "âœ… DeepFabric'i kurduk ve OpenRouter API ile yapÄ±landÄ±rdÄ±k  \n",
        "âœ… GPT-OSS-20B modelini kullanarak sentetik veri Ã¼rettik  \n",
        "âœ… 5 farklÄ± tÃ¼rde veri seti oluÅŸturduk:\n",
        "   - Temel veri seti\n",
        "   - Python soru-cevap\n",
        "   - MÃ¼ÅŸteri konuÅŸmalarÄ±\n",
        "   - Kod Ã¶rnekleri\n",
        "   - Tool calling\n",
        "âœ… Veri setlerini analiz ettik ve gÃ¶rselleÅŸtirdik  \n",
        "âœ… Fine-tuning iÃ§in hazÄ±r hale getirdik  \n",
        "\n",
        "### ğŸš€ Sonraki AdÄ±mlar\n",
        "\n",
        "1. **Daha Fazla Veri Ãœretin**:\n",
        "   - `num_steps` deÄŸerini artÄ±rÄ±n (50-100)\n",
        "   - FarklÄ± konular deneyin\n",
        "   - Temperature ayarlarÄ±nÄ± optimize edin\n",
        "\n",
        "2. **Veri Kalitesini ArtÄ±rÄ±n**:\n",
        "   - Prompt'larÄ± daha spesifik hale getirin\n",
        "   - Ãœretilen Ã¶rnekleri manuel olarak inceleyin\n",
        "   - DÃ¼ÅŸÃ¼k kaliteli Ã¶rnekleri filtreleyin\n",
        "\n",
        "3. **Model EÄŸitimi**:\n",
        "   - ÃœrettiÄŸiniz veri ile kÃ¼Ã§Ã¼k bir model fine-tune edin\n",
        "   - LoRA/QLoRA kullanarak verimli eÄŸitim yapÄ±n\n",
        "   - FarklÄ± hyperparameter'lar deneyin\n",
        "\n",
        "4. **DeÄŸerlendirme**:\n",
        "   - Fine-tune edilmiÅŸ modeli test edin\n",
        "   - Benchmark sonuÃ§larÄ±nÄ± karÅŸÄ±laÅŸtÄ±rÄ±n\n",
        "   - KullanÄ±cÄ± geri bildirimi toplayÄ±n\n",
        "\n",
        "### ğŸ“š FaydalÄ± Kaynaklar\n",
        "\n",
        "- **DeepFabric**: https://github.com/lukehinds/deepfabric\n",
        "- **OpenRouter**: https://openrouter.ai/\n",
        "- **HuggingFace TRL**: https://huggingface.co/docs/trl/\n",
        "- **PEFT/LoRA**: https://huggingface.co/docs/peft/\n",
        "\n",
        "---\n",
        "\n",
        "**Ä°yi Ã§alÄ±ÅŸmalar! ğŸ‰**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Ekstra: Parametreleri Anlama ve Optimizasyon\n",
        "\n",
        "### Konu AÄŸacÄ± Parametreleri\n",
        "\n",
        "- **`depth`**: Konu aÄŸacÄ±nÄ±n derinliÄŸi (kaÃ§ seviye alt konu)\n",
        "  - `depth=1`: Sadece ana konu\n",
        "  - `depth=2`: Ana konu + 1 seviye alt konular\n",
        "  - `depth=3`: Ana konu + 2 seviye alt konular\n",
        "\n",
        "- **`degree`**: Her konudan kaÃ§ alt konu tÃ¼retilir\n",
        "  - `degree=2`: Her konudan 2 alt konu\n",
        "  - `degree=3`: Her konudan 3 alt konu\n",
        "  - Toplam konu: yaklaÅŸÄ±k `degree^depth`\n",
        "\n",
        "### Veri Ãœretim Parametreleri\n",
        "\n",
        "- **`num_steps`**: KaÃ§ Ã¶rnek Ã¼retilecek\n",
        "- **`batch_size`**: Paralel Ã¼retim (API limitine dikkat)\n",
        "- **`temperature`**: YaratÄ±cÄ±lÄ±k seviyesi\n",
        "  - 0.0-0.3: Deterministik, tutarlÄ±\n",
        "  - 0.4-0.7: Dengeli\n",
        "  - 0.8-1.0: YaratÄ±cÄ±, Ã§eÅŸitli\n",
        "\n",
        "### Optimizasyon Ä°puÃ§larÄ±\n",
        "\n",
        "1. **Maliyet YÃ¶netimi**: OpenRouter Ã¼cretlidir\n",
        "   - Ã–nce `num_steps=5` ile test edin\n",
        "   - Kaliteyi kontrol edin\n",
        "   - Sonra artÄ±rÄ±n\n",
        "\n",
        "2. **HÄ±z Optimizasyonu**:\n",
        "   - `batch_size=2-4` kullanÄ±n\n",
        "   - Ã‡ok yÃ¼ksek deÄŸerler API limitlerine takÄ±labilir\n",
        "\n",
        "3. **Kalite Ä°yileÅŸtirme**:\n",
        "   - Prompt'larÄ± Ã¶rneklerle zenginleÅŸtirin\n",
        "   - Temperature'Ä± gÃ¶reve gÃ¶re ayarlayÄ±n\n",
        "   - Ãœretilen veriyi dÃ¼zenli inceleyin"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
