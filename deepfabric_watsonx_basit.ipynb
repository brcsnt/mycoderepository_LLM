{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepFabric ile Watsonx API Kullanarak Sentetik Veri Ãœretimi\n",
    "\n",
    "Bu notebook, Watsonx platformundaki Llama modelinizi API Ã¼zerinden kullanarak DeepFabric ile sentetik veri Ã¼retmeyi gÃ¶sterir.\n",
    "\n",
    "## DeepFabric Nedir?\n",
    "\n",
    "DeepFabric, AI modelleri iÃ§in sentetik eÄŸitim verisi oluÅŸturan bir kÃ¼tÃ¼phanedir:\n",
    "\n",
    "- **Konu AÄŸacÄ±**: Bir konudan alt konular oluÅŸturur\n",
    "- **Soru-Cevap Ãœretimi**: Her konu iÃ§in eÄŸitim verileri Ã¼retir\n",
    "- **Ã‡oklu Format**: TRL, ChatML, Alpaca formatlarÄ±nÄ± destekler\n",
    "- **OpenAI-Uyumlu API**: Herhangi bir OpenAI-compatible API ile Ã§alÄ±ÅŸÄ±r\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Kurulum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeepFabric kÃ¼tÃ¼phanesini kur\n",
    "!pip install deepfabric -q\n",
    "\n",
    "print(\"âœ“ DeepFabric kuruldu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerekli kÃ¼tÃ¼phaneler\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Watsonx API KonfigÃ¼rasyonu\n",
    "\n",
    "### Watsonx API Bilgileriniz:\n",
    "\n",
    "EÄŸer Watsonx API'niz OpenAI-uyumlu ise (Ã¶rneÄŸin bir proxy Ã¼zerinden eriÅŸiyorsanÄ±z), sadece 3 bilgi gerekir:\n",
    "\n",
    "1. **API URL**: Watsonx API endpoint'iniz\n",
    "2. **API Key**: Authentication iÃ§in key (veya dummy key)\n",
    "3. **Model AdÄ±**: KullandÄ±ÄŸÄ±nÄ±z model adÄ±\n",
    "\n",
    "DeepFabric, OpenAI formatÄ±nda API bekliyor. EÄŸer Watsonx API'niz bu formatta ise direkt kullanabilirsiniz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# WATSONX API KONFÄ°GÃœRASYONU\n",
    "# Kendi bilgilerinizi buraya girin\n",
    "# ========================================\n",
    "\n",
    "# 1. API URL (Ã¶rnek: http://your-watsonx-api.com:8000/v1)\n",
    "API_URL = \"http://localhost:8000/v1\"  # KENDÄ° URL'NÄ°ZÄ° GÄ°RÄ°N\n",
    "\n",
    "# 2. API Key (gerekiyorsa)\n",
    "API_KEY = \"your-api-key-here\"  # KENDÄ° KEY'Ä°NÄ°ZÄ° GÄ°RÄ°N (veya dummy key)\n",
    "\n",
    "# 3. Model adÄ±\n",
    "MODEL_NAME = \"llama-3-70b-instruct\"  # KENDÄ° MODEL ADINIZI GÄ°RÄ°N\n",
    "\n",
    "# Environment variables olarak ayarla (DeepFabric bunlarÄ± kullanacak)\n",
    "os.environ['OPENAI_API_KEY'] = API_KEY\n",
    "os.environ['OPENAI_BASE_URL'] = API_URL\n",
    "\n",
    "print(\"âœ… API KonfigÃ¼rasyonu tamamlandÄ±\")\n",
    "print(f\"  URL: {API_URL}\")\n",
    "print(f\"  Model: {MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. API BaÄŸlantÄ±sÄ±nÄ± Test Et (Opsiyonel)\n",
    "\n",
    "API'nizin Ã§alÄ±ÅŸtÄ±ÄŸÄ±ndan emin olmak iÃ§in basit bir test yapabilirsiniz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI client ile test (DeepFabric aynÄ± ÅŸekilde baÄŸlanÄ±r)\n",
    "try:\n",
    "    from openai import OpenAI\n",
    "    \n",
    "    client = OpenAI(\n",
    "        api_key=API_KEY,\n",
    "        base_url=API_URL\n",
    "    )\n",
    "    \n",
    "    # Test prompt\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL_NAME,\n",
    "        messages=[{\"role\": \"user\", \"content\": \"Python nedir?\"}],\n",
    "        max_tokens=100\n",
    "    )\n",
    "    \n",
    "    print(\"âœ… API baÄŸlantÄ±sÄ± baÅŸarÄ±lÄ±!\")\n",
    "    print(f\"\\nTest yanÄ±tÄ±:\\n{response.choices[0].message.content}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ API baÄŸlantÄ± hatasÄ±: {e}\")\n",
    "    print(\"\\nLÃ¼tfen API URL, Key ve Model adÄ±nÄ± kontrol edin.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Basit Ã–rnek: CLI ile Sentetik Veri Ãœretimi\n",
    "\n",
    "DeepFabric'in en basit kullanÄ±mÄ± komut satÄ±rÄ±ndan:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basit bir sentetik veri seti oluÅŸtur\n",
    "!deepfabric generate \\\n",
    "  --mode tree \\\n",
    "  --provider openai \\\n",
    "  --model {MODEL_NAME} \\\n",
    "  --depth 2 \\\n",
    "  --degree 2 \\\n",
    "  --num-steps 10 \\\n",
    "  --topic-prompt \"Python Programlama Temelleri\" \\\n",
    "  --dataset-save-as dataset_basit.jsonl\n",
    "\n",
    "print(\"\\nâœ… Veri Ã¼retimi tamamlandÄ±!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ãœretilen veriyi incele\n",
    "if os.path.exists('dataset_basit.jsonl'):\n",
    "    print(\"ğŸ“Š ÃœRETÄ°LEN VERÄ° Ã–RNEKLERÄ°:\\n\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    with open('dataset_basit.jsonl', 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if i < 2:  # Ä°lk 2 Ã¶rneÄŸi gÃ¶ster\n",
    "                data = json.loads(line)\n",
    "                print(f\"\\nğŸ”¹ Ã–rnek {i+1}:\")\n",
    "                print(\"-\" * 80)\n",
    "                print(json.dumps(data, indent=2, ensure_ascii=False))\n",
    "                print(\"=\" * 80)\n",
    "else:\n",
    "    print(\"âŒ Veri seti bulunamadÄ±\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. TXT DosyasÄ±ndan Soru-Cevap Ãœretimi\n",
    "\n",
    "Kendi txt dosyanÄ±zdan sentetik veri oluÅŸturabilirsiniz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ã–rnek txt dosyasÄ± oluÅŸtur (veya kendi dosyanÄ±zÄ± kullanÄ±n)\n",
    "ornek_metin = \"\"\"\n",
    "Yapay Zeka ve Makine Ã–ÄŸrenmesi\n",
    "\n",
    "Makine Ã¶ÄŸrenmesi, yapay zekanÄ±n bir alt dalÄ±dÄ±r ve bilgisayarlarÄ±n \n",
    "veriden Ã¶ÄŸrenmesini saÄŸlar. Temel kavramlar:\n",
    "\n",
    "1. Supervised Learning: Etiketli veri ile Ã¶ÄŸrenme\n",
    "2. Unsupervised Learning: Etiketsiz veri ile Ã¶ÄŸrenme\n",
    "3. Reinforcement Learning: Ã–dÃ¼l-ceza sistemi ile Ã¶ÄŸrenme\n",
    "4. Deep Learning: Ã‡ok katmanlÄ± sinir aÄŸlarÄ±\n",
    "\n",
    "Model eÄŸitimi iÃ§in veri kalitesi Ã§ok Ã¶nemlidir.\n",
    "\"\"\"\n",
    "\n",
    "# Kendi dosyanÄ±zÄ± kullanmak iÃ§in:\n",
    "# dosya_yolu = \"kendi_dosyaniz.txt\"\n",
    "\n",
    "with open('ornek_konu.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(ornek_metin)\n",
    "\n",
    "print(\"âœ“ Ã–rnek txt dosyasÄ± oluÅŸturuldu: ornek_konu.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Txt dosyasÄ±nÄ± oku\n",
    "with open('ornek_konu.txt', 'r', encoding='utf-8') as f:\n",
    "    txt_icerik = f.read()\n",
    "\n",
    "print(f\"ğŸ“– Dosya okundu ({len(txt_icerik)} karakter)\")\n",
    "print(f\"\\nÄ°Ã§erik:\\n{txt_icerik[:200]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YAML konfigÃ¼rasyonu oluÅŸtur (txt iÃ§eriÄŸini topic olarak kullan)\n",
    "yaml_config = f\"\"\"\n",
    "dataset_system_prompt: |\n",
    "  Sen yardÄ±mcÄ± bir TÃ¼rkÃ§e AI asistanÄ±sÄ±n. KullanÄ±cÄ±lara detaylÄ± \n",
    "  ve anlaÅŸÄ±lÄ±r ÅŸekilde yanÄ±t veriyorsun.\n",
    "\n",
    "topic_tree:\n",
    "  # Txt dosyasÄ±nÄ±n iÃ§eriÄŸini ana konu olarak kullanÄ±yoruz\n",
    "  topic_prompt: |\n",
    "    {txt_icerik}\n",
    "    \n",
    "    YukarÄ±daki konular hakkÄ±nda detaylÄ± alt baÅŸlÄ±klar oluÅŸtur.\n",
    "  \n",
    "  provider: \"openai\"\n",
    "  model: \"{MODEL_NAME}\"\n",
    "  temperature: 0.7\n",
    "  degree: 3  # Her konudan 3 alt konu\n",
    "  depth: 2   # 2 seviye derinlik\n",
    "\n",
    "data_engine:\n",
    "  generation_system_prompt: |\n",
    "    Verilen konular hakkÄ±nda TÃ¼rkÃ§e soru-cevap Ã§iftleri oluÅŸtur.\n",
    "    Her cevap:\n",
    "    - Net ve anlaÅŸÄ±lÄ±r olmalÄ±\n",
    "    - Ã–rnekler iÃ§ermeli  \n",
    "    - EÄŸitici olmalÄ±\n",
    "  \n",
    "  temperature: 0.6\n",
    "  provider: \"openai\"\n",
    "  model: \"{MODEL_NAME}\"\n",
    "\n",
    "dataset:\n",
    "  creation:\n",
    "    num_steps: 20      # 20 soru-cevap Ã§ifti\n",
    "    batch_size: 2      # 2'ÅŸer 2'ÅŸer Ã¼ret\n",
    "    sys_msg: true\n",
    "  template: \"builtin://chatml.py\"\n",
    "\"\"\"\n",
    "\n",
    "with open('txt_config.yaml', 'w', encoding='utf-8') as f:\n",
    "    f.write(yaml_config)\n",
    "\n",
    "print(\"âœ“ YAML konfigÃ¼rasyon oluÅŸturuldu: txt_config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Txt dosyasÄ±ndan soru-cevap Ã¼ret\n",
    "!deepfabric generate \\\n",
    "  --config txt_config.yaml \\\n",
    "  --dataset-save-as dataset_from_txt.jsonl\n",
    "\n",
    "print(\"\\nâœ… TXT dosyasÄ±ndan sentetik veri Ã¼retimi tamamlandÄ±!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ãœretilen soru-cevaplarÄ± incele\n",
    "if os.path.exists('dataset_from_txt.jsonl'):\n",
    "    print(\"\\nğŸ“Š TXT'DEN ÃœRETÄ°LEN SORU-CEVAPLAR:\\n\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    with open('dataset_from_txt.jsonl', 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if i < 3:  # Ä°lk 3 Ã¶rneÄŸi gÃ¶ster\n",
    "                data = json.loads(line)\n",
    "                print(f\"\\nğŸ”¹ Ã–rnek {i+1}:\")\n",
    "                print(\"-\" * 80)\n",
    "                \n",
    "                if 'messages' in data:\n",
    "                    for msg in data['messages']:\n",
    "                        role = msg.get('role', '').upper()\n",
    "                        content = msg.get('content', '')\n",
    "                        print(f\"\\n[{role}]\")\n",
    "                        print(content[:500])\n",
    "                        if len(content) > 500:\n",
    "                            print(\"...\")\n",
    "                \n",
    "                print(\"\\n\" + \"=\" * 80)\n",
    "else:\n",
    "    print(\"âŒ Veri seti bulunamadÄ±\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Parametrelerin AÃ§Ä±klamasÄ±\n",
    "\n",
    "### Konu AÄŸacÄ±:\n",
    "\n",
    "- **`depth`**: AÄŸaÃ§ derinliÄŸi (1-5). `depth=2` â†’ Ana konu â†’ Alt konu\n",
    "- **`degree`**: Her konudan kaÃ§ alt konu (1-10). `degree=3` â†’ 3 alt konu\n",
    "- **`topic_prompt`**: Ana konu metni (txt dosyanÄ±zÄ±n iÃ§eriÄŸi olabilir)\n",
    "\n",
    "### Veri Ãœretimi:\n",
    "\n",
    "- **`num_steps`**: Toplam kaÃ§ Ã¶rnek Ã¼retilecek\n",
    "- **`batch_size`**: Paralel Ã¼retim iÃ§in batch sayÄ±sÄ±\n",
    "- **`temperature`**: 0.0 (deterministik) - 1.0 (yaratÄ±cÄ±)\n",
    "\n",
    "### Prompt'lar:\n",
    "\n",
    "- **`dataset_system_prompt`**: Sistemin genel davranÄ±ÅŸÄ±\n",
    "- **`generation_system_prompt`**: Veri Ã¼retim stili\n",
    "- **`topic_prompt`**: Ana konu (buraya txt iÃ§eriÄŸinizi koyun)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. FarklÄ± Formatlara DÃ¶nÃ¼ÅŸtÃ¼rme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatML formatÄ±na Ã§evir\n",
    "!deepfabric format \\\n",
    "  --dataset dataset_from_txt.jsonl \\\n",
    "  --format builtin://chatml.py \\\n",
    "  --output dataset_chatml.jsonl\n",
    "\n",
    "print(\"âœ“ ChatML formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼ldÃ¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alpaca formatÄ±na Ã§evir  \n",
    "!deepfabric format \\\n",
    "  --dataset dataset_from_txt.jsonl \\\n",
    "  --format builtin://alpaca.py \\\n",
    "  --output dataset_alpaca.jsonl\n",
    "\n",
    "print(\"âœ“ Alpaca formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼ldÃ¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HuggingFace TRL formatÄ±\n",
    "!deepfabric format \\\n",
    "  --dataset dataset_from_txt.jsonl \\\n",
    "  --format builtin://trl_sft_tools \\\n",
    "  --output dataset_hf.jsonl\n",
    "\n",
    "print(\"âœ“ HuggingFace TRL formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼ldÃ¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Veri Analizi Fonksiyonu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def veri_analizi(dosya_yolu):\n",
    "    \"\"\"\n",
    "    JSONL veri setini analiz eder\n",
    "    \"\"\"\n",
    "    if not os.path.exists(dosya_yolu):\n",
    "        print(f\"âŒ Dosya bulunamadÄ±: {dosya_yolu}\")\n",
    "        return\n",
    "    \n",
    "    veriler = []\n",
    "    with open(dosya_yolu, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            veriler.append(json.loads(line))\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Veri Analizi: {dosya_yolu}\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Toplam Ã¶rnek: {len(veriler)}\")\n",
    "    \n",
    "    if veriler and 'messages' in veriler[0]:\n",
    "        mesaj_sayilari = [len(v['messages']) for v in veriler if 'messages' in v]\n",
    "        print(f\"Ortalama mesaj sayÄ±sÄ±: {sum(mesaj_sayilari) / len(mesaj_sayilari):.1f}\")\n",
    "        print(f\"Min-Max mesaj: {min(mesaj_sayilari)} - {max(mesaj_sayilari)}\")\n",
    "    \n",
    "    if veriler:\n",
    "        print(f\"\\nVeri yapÄ±sÄ±: {list(veriler[0].keys())}\")\n",
    "    \n",
    "    return veriler\n",
    "\n",
    "# KullanÄ±m:\n",
    "# veri_analizi('dataset_from_txt.jsonl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Ã–zet\n",
    "\n",
    "### âœ… Ne YaptÄ±k?\n",
    "\n",
    "1. DeepFabric kurduk\n",
    "2. Watsonx API'nizi yapÄ±landÄ±rdÄ±k\n",
    "3. Basit veri setleri oluÅŸturduk\n",
    "4. TXT dosyasÄ±ndan soru-cevap Ã¼rettik\n",
    "5. FarklÄ± formatlara dÃ¶nÃ¼ÅŸtÃ¼rdÃ¼k\n",
    "\n",
    "### ğŸ¯ NasÄ±l KullanÄ±rsÄ±nÄ±z?\n",
    "\n",
    "**AdÄ±m 1:** API bilgilerinizi girin (BÃ¶lÃ¼m 2)\n",
    "```python\n",
    "API_URL = \"http://your-api-url/v1\"\n",
    "API_KEY = \"your-key\"\n",
    "MODEL_NAME = \"your-model\"\n",
    "```\n",
    "\n",
    "**AdÄ±m 2:** Kendi txt dosyanÄ±zÄ± kullanÄ±n (BÃ¶lÃ¼m 5)\n",
    "```python\n",
    "with open('kendi_dosyaniz.txt', 'r') as f:\n",
    "    txt_icerik = f.read()\n",
    "```\n",
    "\n",
    "**AdÄ±m 3:** YAML config oluÅŸturun ve Ã¼retin\n",
    "```bash\n",
    "deepfabric generate --config txt_config.yaml --dataset-save-as sonuc.jsonl\n",
    "```\n",
    "\n",
    "### ğŸ’¡ Ä°puÃ§larÄ±:\n",
    "\n",
    "- KÃ¼Ã§Ã¼k baÅŸlayÄ±n: `num_steps=5-10`\n",
    "- Spesifik konular seÃ§in\n",
    "- Prompt'larÄ± Ã¶zelleÅŸtirin\n",
    "- Temperature ayarlayÄ±n (teknik: 0.3-0.5, yaratÄ±cÄ±: 0.7-0.8)\n",
    "\n",
    "---\n",
    "\n",
    "**BaÅŸarÄ±lar!** ğŸš€"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
