{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding Fine-tuning Tutorial\n",
    "\n",
    "Bu notebook, Turkish BERT ve BGE modellerini soru-cevap verileri üzerinde fine-tune etmek için adım adım bir kılavuzdur.\n",
    "\n",
    "## İçindekiler\n",
    "1. [Kurulum](#kurulum)\n",
    "2. [Veri Yükleme ve Hazırlama](#veri-yükleme)\n",
    "3. [Turkish BERT Fine-tuning](#turkish-bert)\n",
    "4. [BGE Model Fine-tuning](#bge-model)\n",
    "5. [Model Değerlendirme](#değerlendirme)\n",
    "6. [Kullanım Örnekleri](#kullanım)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Kurulum <a id=\"kurulum\"></a>\n",
    "\n",
    "Gerekli kütüphaneleri yükleyin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q sentence-transformers transformers torch pandas numpy scikit-learn scipy tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# GPU kontrolü\n",
    "print(f\"CUDA mevcut: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Belleği: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Veri Yükleme ve Hazırlama <a id=\"veri-yükleme\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Örnek veri yükleme\n",
    "with open('example_qa_data.json', 'r', encoding='utf-8') as f:\n",
    "    qa_data = json.load(f)\n",
    "\n",
    "print(f\"Toplam {len(qa_data)} soru-cevap çifti yüklendi.\")\n",
    "print(\"\\nİlk örnek:\")\n",
    "print(f\"Soru: {qa_data[0]['question']}\")\n",
    "print(f\"Cevap: {qa_data[0]['answer']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veriyi DataFrame'e çevir\n",
    "df = pd.DataFrame(qa_data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veri istatistikleri\n",
    "print(\"Veri İstatistikleri:\")\n",
    "print(f\"Toplam örnek sayısı: {len(df)}\")\n",
    "print(f\"Ortalama soru uzunluğu: {df['question'].str.len().mean():.2f} karakter\")\n",
    "print(f\"Ortalama cevap uzunluğu: {df['answer'].str.len().mean():.2f} karakter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veriyi train/test olarak ayır\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "print(f\"Training örnekleri: {len(train_df)}\")\n",
    "print(f\"Test örnekleri: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# InputExample formatına dönüştür\n",
    "def create_examples(df):\n",
    "    examples = []\n",
    "    for _, row in df.iterrows():\n",
    "        examples.append(InputExample(texts=[row['question'], row['answer']], label=1.0))\n",
    "    return examples\n",
    "\n",
    "train_examples = create_examples(train_df)\n",
    "eval_examples = create_examples(test_df)\n",
    "\n",
    "print(f\"Training examples: {len(train_examples)}\")\n",
    "print(f\"Evaluation examples: {len(eval_examples)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Turkish BERT Fine-tuning <a id=\"turkish-bert\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model yükleme\n",
    "turkish_bert = SentenceTransformer('dbmdz/bert-base-turkish-cased')\n",
    "turkish_bert.max_seq_length = 128\n",
    "\n",
    "print(f\"Model yüklendi: {turkish_bert}\")\n",
    "print(f\"Max sequence length: {turkish_bert.max_seq_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Orijinal model ile bir test (fine-tuning öncesi)\n",
    "test_questions = [\n",
    "    \"Python nedir?\",\n",
    "    \"Makine öğrenmesi nasıl çalışır?\"\n",
    "]\n",
    "test_answers = [\n",
    "    \"Python yüksek seviyeli bir programlama dilidir.\",\n",
    "    \"Makine öğrenmesi verilerden pattern öğrenir.\"\n",
    "]\n",
    "\n",
    "q_emb_before = turkish_bert.encode(test_questions, normalize_embeddings=True)\n",
    "a_emb_before = turkish_bert.encode(test_answers, normalize_embeddings=True)\n",
    "\n",
    "sim_before = cosine_similarity(q_emb_before, a_emb_before)\n",
    "print(\"Fine-tuning ÖNCESI benzerlik skorları:\")\n",
    "for i, (q, a) in enumerate(zip(test_questions, test_answers)):\n",
    "    print(f\"  {q} -> {a}\")\n",
    "    print(f\"  Benzerlik: {sim_before[i][i]:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader ve Loss oluşturma\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=16)\n",
    "train_loss = losses.MultipleNegativesRankingLoss(turkish_bert)\n",
    "\n",
    "# Evaluator\n",
    "evaluator = EmbeddingSimilarityEvaluator.from_input_examples(eval_examples, name='turkish-bert-eval')\n",
    "\n",
    "print(\"DataLoader ve Loss fonksiyonu hazır.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuning\n",
    "output_path = './models/turkish-bert-qa-finetuned'\n",
    "\n",
    "turkish_bert.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    evaluator=evaluator,\n",
    "    epochs=3,\n",
    "    warmup_steps=100,\n",
    "    optimizer_params={'lr': 2e-5},\n",
    "    output_path=output_path,\n",
    "    evaluation_steps=50,\n",
    "    save_best_model=True,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "print(f\"\\nModel kaydedildi: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuned model yükleme ve test\n",
    "turkish_bert_ft = SentenceTransformer(output_path)\n",
    "\n",
    "q_emb_after = turkish_bert_ft.encode(test_questions, normalize_embeddings=True)\n",
    "a_emb_after = turkish_bert_ft.encode(test_answers, normalize_embeddings=True)\n",
    "\n",
    "sim_after = cosine_similarity(q_emb_after, a_emb_after)\n",
    "\n",
    "print(\"Fine-tuning SONRASI benzerlik skorları:\")\n",
    "for i, (q, a) in enumerate(zip(test_questions, test_answers)):\n",
    "    print(f\"  {q} -> {a}\")\n",
    "    print(f\"  Önce: {sim_before[i][i]:.4f}\")\n",
    "    print(f\"  Sonra: {sim_after[i][i]:.4f}\")\n",
    "    print(f\"  İyileşme: {(sim_after[i][i] - sim_before[i][i])*100:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. BGE Model Fine-tuning <a id=\"bge-model\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BGE-M3 model yükleme\n",
    "bge_model = SentenceTransformer('BAAI/bge-m3')\n",
    "bge_model.max_seq_length = 512\n",
    "\n",
    "print(f\"Model yüklendi: {bge_model}\")\n",
    "print(f\"Max sequence length: {bge_model.max_seq_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BGE için instruction ekle\n",
    "query_instruction = \"Bu soruyu cevaplamak için ilgili bilgiyi ara: \"\n",
    "\n",
    "def create_bge_examples(df, use_instruction=True):\n",
    "    examples = []\n",
    "    for _, row in df.iterrows():\n",
    "        if use_instruction:\n",
    "            question = f\"{query_instruction}{row['question']}\"\n",
    "        else:\n",
    "            question = row['question']\n",
    "        examples.append(InputExample(texts=[question, row['answer']], label=1.0))\n",
    "    return examples\n",
    "\n",
    "train_examples_bge = create_bge_examples(train_df, use_instruction=True)\n",
    "eval_examples_bge = create_bge_examples(test_df, use_instruction=True)\n",
    "\n",
    "print(f\"BGE Training examples: {len(train_examples_bge)}\")\n",
    "print(f\"BGE Evaluation examples: {len(eval_examples_bge)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Orijinal BGE model testi\n",
    "test_questions_inst = [f\"{query_instruction}{q}\" for q in test_questions]\n",
    "\n",
    "q_emb_bge_before = bge_model.encode(test_questions_inst, normalize_embeddings=True)\n",
    "a_emb_bge_before = bge_model.encode(test_answers, normalize_embeddings=True)\n",
    "\n",
    "sim_bge_before = cosine_similarity(q_emb_bge_before, a_emb_bge_before)\n",
    "print(\"BGE Fine-tuning ÖNCESI benzerlik skorları:\")\n",
    "for i, (q, a) in enumerate(zip(test_questions, test_answers)):\n",
    "    print(f\"  {q} -> {a}\")\n",
    "    print(f\"  Benzerlik: {sim_bge_before[i][i]:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader ve Loss\n",
    "train_dataloader_bge = DataLoader(train_examples_bge, shuffle=True, batch_size=16)\n",
    "train_loss_bge = losses.MultipleNegativesRankingLoss(bge_model)\n",
    "evaluator_bge = EmbeddingSimilarityEvaluator.from_input_examples(eval_examples_bge, name='bge-eval')\n",
    "\n",
    "print(\"BGE DataLoader ve Loss fonksiyonu hazır.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BGE Fine-tuning\n",
    "output_path_bge = './models/bge-m3-qa-finetuned'\n",
    "\n",
    "bge_model.fit(\n",
    "    train_objectives=[(train_dataloader_bge, train_loss_bge)],\n",
    "    evaluator=evaluator_bge,\n",
    "    epochs=3,\n",
    "    warmup_steps=100,\n",
    "    optimizer_params={'lr': 1e-5},  # BGE için daha düşük learning rate\n",
    "    output_path=output_path_bge,\n",
    "    evaluation_steps=50,\n",
    "    save_best_model=True,\n",
    "    show_progress_bar=True,\n",
    "    scheduler='warmuplinear'\n",
    ")\n",
    "\n",
    "print(f\"\\nBGE Model kaydedildi: {output_path_bge}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuned BGE model testi\n",
    "bge_model_ft = SentenceTransformer(output_path_bge)\n",
    "\n",
    "q_emb_bge_after = bge_model_ft.encode(test_questions_inst, normalize_embeddings=True)\n",
    "a_emb_bge_after = bge_model_ft.encode(test_answers, normalize_embeddings=True)\n",
    "\n",
    "sim_bge_after = cosine_similarity(q_emb_bge_after, a_emb_bge_after)\n",
    "\n",
    "print(\"BGE Fine-tuning SONRASI benzerlik skorları:\")\n",
    "for i, (q, a) in enumerate(zip(test_questions, test_answers)):\n",
    "    print(f\"  {q} -> {a}\")\n",
    "    print(f\"  Önce: {sim_bge_before[i][i]:.4f}\")\n",
    "    print(f\"  Sonra: {sim_bge_after[i][i]:.4f}\")\n",
    "    print(f\"  İyileşme: {(sim_bge_after[i][i] - sim_bge_before[i][i])*100:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Değerlendirme <a id=\"değerlendirme\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test seti üzerinde değerlendirme\n",
    "test_questions_all = test_df['question'].tolist()\n",
    "test_answers_all = test_df['answer'].tolist()\n",
    "\n",
    "# Turkish BERT\n",
    "q_emb_bert = turkish_bert_ft.encode(test_questions_all, normalize_embeddings=True)\n",
    "a_emb_bert = turkish_bert_ft.encode(test_answers_all, normalize_embeddings=True)\n",
    "sim_matrix_bert = cosine_similarity(q_emb_bert, a_emb_bert)\n",
    "\n",
    "# BGE\n",
    "test_questions_all_inst = [f\"{query_instruction}{q}\" for q in test_questions_all]\n",
    "q_emb_bge = bge_model_ft.encode(test_questions_all_inst, normalize_embeddings=True)\n",
    "a_emb_bge = bge_model_ft.encode(test_answers_all, normalize_embeddings=True)\n",
    "sim_matrix_bge = cosine_similarity(q_emb_bge, a_emb_bge)\n",
    "\n",
    "print(\"Embedding'ler hesaplandı.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy@k hesaplama\n",
    "def calculate_accuracy_at_k(sim_matrix, k_values=[1, 3, 5]):\n",
    "    n = len(sim_matrix)\n",
    "    results = {}\n",
    "\n",
    "    for k in k_values:\n",
    "        correct = 0\n",
    "        for i in range(n):\n",
    "            top_k_indices = np.argsort(sim_matrix[i])[-k:][::-1]\n",
    "            if i in top_k_indices:\n",
    "                correct += 1\n",
    "        results[f'accuracy@{k}'] = correct / n\n",
    "\n",
    "    return results\n",
    "\n",
    "# Turkish BERT metrikleri\n",
    "metrics_bert = calculate_accuracy_at_k(sim_matrix_bert)\n",
    "print(\"Turkish BERT Metrikleri:\")\n",
    "for metric, value in metrics_bert.items():\n",
    "    print(f\"  {metric}: {value:.4f}\")\n",
    "\n",
    "# BGE metrikleri\n",
    "metrics_bge = calculate_accuracy_at_k(sim_matrix_bge)\n",
    "print(\"\\nBGE Metrikleri:\")\n",
    "for metric, value in metrics_bge.items():\n",
    "    print(f\"  {metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benzerlik dağılımı görselleştirme\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Turkish BERT\n",
    "correct_sims_bert = [sim_matrix_bert[i][i] for i in range(len(sim_matrix_bert))]\n",
    "axes[0].hist(correct_sims_bert, bins=20, alpha=0.7, color='blue', edgecolor='black')\n",
    "axes[0].set_title('Turkish BERT - Doğru Eşleşme Benzerlik Dağılımı')\n",
    "axes[0].set_xlabel('Cosine Similarity')\n",
    "axes[0].set_ylabel('Frekans')\n",
    "axes[0].axvline(np.mean(correct_sims_bert), color='red', linestyle='--', label=f'Ortalama: {np.mean(correct_sims_bert):.3f}')\n",
    "axes[0].legend()\n",
    "\n",
    "# BGE\n",
    "correct_sims_bge = [sim_matrix_bge[i][i] for i in range(len(sim_matrix_bge))]\n",
    "axes[1].hist(correct_sims_bge, bins=20, alpha=0.7, color='green', edgecolor='black')\n",
    "axes[1].set_title('BGE - Doğru Eşleşme Benzerlik Dağılımı')\n",
    "axes[1].set_xlabel('Cosine Similarity')\n",
    "axes[1].set_ylabel('Frekans')\n",
    "axes[1].axvline(np.mean(correct_sims_bge), color='red', linestyle='--', label=f'Ortalama: {np.mean(correct_sims_bge):.3f}')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model karşılaştırması\n",
    "comparison_df = pd.DataFrame([\n",
    "    {'Model': 'Turkish BERT', **metrics_bert, 'Avg Similarity': np.mean(correct_sims_bert)},\n",
    "    {'Model': 'BGE-M3', **metrics_bge, 'Avg Similarity': np.mean(correct_sims_bge)}\n",
    "])\n",
    "\n",
    "print(\"\\nModel Karşılaştırması:\")\n",
    "print(comparison_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Kullanım Örnekleri <a id=\"kullanım\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Semantic Search Örneği\n",
    "def semantic_search(query, model, answer_database, top_k=3, use_instruction=False):\n",
    "    \"\"\"\n",
    "    Semantic search ile en ilgili cevapları bulur.\n",
    "    \"\"\"\n",
    "    if use_instruction:\n",
    "        query = f\"{query_instruction}{query}\"\n",
    "\n",
    "    # Embedding'leri hesapla\n",
    "    query_emb = model.encode([query], normalize_embeddings=True)\n",
    "    answer_embs = model.encode(answer_database, normalize_embeddings=True)\n",
    "\n",
    "    # Benzerlik hesapla\n",
    "    similarities = cosine_similarity(query_emb, answer_embs)[0]\n",
    "\n",
    "    # Top-k sonuçları al\n",
    "    top_k_indices = np.argsort(similarities)[-top_k:][::-1]\n",
    "\n",
    "    results = []\n",
    "    for idx in top_k_indices:\n",
    "        results.append({\n",
    "            'answer': answer_database[idx],\n",
    "            'score': similarities[idx]\n",
    "        })\n",
    "\n",
    "    return results\n",
    "\n",
    "# Cevap veritabanı\n",
    "answer_db = df['answer'].tolist()\n",
    "\n",
    "# Örnek sorgular\n",
    "query1 = \"Python hangi tür bir dildir?\"\n",
    "query2 = \"Derin öğrenme ile ilgili bilgi ver\"\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"TURKISH BERT - Semantic Search\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for query in [query1, query2]:\n",
    "    print(f\"\\nSoru: {query}\")\n",
    "    results = semantic_search(query, turkish_bert_ft, answer_db, top_k=3)\n",
    "    for i, result in enumerate(results, 1):\n",
    "        print(f\"  {i}. {result['answer'][:60]}... (Skor: {result['score']:.4f})\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"BGE - Semantic Search\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for query in [query1, query2]:\n",
    "    print(f\"\\nSoru: {query}\")\n",
    "    results = semantic_search(query, bge_model_ft, answer_db, top_k=3, use_instruction=True)\n",
    "    for i, result in enumerate(results, 1):\n",
    "        print(f\"  {i}. {result['answer'][:60]}... (Skor: {result['score']:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering örneği\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Tüm cevapların embedding'lerini hesapla\n",
    "all_answers = df['answer'].tolist()\n",
    "answer_embeddings = bge_model_ft.encode(all_answers, normalize_embeddings=True)\n",
    "\n",
    "# K-means clustering\n",
    "n_clusters = 5\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "clusters = kmeans.fit_predict(answer_embeddings)\n",
    "\n",
    "# Her cluster'dan örnekler göster\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"CLUSTERING SONUÇLARI\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for cluster_id in range(n_clusters):\n",
    "    print(f\"\\nCluster {cluster_id + 1}:\")\n",
    "    cluster_answers = [all_answers[i] for i in range(len(all_answers)) if clusters[i] == cluster_id]\n",
    "    for answer in cluster_answers[:3]:  # İlk 3 örnek\n",
    "        print(f\"  - {answer[:60]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model kaydetme ve yükleme\n",
    "print(\"\\nModeller kaydedildi:\")\n",
    "print(f\"  Turkish BERT: {output_path}\")\n",
    "print(f\"  BGE-M3: {output_path_bge}\")\n",
    "print(\"\\nModelleri yüklemek için:\")\n",
    "print(f\"  model = SentenceTransformer('{output_path}')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sonuç\n",
    "\n",
    "Bu notebook'ta:\n",
    "1. ✅ Turkish BERT modelini fine-tune ettik\n",
    "2. ✅ BGE-M3 modelini fine-tune ettik\n",
    "3. ✅ Her iki modeli değerlendirdik\n",
    "4. ✅ Semantic search ve clustering örnekleri yaptık\n",
    "\n",
    "### Öneriler:\n",
    "- Daha büyük veri setleri ile daha iyi sonuçlar elde edebilirsiniz\n",
    "- Farklı hiperparametrelerle deneme yapın\n",
    "- Production kullanımı için modeli ONNX formatına çevirebilirsiniz\n",
    "- FAISS gibi kütüphanelerle büyük ölçekli arama yapabilirsiniz\n",
    "\n",
    "### Kaynaklar:\n",
    "- [Sentence Transformers Docs](https://www.sbert.net/)\n",
    "- [BGE Models](https://huggingface.co/BAAI)\n",
    "- [Turkish BERT](https://huggingface.co/dbmdz/bert-base-turkish-cased)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
