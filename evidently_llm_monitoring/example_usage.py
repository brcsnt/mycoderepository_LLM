"""
Ã–rnek KullanÄ±m SenaryolarÄ±
Bu dosya farklÄ± kullanÄ±m Ã¶rneklerini gÃ¶sterir.
"""

from llm_client import LLMClient
from monitoring import LLMMonitor


def example_1_basic_usage():
    """Ã–rnek 1: Temel KullanÄ±m"""
    print("\n" + "=" * 60)
    print("ğŸ“ Ã–RNEK 1: TEMEL KULLANIM")
    print("=" * 60 + "\n")

    # Client ve monitor baÅŸlat
    client = LLMClient()
    monitor = LLMMonitor()

    # Tek bir soru sor
    prompt = "Python'da fonksiyon nasÄ±l tanÄ±mlanÄ±r?"
    result = client.generate(prompt)

    print(f"Soru: {prompt}")
    print(f"Cevap: {result['response']}")
    print(f"SÃ¼re: {result['response_time']:.2f}s\n")

    # Monitoring'e kaydet
    monitor.add_interaction(result)


def example_2_batch_processing():
    """Ã–rnek 2: Toplu Ä°ÅŸleme"""
    print("\n" + "=" * 60)
    print("ğŸ“¦ Ã–RNEK 2: TOPLU Ä°ÅLEME")
    print("=" * 60 + "\n")

    client = LLMClient()
    monitor = LLMMonitor()

    # Birden fazla soru
    prompts = [
        "JavaScript'te arrow function nedir?",
        "React hooks neden kullanÄ±lÄ±r?",
        "RESTful API'nin temel prensipleri nelerdir?",
    ]

    # Batch olarak iÅŸle
    results = client.batch_generate(prompts)

    # TÃ¼mÃ¼nÃ¼ monitÃ¶re ekle
    for result in results:
        monitor.add_interaction(result)

    # Ä°statistikleri gÃ¶ster
    monitor.print_statistics()


def example_3_quality_monitoring():
    """Ã–rnek 3: Kalite Ä°zleme"""
    print("\n" + "=" * 60)
    print("ğŸ“Š Ã–RNEK 3: KALÄ°TE Ä°ZLEME")
    print("=" * 60 + "\n")

    client = LLMClient()
    monitor = LLMMonitor()

    # Test sorularÄ±
    test_prompts = [
        "Python nedir?",
        "Machine learning algoritmalarÄ± hakkÄ±nda detaylÄ± bilgi ver.",
        "SQL JOIN tÃ¼rleri nelerdir ve nasÄ±l kullanÄ±lÄ±r?",
        "Docker container'larÄ±n avantajlarÄ±?",
        "Kubernetes nedir?",
    ]

    # Ä°ÅŸle
    for prompt in test_prompts:
        result = client.generate(prompt)
        monitor.add_interaction(result)

    # Kalite analizi
    quality = monitor.analyze_quality()

    print("ğŸ“ˆ Kalite Metrikleri:")
    print(f"   - Ã‡ok kÄ±sa cevaplar: {quality.get('very_short_responses', 0)}")
    print(f"   - Ã‡ok uzun cevaplar: {quality.get('very_long_responses', 0)}")
    print(f"   - YavaÅŸ cevaplar: {quality.get('slow_responses', 0)}")
    print(f"   - HÄ±zlÄ± cevaplar: {quality.get('fast_responses', 0)}")
    print(f"   - Hata oranÄ±: {quality.get('error_rate', 0):.1f}%\n")


def example_4_report_generation():
    """Ã–rnek 4: Evidently Raporu OluÅŸturma"""
    print("\n" + "=" * 60)
    print("ğŸ“„ Ã–RNEK 4: RAPOR OLUÅTURMA")
    print("=" * 60 + "\n")

    client = LLMClient()
    monitor = LLMMonitor()

    # Veri topla
    prompts = [
        "Python ile web scraping nasÄ±l yapÄ±lÄ±r?",
        "Git workflow best practices nelerdir?",
        "CI/CD pipeline nedir?",
        "Mikroservis mimarisi avantajlarÄ±?",
        "Database indexing nasÄ±l Ã§alÄ±ÅŸÄ±r?",
    ]

    for prompt in prompts:
        result = client.generate(prompt)
        monitor.add_interaction(result)

    # Evidently raporu oluÅŸtur
    print("Evidently raporu oluÅŸturuluyor...")
    report = monitor.generate_report()

    # Veriyi de kaydet
    monitor.save_data()

    print("\nâœ… Rapor ve veri baÅŸarÄ±yla kaydedildi!")


def example_5_model_comparison():
    """Ã–rnek 5: Model KarÅŸÄ±laÅŸtÄ±rma"""
    print("\n" + "=" * 60)
    print("ğŸ”¬ Ã–RNEK 5: MODEL KARÅILAÅTIRMA")
    print("=" * 60 + "\n")

    # AynÄ± prompt'u farklÄ± ayarlarla test et
    test_prompt = "Machine learning ve deep learning arasÄ±ndaki farklar nelerdir?"

    client = LLMClient()
    monitor = LLMMonitor()

    # FarklÄ± temperature deÄŸerleri ile test et
    temperatures = [0.3, 0.7, 1.0]

    for temp in temperatures:
        print(f"\nTemperature: {temp}")
        result = client.generate(test_prompt, temperature=temp)
        result['temperature'] = temp  # Metadataya ekle
        monitor.add_interaction(result)

        print(f"Response uzunluÄŸu: {len(result['response'])} karakter")
        print(f"SÃ¼re: {result['response_time']:.2f}s")

    # Ä°statistikleri gÃ¶ster
    monitor.print_statistics()


def example_6_error_handling():
    """Ã–rnek 6: Hata YÃ¶netimi"""
    print("\n" + "=" * 60)
    print("âš ï¸  Ã–RNEK 6: HATA YÃ–NETÄ°MÄ°")
    print("=" * 60 + "\n")

    client = LLMClient()
    monitor = LLMMonitor()

    # Normal ve potansiyel problemli promptlar
    prompts = [
        "Normal bir soru: Python nedir?",
        "",  # BoÅŸ prompt
        "Ã‡ok uzun bir prompt: " + "lorem ipsum " * 500,  # Ã‡ok uzun prompt
    ]

    for i, prompt in enumerate(prompts, 1):
        print(f"\nTest {i}:")
        result = client.generate(prompt)

        if 'error' in result:
            print(f"âŒ Hata: {result['error']}")
        else:
            print(f"âœ… BaÅŸarÄ±lÄ±: {len(result['response'])} karakter")

        monitor.add_interaction(result)

    # Hata analizi
    quality = monitor.analyze_quality()
    print(f"\nğŸ“Š Hata oranÄ±: {quality.get('error_rate', 0):.1f}%")


def main():
    """TÃ¼m Ã¶rnekleri Ã§alÄ±ÅŸtÄ±r"""
    print("\n" + "=" * 60)
    print("ğŸ“ EVIDENTLY LLM MONITORING - Ã–RNEK KULANIMLAR")
    print("=" * 60)

    examples = [
        ("1", "Temel KullanÄ±m", example_1_basic_usage),
        ("2", "Toplu Ä°ÅŸleme", example_2_batch_processing),
        ("3", "Kalite Ä°zleme", example_3_quality_monitoring),
        ("4", "Rapor OluÅŸturma", example_4_report_generation),
        ("5", "Model KarÅŸÄ±laÅŸtÄ±rma", example_5_model_comparison),
        ("6", "Hata YÃ¶netimi", example_6_error_handling),
    ]

    print("\nHangi Ã¶rneÄŸi Ã§alÄ±ÅŸtÄ±rmak istersiniz?")
    for num, name, _ in examples:
        print(f"  {num}. {name}")
    print("  0. TÃ¼mÃ¼nÃ¼ Ã§alÄ±ÅŸtÄ±r")
    print("  q. Ã‡Ä±kÄ±ÅŸ")

    choice = input("\nSeÃ§iminiz: ").strip()

    if choice == 'q':
        print("Ã‡Ä±kÄ±lÄ±yor...")
        return

    if choice == '0':
        for _, _, func in examples:
            func()
            print("\n" + "-" * 60)
    else:
        for num, _, func in examples:
            if choice == num:
                func()
                break
        else:
            print("GeÃ§ersiz seÃ§im!")

    print("\nâœ… Ã–rnek(ler) tamamlandÄ±!")


if __name__ == "__main__":
    main()
