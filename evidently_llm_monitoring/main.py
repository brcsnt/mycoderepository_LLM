"""
Evidently LLM Monitoring - Ana Uygulama
LLM API'sine baÄŸlanÄ±r ve Evidently ile izler.
"""

import sys
from typing import List, Optional
from llm_client import LLMClient
from monitoring import LLMMonitor


class LLMMonitoringApp:
    """Ana uygulama sÄ±nÄ±fÄ±"""

    def __init__(self):
        print("\n" + "=" * 60)
        print("ğŸš€ EVIDENTLY LLM MONÄ°TORÄ°NG SÄ°STEMÄ°")
        print("=" * 60 + "\n")

        # LLM client ve monitor baÅŸlat
        try:
            self.llm_client = LLMClient()
            self.monitor = LLMMonitor()
            print("\nâœ… Sistem baÅŸarÄ±yla baÅŸlatÄ±ldÄ±!\n")
        except Exception as e:
            print(f"\nâŒ Hata: {e}")
            print("LÃ¼tfen konfigÃ¼rasyonu kontrol edin.\n")
            sys.exit(1)

    def process_single_prompt(self, prompt: str, **kwargs) -> dict:
        """
        Tek bir prompt iÅŸle ve monitÃ¶r et

        Args:
            prompt: KullanÄ±cÄ± promptu
            **kwargs: LLM parametreleri

        Returns:
            LLM response ve metrikleri
        """
        print(f"ğŸ“ Ä°ÅŸleniyor: {prompt[:50]}...")

        # LLM'den response al
        result = self.llm_client.generate(prompt, **kwargs)

        # Monitoring sistemine kaydet
        self.monitor.add_interaction(result)

        return result

    def process_batch(self, prompts: List[str], **kwargs) -> List[dict]:
        """
        Birden fazla prompt'u iÅŸle

        Args:
            prompts: Prompt listesi
            **kwargs: LLM parametreleri

        Returns:
            Response listesi
        """
        print(f"\nğŸ“¦ {len(prompts)} prompt toplu iÅŸleniyor...\n")

        results = []
        for i, prompt in enumerate(prompts, 1):
            print(f"[{i}/{len(prompts)}] Ä°ÅŸleniyor...")
            result = self.process_single_prompt(prompt, **kwargs)
            results.append(result)

        return results

    def interactive_mode(self):
        """Ä°nteraktif sohbet modu"""
        print("\nğŸ’¬ Ä°NTERAKTÄ°F MOD")
        print("Ã‡Ä±kmak iÃ§in 'exit' veya 'quit' yazÄ±n")
        print("Rapor oluÅŸturmak iÃ§in 'report' yazÄ±n")
        print("Ä°statistikler iÃ§in 'stats' yazÄ±n")
        print("-" * 60 + "\n")

        while True:
            try:
                user_input = input("ğŸ‘¤ Siz: ").strip()

                if not user_input:
                    continue

                # Ã–zel komutlar
                if user_input.lower() in ['exit', 'quit', 'Ã§Ä±kÄ±ÅŸ']:
                    print("\nğŸ‘‹ GÃ¶rÃ¼ÅŸmek Ã¼zere!")
                    break

                elif user_input.lower() == 'report':
                    print("\nğŸ“Š Rapor oluÅŸturuluyor...\n")
                    self.monitor.generate_report()
                    continue

                elif user_input.lower() == 'stats':
                    self.monitor.print_statistics()
                    continue

                elif user_input.lower() == 'save':
                    self.monitor.save_data()
                    continue

                # Normal prompt iÅŸle
                result = self.process_single_prompt(user_input)

                print(f"\nğŸ¤– LLM: {result['response']}")
                print(f"â±ï¸  SÃ¼re: {result['response_time']:.2f}s")
                print(f"ğŸ“ Uzunluk: {len(result['response'])} karakter\n")

            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ Kesintiye uÄŸradÄ±. Ã‡Ä±kÄ±lÄ±yor...")
                break
            except Exception as e:
                print(f"\nâŒ Hata: {e}\n")

    def run_demo(self):
        """Demo senaryosu Ã§alÄ±ÅŸtÄ±r"""
        print("\nğŸ¬ DEMO SENARYOSU BAÅLIYOR...\n")

        # Ã–rnek sorular
        demo_prompts = [
            "Python'da liste ve tuple arasÄ±ndaki farklar nelerdir?",
            "Machine learning iÃ§in hangi Python kÃ¼tÃ¼phanelerini Ã¶nerirsin?",
            "REST API nedir? KÄ±sa bir aÃ§Ä±klama yap.",
            "Docker container'larÄ± neden kullanÄ±lÄ±r?",
            "Git'te branch nedir ve nasÄ±l kullanÄ±lÄ±r?",
        ]

        # Prompts iÅŸle
        results = self.process_batch(demo_prompts)

        # Ä°statistikler gÃ¶ster
        print("\n" + "=" * 60)
        self.monitor.print_statistics()

        # Kalite analizi
        quality = self.monitor.analyze_quality()
        print("ğŸ“Š KALÄ°TE ANALÄ°ZÄ°")
        print("=" * 60)
        print(f"Ã‡ok kÄ±sa cevaplar (<50 karakter): {quality.get('very_short_responses', 0)}")
        print(f"Ã‡ok uzun cevaplar (>1000 karakter): {quality.get('very_long_responses', 0)}")
        print(f"YavaÅŸ cevaplar (>5s): {quality.get('slow_responses', 0)}")
        print(f"HÄ±zlÄ± cevaplar (<1s): {quality.get('fast_responses', 0)}")
        print(f"Hata oranÄ±: {quality.get('error_rate', 0):.1f}%")
        print("=" * 60 + "\n")

        # Rapor oluÅŸtur
        print("ğŸ“„ Evidently raporu oluÅŸturuluyor...\n")
        self.monitor.generate_report()

        # Veriyi kaydet
        print("ğŸ’¾ Veri kaydediliyor...\n")
        self.monitor.save_data()

        print("\nâœ… Demo tamamlandÄ±!")

    def run_custom_scenario(self, prompts: List[str], generate_report: bool = True):
        """
        Ã–zel senaryo Ã§alÄ±ÅŸtÄ±r

        Args:
            prompts: Ä°ÅŸlenecek promptlar
            generate_report: Rapor oluÅŸturulsun mu?
        """
        results = self.process_batch(prompts)

        self.monitor.print_statistics()

        if generate_report:
            self.monitor.generate_report()
            self.monitor.save_data()

        return results


def main():
    """Ana fonksiyon"""
    import argparse

    parser = argparse.ArgumentParser(description='Evidently LLM Monitoring')
    parser.add_argument('--mode', choices=['interactive', 'demo', 'batch'],
                        default='interactive',
                        help='Ã‡alÄ±ÅŸma modu')
    parser.add_argument('--prompts', nargs='+',
                        help='Batch modunda iÅŸlenecek promptlar')

    args = parser.parse_args()

    # UygulamayÄ± baÅŸlat
    app = LLMMonitoringApp()

    # Mod seÃ§imine gÃ¶re Ã§alÄ±ÅŸtÄ±r
    if args.mode == 'interactive':
        app.interactive_mode()
    elif args.mode == 'demo':
        app.run_demo()
    elif args.mode == 'batch':
        if not args.prompts:
            print("âŒ Batch modu iÃ§in --prompts parametresi gerekli!")
            sys.exit(1)
        app.run_custom_scenario(args.prompts)
    else:
        print(f"âŒ GeÃ§ersiz mod: {args.mode}")
        sys.exit(1)


if __name__ == "__main__":
    main()
