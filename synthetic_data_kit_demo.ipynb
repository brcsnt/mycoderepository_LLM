{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta Llama Synthetic Data Kit - Yerel Model KullanÄ±m Rehberi\n",
    "\n",
    "Bu notebook, Meta Llama'nÄ±n Synthetic Data Kit'ini yerel Llama modelinizle nasÄ±l kullanacaÄŸÄ±nÄ±zÄ± adÄ±m adÄ±m gÃ¶sterir.\n",
    "\n",
    "## Ä°Ã§indekiler\n",
    "1. Synthetic Data Kit Nedir?\n",
    "2. Kurulum\n",
    "3. Yerel Model API AyarlarÄ± (vLLM)\n",
    "4. Temel KullanÄ±m - 4 AdÄ±m\n",
    "   - Ingest (Veri YÃ¼kleme)\n",
    "   - Create (Sentetik Veri OluÅŸturma)\n",
    "   - Curate (Veri Filtreleme)\n",
    "   - Save-As (Format DÃ¶nÃ¼ÅŸtÃ¼rme)\n",
    "5. Pratik Demo\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Synthetic Data Kit Nedir?\n",
    "\n",
    "Meta Llama'nÄ±n Synthetic Data Kit'i, LLM'leri fine-tune etmek iÃ§in yÃ¼ksek kaliteli sentetik veri setleri oluÅŸturmaya yarayan aÃ§Ä±k kaynaklÄ± bir araÃ§tÄ±r.\n",
    "\n",
    "**Ana Ã–zellikler:**\n",
    "- PDF, HTML, DOCX, TXT gibi Ã§eÅŸitli dosya formatlarÄ±nÄ± iÅŸler\n",
    "- QA Ã§iftleri, Chain-of-Thought, Ã¶zet gibi formatlar Ã¼retir\n",
    "- Kalite kontrolÃ¼ iÃ§in LLM-as-a-judge kullanÄ±r\n",
    "- Yerel model desteÄŸi (vLLM) ve API endpoint desteÄŸi\n",
    "- Toplu iÅŸlem (batch processing) yetenekleri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Kurulum\n",
    "\n",
    "### Gereksinimler\n",
    "- Python 3.10+\n",
    "- Yerel Llama modeli (Ã¶rn: Llama 3.1, Llama 3.2)\n",
    "- vLLM (yerel inference iÃ§in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthetic Data Kit'i kuralÄ±m\n",
    "!pip install synthetic-data-kit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vLLM kurulumu (yerel model Ã§alÄ±ÅŸtÄ±rmak iÃ§in)\n",
    "!pip install vllm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Yerel Model API AyarlarÄ± (vLLM)\n",
    "\n",
    "Synthetic Data Kit, yerel modelinizi kullanmak iÃ§in bir API endpoint'e ihtiyaÃ§ duyar. vLLM ile yerel modelinizi OpenAI-uyumlu bir API olarak Ã§alÄ±ÅŸtÄ±rabilirsiniz.\n",
    "\n",
    "### 3.1. vLLM Sunucusunu BaÅŸlatma\n",
    "\n",
    "**Terminal'de Ã§alÄ±ÅŸtÄ±rÄ±n (ayrÄ± bir terminal penceresi):**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "# Llama modelinizin yolunu belirtin\n",
    "python -m vllm.entrypoints.openai.api_server \\\n",
    "    --model /path/to/your/llama-model \\\n",
    "    --host 0.0.0.0 \\\n",
    "    --port 8000 \\\n",
    "    --dtype auto \\\n",
    "    --api-key your-api-key-here\n",
    "\n",
    "# Ã–rnek:\n",
    "python -m vllm.entrypoints.openai.api_server \\\n",
    "    --model meta-llama/Llama-3.2-3B-Instruct \\\n",
    "    --host 0.0.0.0 \\\n",
    "    --port 8000 \\\n",
    "    --dtype auto \\\n",
    "    --api-key sk-123456\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. API BaÄŸlantÄ±sÄ±nÄ± Test Etme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# vLLM API'nizin Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± test edin\n",
    "api_url = \"http://localhost:8000/v1/chat/completions\"\n",
    "api_key = \"sk-123456\"  # vLLM baÅŸlatÄ±rken kullandÄ±ÄŸÄ±nÄ±z API key\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {api_key}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "data = {\n",
    "    \"model\": \"meta-llama/Llama-3.2-3B-Instruct\",  # Model adÄ±nÄ±z\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"Merhaba! NasÄ±lsÄ±n?\"}\n",
    "    ],\n",
    "    \"max_tokens\": 100\n",
    "}\n",
    "\n",
    "try:\n",
    "    response = requests.post(api_url, headers=headers, json=data)\n",
    "    response.raise_for_status()\n",
    "    result = response.json()\n",
    "    print(\"âœ… API baÅŸarÄ±yla Ã§alÄ±ÅŸÄ±yor!\")\n",
    "    print(f\"Model yanÄ±tÄ±: {result['choices'][0]['message']['content']}\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ API hatasÄ±: {e}\")\n",
    "    print(\"LÃ¼tfen vLLM sunucusunun Ã§alÄ±ÅŸtÄ±ÄŸÄ±ndan emin olun.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Synthetic Data Kit - 4 AdÄ±mlÄ±k Ä°ÅŸ AkÄ±ÅŸÄ±\n",
    "\n",
    "Synthetic Data Kit 4 ana komuttan oluÅŸur:\n",
    "\n",
    "1. **`ingest`**: DokÃ¼manlarÄ± iÅŸler ve parse eder\n",
    "2. **`create`**: Sentetik eÄŸitim Ã¶rnekleri oluÅŸturur (QA, CoT, Ã¶zet)\n",
    "3. **`curate`**: Kalite kontrolÃ¼ yapar ve filtreler\n",
    "4. **`save-as`**: Fine-tuning formatlarÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. KonfigÃ¼rasyon DosyasÄ± OluÅŸturma\n",
    "\n",
    "Yerel API'nizi kullanmak iÃ§in bir config dosyasÄ± oluÅŸturalÄ±m:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import os\n",
    "\n",
    "# Demo iÃ§in klasÃ¶r yapÄ±sÄ± oluÅŸturalÄ±m\n",
    "os.makedirs('demo_data/input', exist_ok=True)\n",
    "os.makedirs('demo_data/output', exist_ok=True)\n",
    "\n",
    "# KonfigÃ¼rasyon dosyasÄ±\n",
    "config = {\n",
    "    'llm': {\n",
    "        'provider': 'openai',  # vLLM OpenAI-uyumlu API kullanÄ±r\n",
    "        'api_base': 'http://localhost:8000/v1',\n",
    "        'api_key': 'sk-123456',  # vLLM API key'iniz\n",
    "        'model': 'meta-llama/Llama-3.2-3B-Instruct',  # Model adÄ±nÄ±z\n",
    "        'temperature': 0.7,\n",
    "        'max_tokens': 2048\n",
    "    },\n",
    "    'ingest': {\n",
    "        'chunk_size': 2000,\n",
    "        'chunk_overlap': 200\n",
    "    },\n",
    "    'create': {\n",
    "        'format': 'qa',  # qa, cot, summary\n",
    "        'num_examples': 5\n",
    "    },\n",
    "    'curate': {\n",
    "        'quality_threshold': 0.7\n",
    "    }\n",
    "}\n",
    "\n",
    "# Config dosyasÄ±nÄ± kaydet\n",
    "with open('demo_data/config.yaml', 'w') as f:\n",
    "    yaml.dump(config, f, default_flow_style=False)\n",
    "\n",
    "print(\"âœ… KonfigÃ¼rasyon dosyasÄ± oluÅŸturuldu: demo_data/config.yaml\")\n",
    "print(\"\\nÄ°Ã§erik:\")\n",
    "print(yaml.dump(config, default_flow_style=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Ã–rnek Veri HazÄ±rlama\n",
    "\n",
    "Demo iÃ§in Ã¶rnek bir metin dosyasÄ± oluÅŸturalÄ±m:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ã–rnek metin verisi\n",
    "sample_text = \"\"\"\n",
    "Yapay Zeka ve Makine Ã–ÄŸrenmesi\n",
    "\n",
    "Yapay zeka (AI), makinelerin insan benzeri zeka gerektiren gÃ¶revleri yerine getirmesini saÄŸlayan \n",
    "bir bilgisayar bilimi dalÄ±dÄ±r. Makine Ã¶ÄŸrenmesi ise yapay zekanÄ±n bir alt dalÄ±dÄ±r ve makinelerin \n",
    "deneyimlerden Ã¶ÄŸrenmesini ve zamanla performansÄ±nÄ± artÄ±rmasÄ±nÄ± saÄŸlar.\n",
    "\n",
    "Derin Ã¶ÄŸrenme, makine Ã¶ÄŸrenmesinin Ã¶zel bir tÃ¼rÃ¼dÃ¼r ve yapay sinir aÄŸlarÄ±nÄ± kullanÄ±r. Bu aÄŸlar, \n",
    "insan beyninin Ã§alÄ±ÅŸma ÅŸeklinden ilham alÄ±r ve birden fazla katmandan oluÅŸur. Her katman, veriden \n",
    "farklÄ± seviyede Ã¶zellikler Ã¶ÄŸrenir.\n",
    "\n",
    "Large Language Models (LLM'ler), milyarlarca parametre iÃ§eren ve bÃ¼yÃ¼k metin veri setleri Ã¼zerinde \n",
    "eÄŸitilen derin Ã¶ÄŸrenme modelleridir. Bu modeller, doÄŸal dil iÅŸleme gÃ¶revlerinde Ã§Ä±ÄŸÄ±r aÃ§mÄ±ÅŸtÄ±r. \n",
    "GPT, BERT ve Llama gibi modeller, metin oluÅŸturma, Ã§eviri, soru-cevap ve birÃ§ok diÄŸer gÃ¶revde \n",
    "kullanÄ±lÄ±r.\n",
    "\n",
    "Fine-tuning, Ã¶nceden eÄŸitilmiÅŸ bir modelin belirli bir gÃ¶rev iÃ§in yeniden eÄŸitilmesi sÃ¼recidir. \n",
    "Bu iÅŸlem, modelin genel bilgisini korurken, Ã¶zel bir domaine veya gÃ¶reve adapte olmasÄ±nÄ± saÄŸlar.\n",
    "\"\"\"\n",
    "\n",
    "with open('demo_data/input/ai_tutorial.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(sample_text)\n",
    "\n",
    "print(\"âœ… Ã–rnek veri dosyasÄ± oluÅŸturuldu: demo_data/input/ai_tutorial.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Pratik Demo - AdÄ±m AdÄ±m KullanÄ±m\n",
    "\n",
    "Åimdi Synthetic Data Kit'in tÃ¼m adÄ±mlarÄ±nÄ± kullanalÄ±m."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdÄ±m 1: INGEST - DokÃ¼manlarÄ± Ä°ÅŸleme\n",
    "\n",
    "Ä°lk adÄ±m, ham dokÃ¼manlarÄ± parse edip chunk'lara ayÄ±rmaktÄ±r."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INGEST komutu\n",
    "!synthetic-data-kit ingest \\\n",
    "    --input-dir demo_data/input \\\n",
    "    --output-file demo_data/ingested.jsonl \\\n",
    "    --chunk-size 1000 \\\n",
    "    --chunk-overlap 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ä°ÅŸlenmiÅŸ veriyi inceleyelim\n",
    "import json\n",
    "\n",
    "print(\"ğŸ“„ Ä°ÅŸlenmiÅŸ Veri:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "with open('demo_data/ingested.jsonl', 'r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f, 1):\n",
    "        data = json.loads(line)\n",
    "        print(f\"\\nChunk {i}:\")\n",
    "        print(f\"Kaynak: {data.get('source', 'N/A')}\")\n",
    "        print(f\"Ä°Ã§erik (ilk 200 karakter): {data.get('text', '')[:200]}...\")\n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdÄ±m 2: CREATE - Sentetik EÄŸitim Verisi OluÅŸturma\n",
    "\n",
    "Ä°ÅŸlenmiÅŸ veriden QA Ã§iftleri, Chain-of-Thought veya Ã¶zet Ã¶rnekleri oluÅŸturalÄ±m.\n",
    "\n",
    "**Ã–NEMLÄ°:** Bu adÄ±m yerel modelinizi kullanacak. vLLM sunucunuzun Ã§alÄ±ÅŸtÄ±ÄŸÄ±ndan emin olun!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE komutu - QA Ã§iftleri oluÅŸturma\n",
    "!synthetic-data-kit create \\\n",
    "    --input-file demo_data/ingested.jsonl \\\n",
    "    --output-file demo_data/created_qa.jsonl \\\n",
    "    --format qa \\\n",
    "    --api-base http://localhost:8000/v1 \\\n",
    "    --api-key sk-123456 \\\n",
    "    --model meta-llama/Llama-3.2-3B-Instruct \\\n",
    "    --temperature 0.7 \\\n",
    "    --num-examples 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OluÅŸturulan QA Ã§iftlerini inceleyelim\n",
    "print(\"ğŸ’¬ OluÅŸturulan QA Ã‡iftleri:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "with open('demo_data/created_qa.jsonl', 'r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f, 1):\n",
    "        data = json.loads(line)\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Ã–rnek {i}:\")\n",
    "        print(f\"\\nSoru: {data.get('question', 'N/A')}\")\n",
    "        print(f\"\\nCevap: {data.get('answer', 'N/A')}\")\n",
    "        print(f\"\\nKaynak: {data.get('source', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternatif: Chain-of-Thought (CoT) FormatÄ±nda OluÅŸturma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE komutu - CoT formatÄ±\n",
    "!synthetic-data-kit create \\\n",
    "    --input-file demo_data/ingested.jsonl \\\n",
    "    --output-file demo_data/created_cot.jsonl \\\n",
    "    --format cot \\\n",
    "    --api-base http://localhost:8000/v1 \\\n",
    "    --api-key sk-123456 \\\n",
    "    --model meta-llama/Llama-3.2-3B-Instruct \\\n",
    "    --temperature 0.7 \\\n",
    "    --num-examples 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdÄ±m 3: CURATE - Kalite KontrolÃ¼\n",
    "\n",
    "LLM-as-a-judge kullanarak dÃ¼ÅŸÃ¼k kaliteli Ã¶rnekleri filtreleyelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CURATE komutu\n",
    "!synthetic-data-kit curate \\\n",
    "    --input-file demo_data/created_qa.jsonl \\\n",
    "    --output-file demo_data/curated.jsonl \\\n",
    "    --api-base http://localhost:8000/v1 \\\n",
    "    --api-key sk-123456 \\\n",
    "    --model meta-llama/Llama-3.2-3B-Instruct \\\n",
    "    --quality-threshold 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FiltrelenmiÅŸ veriyi inceleyelim\n",
    "print(\"ğŸ” Kalite KontrolÃ¼ SonuÃ§larÄ±:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "with open('demo_data/curated.jsonl', 'r', encoding='utf-8') as f:\n",
    "    curated_data = [json.loads(line) for line in f]\n",
    "\n",
    "print(f\"\\nFiltrelenmiÅŸ Ã¶rnek sayÄ±sÄ±: {len(curated_data)}\")\n",
    "\n",
    "for i, data in enumerate(curated_data, 1):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Ã–rnek {i}:\")\n",
    "    print(f\"Kalite Skoru: {data.get('quality_score', 'N/A')}\")\n",
    "    print(f\"Soru: {data.get('question', 'N/A')}\")\n",
    "    print(f\"Cevap: {data.get('answer', 'N/A')[:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdÄ±m 4: SAVE-AS - Fine-tuning FormatÄ±na DÃ¶nÃ¼ÅŸtÃ¼rme\n",
    "\n",
    "Son olarak, verimizi fine-tuning iÃ§in uygun formatlara dÃ¶nÃ¼ÅŸtÃ¼relim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE-AS komutu - Alpaca formatÄ±\n",
    "!synthetic-data-kit save-as \\\n",
    "    --input-file demo_data/curated.jsonl \\\n",
    "    --output-file demo_data/final_alpaca.json \\\n",
    "    --format alpaca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alpaca formatÄ±nÄ± inceleyelim\n",
    "with open('demo_data/final_alpaca.json', 'r', encoding='utf-8') as f:\n",
    "    alpaca_data = json.load(f)\n",
    "\n",
    "print(\"ğŸ“¦ Alpaca FormatÄ±:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Toplam Ã¶rnek: {len(alpaca_data)}\\n\")\n",
    "\n",
    "for i, item in enumerate(alpaca_data[:2], 1):  # Ä°lk 2 Ã¶rneÄŸi gÃ¶ster\n",
    "    print(f\"\\nÃ–rnek {i}:\")\n",
    "    print(json.dumps(item, indent=2, ensure_ascii=False))\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatML formatÄ±na da dÃ¶nÃ¼ÅŸtÃ¼rebiliriz\n",
    "!synthetic-data-kit save-as \\\n",
    "    --input-file demo_data/curated.jsonl \\\n",
    "    --output-file demo_data/final_chatml.jsonl \\\n",
    "    --format chatml\n",
    "\n",
    "print(\"âœ… ChatML formatÄ± oluÅŸturuldu: demo_data/final_chatml.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Python ile Programatik KullanÄ±m\n",
    "\n",
    "CLI yerine Python kodu ile de kullanabilirsiniz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python API kullanÄ±mÄ± (varsa)\n",
    "# Not: Bu kÄ±sÄ±m SDK'nÄ±n Python API'sine gÃ¶re gÃ¼ncellenmelidir\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "# Yerel modelinize baÄŸlanma\n",
    "client = OpenAI(\n",
    "    base_url=\"http://localhost:8000/v1\",\n",
    "    api_key=\"sk-123456\"\n",
    ")\n",
    "\n",
    "# Ã–rnek kullanÄ±m\n",
    "response = client.chat.completions.create(\n",
    "    model=\"meta-llama/Llama-3.2-3B-Instruct\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Sen yardÄ±mcÄ± bir asistansÄ±n.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Yapay zeka nedir?\"}\n",
    "    ],\n",
    "    max_tokens=200\n",
    ")\n",
    "\n",
    "print(\"Model YanÄ±tÄ±:\")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Toplu Ä°ÅŸleme (Batch Processing)\n",
    "\n",
    "Birden fazla dosyayÄ± aynÄ± anda iÅŸleyebilirsiniz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Birden fazla dosya ekleyelim\n",
    "texts = [\n",
    "    (\"python_basics.txt\", \"Python bir programlama dilidir. Basit sÃ¶zdizimine sahiptir.\"),\n",
    "    (\"database.txt\", \"VeritabanlarÄ± veri depolamak iÃ§in kullanÄ±lÄ±r. SQL sorgu dilidir.\")\n",
    "]\n",
    "\n",
    "for filename, content in texts:\n",
    "    with open(f'demo_data/input/{filename}', 'w', encoding='utf-8') as f:\n",
    "        f.write(content)\n",
    "\n",
    "print(\"âœ… Birden fazla dosya eklendi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TÃ¼m klasÃ¶rÃ¼ iÅŸleme\n",
    "!synthetic-data-kit ingest \\\n",
    "    --input-dir demo_data/input \\\n",
    "    --output-file demo_data/batch_ingested.jsonl \\\n",
    "    --chunk-size 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Ä°puÃ§larÄ± ve En Ä°yi Uygulamalar\n",
    "\n",
    "### 8.1. Model SeÃ§imi\n",
    "- **KÃ¼Ã§Ã¼k modeller (3B-8B)**: HÄ±zlÄ± prototipleme iÃ§in\n",
    "- **Orta modeller (13B-30B)**: Daha iyi kalite\n",
    "- **BÃ¼yÃ¼k modeller (70B+)**: En yÃ¼ksek kalite ama daha yavaÅŸ\n",
    "\n",
    "### 8.2. Parametreler\n",
    "- **Temperature**: 0.7-0.9 arasÄ± Ã§eÅŸitlilik iÃ§in iyi\n",
    "- **Chunk Size**: DÃ¶kÃ¼mana gÃ¶re ayarlayÄ±n (1000-2000 karakter)\n",
    "- **Quality Threshold**: 0.7-0.8 dengeli filtreleme\n",
    "\n",
    "### 8.3. Performans\n",
    "- GPU kullanÄ±n (vLLM ile)\n",
    "- Batch iÅŸleme kullanÄ±n\n",
    "- Ã–nce kÃ¼Ã§Ã¼k Ã¶rneklerle test edin\n",
    "\n",
    "### 8.4. Kalite KontrolÃ¼\n",
    "- Her adÄ±mdan sonra Ã§Ä±ktÄ±larÄ± inceleyin\n",
    "- Curate adÄ±mÄ±nÄ± mutlaka kullanÄ±n\n",
    "- Manuel olarak Ã¶rnekleri gÃ¶zden geÃ§irin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Troubleshooting\n",
    "\n",
    "### Problem: \"Connection refused\" hatasÄ±\n",
    "**Ã‡Ã¶zÃ¼m**: vLLM sunucusunun Ã§alÄ±ÅŸtÄ±ÄŸÄ±ndan emin olun:\n",
    "```bash\n",
    "curl http://localhost:8000/v1/models\n",
    "```\n",
    "\n",
    "### Problem: \"Out of memory\" hatasÄ±\n",
    "**Ã‡Ã¶zÃ¼m**: \n",
    "- Daha kÃ¼Ã§Ã¼k model kullanÄ±n\n",
    "- Chunk size'Ä± azaltÄ±n\n",
    "- GPU belleÄŸini artÄ±rÄ±n\n",
    "\n",
    "### Problem: DÃ¼ÅŸÃ¼k kaliteli Ã¶rnekler\n",
    "**Ã‡Ã¶zÃ¼m**:\n",
    "- Temperature deÄŸerini ayarlayÄ±n\n",
    "- Daha bÃ¼yÃ¼k model kullanÄ±n\n",
    "- Quality threshold'u yÃ¼kseltin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Sonraki AdÄ±mlar\n",
    "\n",
    "ArtÄ±k sentetik veri Ã¼rettiniz! Åimdi yapabilecekleriniz:\n",
    "\n",
    "1. **Fine-tuning**: OluÅŸturduÄŸunuz veri ile modelinizi fine-tune edin\n",
    "2. **Veri Ä°yileÅŸtirme**: Daha fazla kaynak dokÃ¼man ekleyin\n",
    "3. **Format Denemeleri**: QA, CoT, Summary formatlarÄ±nÄ± deneyin\n",
    "4. **Ã–lÃ§eklendirme**: Daha bÃ¼yÃ¼k veri setleri oluÅŸturun\n",
    "\n",
    "### FaydalÄ± Kaynaklar\n",
    "- [Synthetic Data Kit GitHub](https://github.com/meta-llama/synthetic-data-kit)\n",
    "- [vLLM DokÃ¼mantasyonu](https://docs.vllm.ai/)\n",
    "- [Llama Models](https://github.com/meta-llama)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Ã–zet\n",
    "\n",
    "Bu notebook'ta Ã¶ÄŸrendikleriniz:\n",
    "\n",
    "âœ… Synthetic Data Kit kurulumu  \n",
    "âœ… vLLM ile yerel model API'si kurma  \n",
    "âœ… 4 adÄ±mlÄ±k veri oluÅŸturma sÃ¼reci (Ingest â†’ Create â†’ Curate â†’ Save-As)  \n",
    "âœ… FarklÄ± formatlar (QA, CoT, Summary)  \n",
    "âœ… Kalite kontrolÃ¼ ve filtreleme  \n",
    "âœ… Fine-tuning formatlarÄ±na dÃ¶nÃ¼ÅŸtÃ¼rme  \n",
    "\n",
    "**BaÅŸarÄ±lar! ğŸ‰**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
