{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Türkçe BERT Embedding Fine-Tuning - Soru Cevap Seti\n",
    "\n",
    "Bu notebook, `dbmdz/bert-base-turkish-cased` modelini soru-cevap çiftleri için fine-tune eder.\n",
    "\n",
    "## Kurulum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentence-transformers transformers datasets accelerate torch -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kütüphaneleri İçe Aktarma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses, evaluation\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "\n",
    "# GPU kontrolü\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Kullanılan cihaz: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Veri Yükleme\n",
    "\n",
    "Verinizin formatı şu şekilde olmalı:\n",
    "- CSV: 'soru' ve 'cevap' sütunları\n",
    "- JSON: [{\"soru\": \"...\", \"cevap\": \"...\"}, ...]\n",
    "- Excel: 'soru' ve 'cevap' sütunları"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veri yükleme fonksiyonu\n",
    "def load_qa_data(file_path):\n",
    "    \"\"\"\n",
    "    Soru-cevap verilerini yükler.\n",
    "    Desteklenen formatlar: CSV, JSON, Excel\n",
    "    \"\"\"\n",
    "    if file_path.endswith('.csv'):\n",
    "        df = pd.read_csv(file_path)\n",
    "    elif file_path.endswith('.json'):\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        df = pd.DataFrame(data)\n",
    "    elif file_path.endswith(('.xlsx', '.xls')):\n",
    "        df = pd.read_excel(file_path)\n",
    "    else:\n",
    "        raise ValueError(\"Desteklenmeyen dosya formatı!\")\n",
    "    \n",
    "    # Sütun isimlerini kontrol et ve standartlaştır\n",
    "    if 'soru' not in df.columns or 'cevap' not in df.columns:\n",
    "        print(f\"Mevcut sütunlar: {df.columns.tolist()}\")\n",
    "        raise ValueError(\"Veri setinde 'soru' ve 'cevap' sütunları olmalı!\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# ÖRNEK: Eğer elinizde veri yoksa, örnek veri oluşturabilirsiniz:\n",
    "# Kendi veri dosyanızın yolunu yazın\n",
    "DATA_FILE = 'soru_cevap_veri.csv'  # Buraya kendi dosya yolunuzu yazın\n",
    "\n",
    "# Örnek veri oluşturma (test için)\n",
    "sample_data = {\n",
    "    'soru': [\n",
    "        'Python nedir?',\n",
    "        'Makine öğrenmesi ne demektir?',\n",
    "        'Deep learning nedir?',\n",
    "        'BERT modeli nasıl çalışır?',\n",
    "        'Transformer mimarisi nedir?'\n",
    "    ],\n",
    "    'cevap': [\n",
    "        'Python, yüksek seviyeli, yorumlamalı bir programlama dilidir.',\n",
    "        'Makine öğrenmesi, bilgisayarların verilerden öğrenmesini sağlayan yapay zeka dalıdır.',\n",
    "        'Deep learning, çok katmanlı yapay sinir ağları kullanarak öğrenen bir makine öğrenmesi yöntemidir.',\n",
    "        'BERT, çift yönlü transformer mimarisini kullanan bir doğal dil işleme modelidir.',\n",
    "        'Transformer, dikkat mekanizması kullanan modern bir sinir ağı mimarisidir.'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Örnek veri kaydetme (gerçek verileriniz varsa bu bölümü atlayın)\n",
    "df_sample = pd.DataFrame(sample_data)\n",
    "df_sample.to_csv('soru_cevap_veri.csv', index=False, encoding='utf-8')\n",
    "\n",
    "# Veriyi yükle\n",
    "try:\n",
    "    df = load_qa_data(DATA_FILE)\n",
    "    print(f\"✓ Toplam {len(df)} soru-cevap çifti yüklendi\")\n",
    "    print(\"\\nİlk birkaç örnek:\")\n",
    "    print(df.head())\n",
    "except Exception as e:\n",
    "    print(f\"Hata: {e}\")\n",
    "    print(\"Lütfen veri dosyanızın yolunu ve formatını kontrol edin.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Veri Ön İşleme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boş değerleri temizle\n",
    "df = df.dropna(subset=['soru', 'cevap'])\n",
    "\n",
    "# Boşlukları temizle\n",
    "df['soru'] = df['soru'].str.strip()\n",
    "df['cevap'] = df['cevap'].str.strip()\n",
    "\n",
    "# Çok kısa verileri filtrele (opsiyonel)\n",
    "df = df[(df['soru'].str.len() > 5) & (df['cevap'].str.len() > 10)]\n",
    "\n",
    "print(f\"Temizleme sonrası: {len(df)} soru-cevap çifti\")\n",
    "\n",
    "# Train-test split\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "print(f\"\\nEğitim seti: {len(train_df)} örnekleri\")\n",
    "print(f\"Test seti: {len(test_df)} örnekleri\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model ve Tokenizer Yükleme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Türkçe BERT modelini yükle\n",
    "model_name = 'dbmdz/bert-base-turkish-cased'\n",
    "\n",
    "print(f\"Model yükleniyor: {model_name}\")\n",
    "model = SentenceTransformer(model_name)\n",
    "print(\"✓ Model başarıyla yüklendi\")\n",
    "\n",
    "# Model bilgileri\n",
    "print(f\"\\nEmbedding boyutu: {model.get_sentence_embedding_dimension()}\")\n",
    "print(f\"Max token uzunluğu: {model.max_seq_length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training Data Hazırlama\n",
    "\n",
    "Soru-cevap çiftlerini InputExample formatına dönüştürüyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training örneklerini oluştur\n",
    "train_examples = []\n",
    "for idx, row in train_df.iterrows():\n",
    "    # Her soru-cevap çifti için pozitif örnek oluştur (benzerlik skoru = 1.0)\n",
    "    train_examples.append(InputExample(texts=[row['soru'], row['cevap']], label=1.0))\n",
    "\n",
    "print(f\"✓ {len(train_examples)} eğitim örneği oluşturuldu\")\n",
    "\n",
    "# DataLoader oluştur\n",
    "train_batch_size = 16  # GPU belleğinize göre ayarlayın\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=train_batch_size)\n",
    "\n",
    "print(f\"Batch sayısı: {len(train_dataloader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Loss Fonksiyonu Seçimi\n",
    "\n",
    "Soru-cevap embeddingleri için uygun loss fonksiyonları:\n",
    "- **CosineSimilarityLoss**: Soru ve cevap arasındaki kosinüs benzerliğini öğrenir\n",
    "- **MultipleNegativesRankingLoss**: Daha güçlü, negatif örnekler kullanır"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss fonksiyonu seçimi\n",
    "# Seçenek 1: Cosine Similarity Loss (Basit ve etkili)\n",
    "train_loss = losses.CosineSimilarityLoss(model)\n",
    "\n",
    "# Seçenek 2: Multiple Negatives Ranking Loss (Daha güçlü, önerilir)\n",
    "# train_loss = losses.MultipleNegativesRankingLoss(model)\n",
    "\n",
    "print(f\"✓ Loss fonksiyonu: {type(train_loss).__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluator Oluşturma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test seti için evaluator\n",
    "test_questions = test_df['soru'].tolist()\n",
    "test_answers = test_df['cevap'].tolist()\n",
    "test_scores = [1.0] * len(test_df)  # Tüm soru-cevap çiftleri pozitif\n",
    "\n",
    "evaluator = evaluation.EmbeddingSimilarityEvaluator(\n",
    "    test_questions, \n",
    "    test_answers, \n",
    "    test_scores,\n",
    "    name='qa-test'\n",
    ")\n",
    "\n",
    "print(\"✓ Evaluator oluşturuldu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parametreleri\n",
    "num_epochs = 4  # Epoch sayısı\n",
    "warmup_steps = int(len(train_dataloader) * num_epochs * 0.1)  # %10 warmup\n",
    "output_path = './turkish-bert-qa-finetuned'  # Model kaydedilecek yer\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"FINE-TUNING BAŞLIYOR\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Epoch sayısı: {num_epochs}\")\n",
    "print(f\"Batch size: {train_batch_size}\")\n",
    "print(f\"Warmup steps: {warmup_steps}\")\n",
    "print(f\"Model kaydedilecek yer: {output_path}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Fine-tuning başlat\n",
    "model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    evaluator=evaluator,\n",
    "    epochs=num_epochs,\n",
    "    warmup_steps=warmup_steps,\n",
    "    output_path=output_path,\n",
    "    evaluation_steps=500,  # Her 500 adımda bir değerlendirme\n",
    "    save_best_model=True,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Fine-tuning tamamlandı!\")\n",
    "print(f\"Model kaydedildi: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Test Etme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune edilmiş modeli yükle\n",
    "finetuned_model = SentenceTransformer(output_path)\n",
    "\n",
    "# Test sorusu\n",
    "test_soru = \"Yapay zeka nedir?\"\n",
    "\n",
    "# Soru embeddingini al\n",
    "soru_embedding = finetuned_model.encode(test_soru, convert_to_tensor=True)\n",
    "\n",
    "# Tüm cevapların embeddinglerini al\n",
    "cevap_embeddings = finetuned_model.encode(df['cevap'].tolist(), convert_to_tensor=True)\n",
    "\n",
    "# Cosine similarity hesapla\n",
    "from sentence_transformers.util import cos_sim\n",
    "\n",
    "cosine_scores = cos_sim(soru_embedding, cevap_embeddings)[0]\n",
    "\n",
    "# En yüksek skorlu cevapları bul\n",
    "top_k = min(5, len(df))\n",
    "top_results = torch.topk(cosine_scores, k=top_k)\n",
    "\n",
    "print(f\"\\nSoru: {test_soru}\")\n",
    "print(\"\\nEn benzer cevaplar:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for idx, (score, index) in enumerate(zip(top_results[0], top_results[1]), 1):\n",
    "    print(f\"\\n{idx}. Benzerlik Skoru: {score:.4f}\")\n",
    "    print(f\"   Soru: {df.iloc[index]['soru']}\")\n",
    "    print(f\"   Cevap: {df.iloc[index]['cevap']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Model Performans Karşılaştırması"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Orijinal vs Fine-tuned model karşılaştırması\n",
    "original_model = SentenceTransformer(model_name)\n",
    "\n",
    "def test_model_performance(model, name):\n",
    "    \"\"\"Model performansını test eder\"\"\"\n",
    "    print(f\"\\n{name} Model Performansı:\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Test seti üzerinde ortalama benzerlik skoru hesapla\n",
    "    similarities = []\n",
    "    \n",
    "    for idx, row in test_df.head(10).iterrows():  # İlk 10 test örneği\n",
    "        soru_emb = model.encode(row['soru'], convert_to_tensor=True)\n",
    "        cevap_emb = model.encode(row['cevap'], convert_to_tensor=True)\n",
    "        similarity = cos_sim(soru_emb, cevap_emb).item()\n",
    "        similarities.append(similarity)\n",
    "        print(f\"Soru-Cevap {idx+1} benzerliği: {similarity:.4f}\")\n",
    "    \n",
    "    print(f\"\\nOrtalama benzerlik: {np.mean(similarities):.4f}\")\n",
    "    return np.mean(similarities)\n",
    "\n",
    "# Karşılaştırma\n",
    "original_score = test_model_performance(original_model, \"Orijinal\")\n",
    "finetuned_score = test_model_performance(finetuned_model, \"Fine-tuned\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"SONUÇ:\")\n",
    "print(f\"Orijinal model skoru: {original_score:.4f}\")\n",
    "print(f\"Fine-tuned model skoru: {finetuned_score:.4f}\")\n",
    "print(f\"İyileşme: {((finetuned_score - original_score) / original_score * 100):.2f}%\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Modeli Kullanma - Örnek Fonksiyon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_answer(question, knowledge_base_df, model, top_k=3):\n",
    "    \"\"\"\n",
    "    Verilen soru için en iyi cevabı bulur.\n",
    "    \n",
    "    Args:\n",
    "        question: Kullanıcı sorusu\n",
    "        knowledge_base_df: Soru-cevap dataframe'i\n",
    "        model: Fine-tuned model\n",
    "        top_k: Gösterilecek en iyi K sonuç\n",
    "    \n",
    "    Returns:\n",
    "        En iyi cevaplar ve skorlar\n",
    "    \"\"\"\n",
    "    # Soru embeddingini al\n",
    "    question_embedding = model.encode(question, convert_to_tensor=True)\n",
    "    \n",
    "    # Tüm cevapların embeddinglerini al\n",
    "    answer_embeddings = model.encode(\n",
    "        knowledge_base_df['cevap'].tolist(), \n",
    "        convert_to_tensor=True\n",
    "    )\n",
    "    \n",
    "    # Benzerlik hesapla\n",
    "    scores = cos_sim(question_embedding, answer_embeddings)[0]\n",
    "    \n",
    "    # En iyi sonuçları bul\n",
    "    top_results = torch.topk(scores, k=min(top_k, len(knowledge_base_df)))\n",
    "    \n",
    "    results = []\n",
    "    for score, idx in zip(top_results[0], top_results[1]):\n",
    "        results.append({\n",
    "            'soru': knowledge_base_df.iloc[idx]['soru'],\n",
    "            'cevap': knowledge_base_df.iloc[idx]['cevap'],\n",
    "            'skor': score.item()\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Örnek kullanım\n",
    "test_questions = [\n",
    "    \"Programlama dilleri nelerdir?\",\n",
    "    \"Derin öğrenme nasıl çalışır?\",\n",
    "    \"Yapay zeka uygulamaları nelerdir?\"\n",
    "]\n",
    "\n",
    "for q in test_questions:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Soru: {q}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    results = find_best_answer(q, df, finetuned_model, top_k=2)\n",
    "    \n",
    "    for i, result in enumerate(results, 1):\n",
    "        print(f\"\\n{i}. Sonuç (Skor: {result['skor']:.4f})\")\n",
    "        print(f\"   Benzer Soru: {result['soru']}\")\n",
    "        print(f\"   Cevap: {result['cevap']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Model ve Tokenizer'ı Kaydetme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model zaten output_path'e kaydedildi\n",
    "# Ek olarak Hugging Face Hub'a yüklemek isterseniz:\n",
    "\n",
    "# from huggingface_hub import login\n",
    "# login()  # Token ile giriş yapın\n",
    "# finetuned_model.save_to_hub(\"kullanici-adi/turkish-bert-qa-finetuned\")\n",
    "\n",
    "print(f\"\\n✓ Model başarıyla kaydedildi: {output_path}\")\n",
    "print(\"\\nModeli yüklemek için:\")\n",
    "print(f\"model = SentenceTransformer('{output_path}')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notlar ve İpuçları\n",
    "\n",
    "### Hyperparameter Tuning:\n",
    "- **Batch size**: GPU belleğinize göre 8, 16, 32\n",
    "- **Epochs**: Genellikle 2-5 epoch yeterli\n",
    "- **Learning rate**: Varsayılan genellikle iyidir (2e-5)\n",
    "- **Warmup steps**: Total steps'in %10'u önerilir\n",
    "\n",
    "### Loss Fonksiyonları:\n",
    "- **CosineSimilarityLoss**: Basit ve hızlı, soru-cevap çiftleri için iyi\n",
    "- **MultipleNegativesRankingLoss**: Daha güçlü, büyük veri setleri için önerilir\n",
    "- **ContrastiveLoss**: Negatif örneklerle çalışır\n",
    "- **TripletLoss**: Anchor-positive-negative üçlüleri kullanır\n",
    "\n",
    "### Veri Artırma:\n",
    "- Aynı anlama gelen farklı soru formları ekleyin\n",
    "- Negatif örnekler (ilgisiz soru-cevap çiftleri) ekleyin\n",
    "- Veri setinizi büyütmek için paraphrase teknikleri kullanın\n",
    "\n",
    "### Performans İyileştirme:\n",
    "- Daha fazla veri toplayın\n",
    "- Veri kalitesini artırın\n",
    "- Farklı loss fonksiyonları deneyin\n",
    "- Hyperparameter tuning yapın"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
